{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP for analytes classification on PCA data using Keras\n",
    "#### Edgar Acuna\n",
    "#### July 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tempfile\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "df1=pd.read_csv(\"c://onr2020/NRLset1_part1.csv\",header=None)\n",
    "df2=pd.read_csv(\"c://onr2020/NRLset1_part2.csv\",header=None)\n",
    "df3=pd.read_csv(\"c://onr2020/NRLset1_part3.csv\",header=None)\n",
    "df4=pd.read_csv(\"c://onr2020/NRLset1_part4.csv\",header=None)\n",
    "df5=pd.read_csv(\"c://onr2020/NRLset1_part5.csv\",header=None)\n",
    "df6=pd.read_csv(\"c://onr2020/NRLset1_part6.csv\",header=None)\n",
    "df7=pd.read_csv(\"c://onr2020/NRLset1_part7.csv\",header=None)\n",
    "df8=pd.read_csv(\"c://onr2020/NRLset1_part8.csv\",header=None)\n",
    "y=pd.read_csv(\"c://onr2020/labels.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfset1=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "dfset2=dfset1.copy()\n",
    "pca = PCA(n_components=50)\n",
    "pca_result = pca.fit_transform(dfset2)\n",
    "dfset1['pca-one'] = pca_result[:,0]\n",
    "dfset1['pca-two'] = pca_result[:,1] \n",
    "dfset1['pca-three'] = pca_result[:,2]\n",
    "pca_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.167591</td>\n",
       "      <td>-1.468151</td>\n",
       "      <td>-0.873104</td>\n",
       "      <td>0.280079</td>\n",
       "      <td>-0.026923</td>\n",
       "      <td>0.154126</td>\n",
       "      <td>-0.196475</td>\n",
       "      <td>-0.074681</td>\n",
       "      <td>0.016685</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>-0.015719</td>\n",
       "      <td>-0.010643</td>\n",
       "      <td>-0.011491</td>\n",
       "      <td>-0.010950</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.337234</td>\n",
       "      <td>-3.199556</td>\n",
       "      <td>-0.610903</td>\n",
       "      <td>-0.185739</td>\n",
       "      <td>-0.387909</td>\n",
       "      <td>-0.136990</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>-0.394372</td>\n",
       "      <td>0.212147</td>\n",
       "      <td>0.053664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102973</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>-0.051839</td>\n",
       "      <td>-0.025609</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.017732</td>\n",
       "      <td>-0.022576</td>\n",
       "      <td>0.017974</td>\n",
       "      <td>-0.008187</td>\n",
       "      <td>-0.004044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.274613</td>\n",
       "      <td>0.100711</td>\n",
       "      <td>1.996565</td>\n",
       "      <td>-0.693721</td>\n",
       "      <td>-0.118535</td>\n",
       "      <td>-0.054804</td>\n",
       "      <td>-0.105876</td>\n",
       "      <td>-0.099250</td>\n",
       "      <td>-0.017151</td>\n",
       "      <td>0.093985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002206</td>\n",
       "      <td>-0.007794</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>-0.006627</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>-0.005352</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.005572</td>\n",
       "      <td>0.004198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.686995</td>\n",
       "      <td>0.132895</td>\n",
       "      <td>1.957354</td>\n",
       "      <td>-0.713554</td>\n",
       "      <td>-0.084030</td>\n",
       "      <td>0.035380</td>\n",
       "      <td>0.036085</td>\n",
       "      <td>-0.108315</td>\n",
       "      <td>0.054159</td>\n",
       "      <td>0.086967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>-0.001998</td>\n",
       "      <td>-0.004797</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>-0.000779</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>0.004655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.268746</td>\n",
       "      <td>-1.605050</td>\n",
       "      <td>-0.910381</td>\n",
       "      <td>0.259557</td>\n",
       "      <td>-0.052556</td>\n",
       "      <td>0.031169</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.028203</td>\n",
       "      <td>-0.062977</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002194</td>\n",
       "      <td>-0.013587</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>-0.008165</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>-0.003628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0  -7.167591 -1.468151 -0.873104  0.280079 -0.026923  0.154126 -0.196475   \n",
       "1  22.337234 -3.199556 -0.610903 -0.185739 -0.387909 -0.136990 -0.200286   \n",
       "2  -3.274613  0.100711  1.996565 -0.693721 -0.118535 -0.054804 -0.105876   \n",
       "3  -3.686995  0.132895  1.957354 -0.713554 -0.084030  0.035380  0.036085   \n",
       "4  -8.268746 -1.605050 -0.910381  0.259557 -0.052556  0.031169  0.010076   \n",
       "\n",
       "         7         8         9   ...        40        41        42        43  \\\n",
       "0 -0.074681  0.016685  0.001436  ...  0.010736  0.002669  0.015142 -0.015719   \n",
       "1 -0.394372  0.212147  0.053664  ...  0.102973  0.000419 -0.051839 -0.025609   \n",
       "2 -0.099250 -0.017151  0.093985  ... -0.002206 -0.007794  0.004601 -0.006627   \n",
       "3 -0.108315  0.054159  0.086967  ...  0.004965 -0.001998 -0.004797  0.003208   \n",
       "4  0.021967  0.028203 -0.062977  ... -0.002194 -0.013587  0.002520  0.004567   \n",
       "\n",
       "         44        45        46        47        48        49  \n",
       "0 -0.010643 -0.011491 -0.010950  0.000732  0.000089  0.002056  \n",
       "1  0.007779  0.017732 -0.022576  0.017974 -0.008187 -0.004044  \n",
       "2  0.002766 -0.005352  0.002778  0.003041  0.005572  0.004198  \n",
       "3 -0.000610 -0.000779  0.003366  0.002871  0.005891  0.004655  \n",
       "4  0.005434 -0.008165  0.008093 -0.000083 -0.002990 -0.003628  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=pd.DataFrame(pca_result)\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration options\n",
    "feature_vector_length = 50\n",
    "num_classes = 18000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:\n",
      "(12600, 50)\n",
      "Test dimension:\n",
      "(5400, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(b,y, test_size=0.3,random_state=0)\n",
    "print('Train dimension:');print(X_train.shape)\n",
    "print('Test dimension:');print(X_test.shape)\n",
    "\n",
    "# Convert target classes to categorical ones\n",
    "Y_train = to_categorical(Y_train, num_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (50,)\n",
      "WARNING:tensorflow:From C:\\Users\\eacun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               15300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 18000)             1818000   \n",
      "=================================================================\n",
      "Total params: 1,863,400\n",
      "Trainable params: 1,863,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the input shape\n",
    "input_shape = (feature_vector_length,)\n",
    "print(f'Feature shape: {input_shape}')\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.1, input_shape=input_shape))\n",
    "model.add(Dense(300, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eacun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10080 samples, validate on 2520 samples\n",
      "Epoch 1/100\n",
      "10080/10080 [==============================] - 29s 3ms/step - loss: 4.3865 - accuracy: 0.0292 - val_loss: 3.7190 - val_accuracy: 0.0302\n",
      "Epoch 2/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 3.6235 - accuracy: 0.0604 - val_loss: 3.3720 - val_accuracy: 0.1044\n",
      "Epoch 3/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 3.0811 - accuracy: 0.1903 - val_loss: 2.5962 - val_accuracy: 0.3290\n",
      "Epoch 4/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 2.3866 - accuracy: 0.4042 - val_loss: 1.9215 - val_accuracy: 0.5913\n",
      "Epoch 5/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 1.8917 - accuracy: 0.5426 - val_loss: 1.4795 - val_accuracy: 0.7131\n",
      "Epoch 6/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 1.5906 - accuracy: 0.6260 - val_loss: 1.1843 - val_accuracy: 0.7845\n",
      "Epoch 7/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 1.3801 - accuracy: 0.6747 - val_loss: 1.0187 - val_accuracy: 0.7937\n",
      "Epoch 8/100\n",
      "10080/10080 [==============================] - 25s 2ms/step - loss: 1.2633 - accuracy: 0.7080 - val_loss: 0.8371 - val_accuracy: 0.8687\n",
      "Epoch 9/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 1.1586 - accuracy: 0.7265 - val_loss: 0.7518 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "10080/10080 [==============================] - 25s 2ms/step - loss: 1.0790 - accuracy: 0.7403 - val_loss: 0.6999 - val_accuracy: 0.8758\n",
      "Epoch 11/100\n",
      "10080/10080 [==============================] - 25s 2ms/step - loss: 1.0118 - accuracy: 0.7565 - val_loss: 0.6283 - val_accuracy: 0.8976\n",
      "Epoch 12/100\n",
      "10080/10080 [==============================] - 27s 3ms/step - loss: 0.9741 - accuracy: 0.7608 - val_loss: 0.6138 - val_accuracy: 0.8742\n",
      "Epoch 13/100\n",
      "10080/10080 [==============================] - 25s 2ms/step - loss: 0.9329 - accuracy: 0.7739 - val_loss: 0.5615 - val_accuracy: 0.8976\n",
      "Epoch 14/100\n",
      "10080/10080 [==============================] - 25s 2ms/step - loss: 0.8903 - accuracy: 0.7818 - val_loss: 0.5206 - val_accuracy: 0.9052\n",
      "Epoch 15/100\n",
      "10080/10080 [==============================] - 25s 3ms/step - loss: 0.8602 - accuracy: 0.7861 - val_loss: 0.5124 - val_accuracy: 0.9091\n",
      "Epoch 16/100\n",
      "10080/10080 [==============================] - 31s 3ms/step - loss: 0.8388 - accuracy: 0.7936 - val_loss: 0.5031 - val_accuracy: 0.8956\n",
      "Epoch 17/100\n",
      "10080/10080 [==============================] - 32s 3ms/step - loss: 0.8006 - accuracy: 0.7973 - val_loss: 0.4881 - val_accuracy: 0.9024\n",
      "Epoch 18/100\n",
      "10080/10080 [==============================] - 32s 3ms/step - loss: 0.8083 - accuracy: 0.7989 - val_loss: 0.4631 - val_accuracy: 0.9075\n",
      "Epoch 19/100\n",
      "10080/10080 [==============================] - 32s 3ms/step - loss: 0.7815 - accuracy: 0.8024 - val_loss: 0.4454 - val_accuracy: 0.9107\n",
      "Epoch 20/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.7520 - accuracy: 0.8121 - val_loss: 0.4298 - val_accuracy: 0.9222\n",
      "Epoch 21/100\n",
      "10080/10080 [==============================] - 35s 3ms/step - loss: 0.7187 - accuracy: 0.8227 - val_loss: 0.4271 - val_accuracy: 0.9060\n",
      "Epoch 22/100\n",
      "10080/10080 [==============================] - 35s 3ms/step - loss: 0.7280 - accuracy: 0.8188 - val_loss: 0.4058 - val_accuracy: 0.9135\n",
      "Epoch 23/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.6829 - accuracy: 0.8291 - val_loss: 0.4136 - val_accuracy: 0.9111\n",
      "Epoch 24/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.6692 - accuracy: 0.8312 - val_loss: 0.3911 - val_accuracy: 0.9163\n",
      "Epoch 25/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.6613 - accuracy: 0.8309 - val_loss: 0.3911 - val_accuracy: 0.9119\n",
      "Epoch 26/100\n",
      "10080/10080 [==============================] - 32s 3ms/step - loss: 0.6608 - accuracy: 0.8311 - val_loss: 0.3906 - val_accuracy: 0.9111\n",
      "Epoch 27/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.6436 - accuracy: 0.8389 - val_loss: 0.3713 - val_accuracy: 0.9198\n",
      "Epoch 28/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.6108 - accuracy: 0.8407 - val_loss: 0.3629 - val_accuracy: 0.9234\n",
      "Epoch 29/100\n",
      "10080/10080 [==============================] - 32s 3ms/step - loss: 0.6097 - accuracy: 0.8455 - val_loss: 0.3665 - val_accuracy: 0.9202\n",
      "Epoch 30/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.5987 - accuracy: 0.8488 - val_loss: 0.3579 - val_accuracy: 0.9206\n",
      "Epoch 31/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.6056 - accuracy: 0.8493 - val_loss: 0.3692 - val_accuracy: 0.9155loss: 0\n",
      "Epoch 32/100\n",
      "10080/10080 [==============================] - 32s 3ms/step - loss: 0.5864 - accuracy: 0.8493 - val_loss: 0.3423 - val_accuracy: 0.9274\n",
      "Epoch 33/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.5849 - accuracy: 0.8514 - val_loss: 0.3498 - val_accuracy: 0.9246\n",
      "Epoch 34/100\n",
      "10080/10080 [==============================] - 32s 3ms/step - loss: 0.5662 - accuracy: 0.8514 - val_loss: 0.3318 - val_accuracy: 0.9266\n",
      "Epoch 35/100\n",
      "10080/10080 [==============================] - 32s 3ms/step - loss: 0.5567 - accuracy: 0.8573 - val_loss: 0.3485 - val_accuracy: 0.9171\n",
      "Epoch 36/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.5323 - accuracy: 0.8623 - val_loss: 0.3399 - val_accuracy: 0.9270\n",
      "Epoch 37/100\n",
      "10080/10080 [==============================] - 32s 3ms/step - loss: 0.5293 - accuracy: 0.8632 - val_loss: 0.3307 - val_accuracy: 0.9278\n",
      "Epoch 38/100\n",
      "10080/10080 [==============================] - 32s 3ms/step - loss: 0.5313 - accuracy: 0.8632 - val_loss: 0.3428 - val_accuracy: 0.9175\n",
      "Epoch 39/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.5185 - accuracy: 0.8659 - val_loss: 0.3461 - val_accuracy: 0.9183\n",
      "Epoch 40/100\n",
      "10080/10080 [==============================] - 32s 3ms/step - loss: 0.5206 - accuracy: 0.8678 - val_loss: 0.3123 - val_accuracy: 0.9302\n",
      "Epoch 41/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.5098 - accuracy: 0.8689 - val_loss: 0.3031 - val_accuracy: 0.9333\n",
      "Epoch 42/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.5024 - accuracy: 0.8735 - val_loss: 0.3160 - val_accuracy: 0.9254\n",
      "Epoch 43/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.4794 - accuracy: 0.8735 - val_loss: 0.3150 - val_accuracy: 0.9262\n",
      "Epoch 44/100\n",
      "10080/10080 [==============================] - 23s 2ms/step - loss: 0.5087 - accuracy: 0.8669 - val_loss: 0.3039 - val_accuracy: 0.9333\n",
      "Epoch 45/100\n",
      "10080/10080 [==============================] - 22s 2ms/step - loss: 0.4911 - accuracy: 0.8737 - val_loss: 0.3176 - val_accuracy: 0.9266\n",
      "Epoch 46/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.4693 - accuracy: 0.8793 - val_loss: 0.2864 - val_accuracy: 0.9365\n",
      "Epoch 47/100\n",
      "10080/10080 [==============================] - 36s 4ms/step - loss: 0.4785 - accuracy: 0.8748 - val_loss: 0.3030 - val_accuracy: 0.9341\n",
      "Epoch 48/100\n",
      "10080/10080 [==============================] - 36s 4ms/step - loss: 0.4748 - accuracy: 0.8777 - val_loss: 0.2997 - val_accuracy: 0.9313\n",
      "Epoch 49/100\n",
      "10080/10080 [==============================] - 35s 3ms/step - loss: 0.4641 - accuracy: 0.8787 - val_loss: 0.2883 - val_accuracy: 0.9349\n",
      "Epoch 50/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.4582 - accuracy: 0.8801 - val_loss: 0.2752 - val_accuracy: 0.9389\n",
      "Epoch 51/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.4547 - accuracy: 0.8810 - val_loss: 0.3149 - val_accuracy: 0.9179\n",
      "Epoch 52/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.4559 - accuracy: 0.8804 - val_loss: 0.2776 - val_accuracy: 0.9381\n",
      "Epoch 53/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.4466 - accuracy: 0.8847 - val_loss: 0.2898 - val_accuracy: 0.9317\n",
      "Epoch 54/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.4383 - accuracy: 0.8853 - val_loss: 0.2840 - val_accuracy: 0.9365\n",
      "Epoch 55/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.4292 - accuracy: 0.8870 - val_loss: 0.2804 - val_accuracy: 0.9349\n",
      "Epoch 56/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.4331 - accuracy: 0.8863 - val_loss: 0.2724 - val_accuracy: 0.9413\n",
      "Epoch 57/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.4269 - accuracy: 0.8881 - val_loss: 0.2672 - val_accuracy: 0.9409\n",
      "Epoch 58/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.4057 - accuracy: 0.8929 - val_loss: 0.2819 - val_accuracy: 0.9397\n",
      "Epoch 59/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.4133 - accuracy: 0.8920 - val_loss: 0.2669 - val_accuracy: 0.9373\n",
      "Epoch 60/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.4125 - accuracy: 0.8926 - val_loss: 0.2580 - val_accuracy: 0.9425\n",
      "Epoch 61/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.4092 - accuracy: 0.8935 - val_loss: 0.2745 - val_accuracy: 0.9393\n",
      "Epoch 62/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.4126 - accuracy: 0.8930 - val_loss: 0.2828 - val_accuracy: 0.9357\n",
      "Epoch 63/100\n",
      "10080/10080 [==============================] - 35s 4ms/step - loss: 0.4005 - accuracy: 0.8966 - val_loss: 0.2678 - val_accuracy: 0.9429\n",
      "Epoch 64/100\n",
      "10080/10080 [==============================] - 36s 4ms/step - loss: 0.4047 - accuracy: 0.8937 - val_loss: 0.2732 - val_accuracy: 0.9381\n",
      "Epoch 65/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.3946 - accuracy: 0.8949 - val_loss: 0.2662 - val_accuracy: 0.9448\n",
      "Epoch 66/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.4029 - accuracy: 0.8931 - val_loss: 0.2677 - val_accuracy: 0.9417\n",
      "Epoch 67/100\n",
      "10080/10080 [==============================] - 35s 3ms/step - loss: 0.3996 - accuracy: 0.8944 - val_loss: 0.2538 - val_accuracy: 0.9456\n",
      "Epoch 68/100\n",
      "10080/10080 [==============================] - 35s 4ms/step - loss: 0.3737 - accuracy: 0.9013 - val_loss: 0.2690 - val_accuracy: 0.9361\n",
      "Epoch 69/100\n",
      "10080/10080 [==============================] - 38s 4ms/step - loss: 0.3946 - accuracy: 0.8931 - val_loss: 0.2826 - val_accuracy: 0.9294\n",
      "Epoch 70/100\n",
      "10080/10080 [==============================] - 36s 4ms/step - loss: 0.3796 - accuracy: 0.8984 - val_loss: 0.2722 - val_accuracy: 0.9365\n",
      "Epoch 71/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.3707 - accuracy: 0.9016 - val_loss: 0.2542 - val_accuracy: 0.9409\n",
      "Epoch 72/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.3789 - accuracy: 0.8990 - val_loss: 0.2604 - val_accuracy: 0.9377\n",
      "Epoch 73/100\n",
      "10080/10080 [==============================] - 35s 3ms/step - loss: 0.3722 - accuracy: 0.8998 - val_loss: 0.2573 - val_accuracy: 0.9405\n",
      "Epoch 74/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.3832 - accuracy: 0.8989 - val_loss: 0.2838 - val_accuracy: 0.9349\n",
      "Epoch 75/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.3777 - accuracy: 0.8977 - val_loss: 0.2610 - val_accuracy: 0.9345\n",
      "Epoch 76/100\n",
      "10080/10080 [==============================] - 35s 3ms/step - loss: 0.3727 - accuracy: 0.8969 - val_loss: 0.2614 - val_accuracy: 0.9393\n",
      "Epoch 77/100\n",
      "10080/10080 [==============================] - 35s 3ms/step - loss: 0.3585 - accuracy: 0.9025 - val_loss: 0.2526 - val_accuracy: 0.9444\n",
      "Epoch 78/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.3573 - accuracy: 0.9022 - val_loss: 0.2558 - val_accuracy: 0.9448\n",
      "Epoch 79/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.3722 - accuracy: 0.8989 - val_loss: 0.2498 - val_accuracy: 0.9444\n",
      "Epoch 80/100\n",
      "10080/10080 [==============================] - 33s 3ms/step - loss: 0.3713 - accuracy: 0.8998 - val_loss: 0.2517 - val_accuracy: 0.9405\n",
      "Epoch 81/100\n",
      "10080/10080 [==============================] - 34s 3ms/step - loss: 0.3588 - accuracy: 0.9035 - val_loss: 0.2429 - val_accuracy: 0.9492\n",
      "Epoch 82/100\n",
      "10080/10080 [==============================] - 35s 3ms/step - loss: 0.3634 - accuracy: 0.9025 - val_loss: 0.2512 - val_accuracy: 0.9440\n",
      "Epoch 83/100\n",
      "10080/10080 [==============================] - 35s 4ms/step - loss: 0.3474 - accuracy: 0.9068 - val_loss: 0.2418 - val_accuracy: 0.9496\n",
      "Epoch 84/100\n",
      "10080/10080 [==============================] - 31s 3ms/step - loss: 0.3497 - accuracy: 0.9070 - val_loss: 0.2841 - val_accuracy: 0.9345\n",
      "Epoch 85/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3542 - accuracy: 0.9060 - val_loss: 0.2680 - val_accuracy: 0.9357\n",
      "Epoch 86/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3617 - accuracy: 0.9040 - val_loss: 0.2487 - val_accuracy: 0.9425\n",
      "Epoch 87/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3374 - accuracy: 0.9070 - val_loss: 0.2496 - val_accuracy: 0.9456\n",
      "Epoch 88/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3448 - accuracy: 0.9075 - val_loss: 0.2562 - val_accuracy: 0.9369\n",
      "Epoch 89/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3347 - accuracy: 0.9100 - val_loss: 0.2705 - val_accuracy: 0.9369\n",
      "Epoch 90/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3396 - accuracy: 0.9080 - val_loss: 0.2464 - val_accuracy: 0.9460\n",
      "Epoch 91/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3478 - accuracy: 0.9070 - val_loss: 0.2420 - val_accuracy: 0.9452\n",
      "Epoch 92/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3326 - accuracy: 0.9111 - val_loss: 0.2403 - val_accuracy: 0.9460\n",
      "Epoch 93/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3314 - accuracy: 0.9119 - val_loss: 0.2467 - val_accuracy: 0.9480\n",
      "Epoch 94/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3287 - accuracy: 0.9112 - val_loss: 0.2451 - val_accuracy: 0.9440\n",
      "Epoch 95/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3299 - accuracy: 0.9126 - val_loss: 0.2552 - val_accuracy: 0.9409\n",
      "Epoch 96/100\n",
      "10080/10080 [==============================] - 25s 2ms/step - loss: 0.3262 - accuracy: 0.9092 - val_loss: 0.2417 - val_accuracy: 0.9440\n",
      "Epoch 97/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3133 - accuracy: 0.9152 - val_loss: 0.2451 - val_accuracy: 0.9464\n",
      "Epoch 98/100\n",
      "10080/10080 [==============================] - 25s 2ms/step - loss: 0.3203 - accuracy: 0.9138 - val_loss: 0.2404 - val_accuracy: 0.9437\n",
      "Epoch 99/100\n",
      "10080/10080 [==============================] - 24s 2ms/step - loss: 0.3200 - accuracy: 0.9115 - val_loss: 0.2297 - val_accuracy: 0.9512\n",
      "Epoch 100/100\n",
      "10080/10080 [==============================] - 25s 2ms/step - loss: 0.3225 - accuracy: 0.9110 - val_loss: 0.2337 - val_accuracy: 0.9452\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "baseline_history=model.fit(X_train, Y_train, epochs=100, batch_size=50, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400/5400 [==============================] - 4s 790us/step\n",
      "[0.24746465962242198, 0.9425926208496094]\n",
      "Test results - Loss: 0.24746465962242198 - Accuracy: 0.9425926208496094%\n"
     ]
    }
   ],
   "source": [
    "# Test the model after training\n",
    "test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(test_results)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing all the results with MLP\n",
    "|Data | Accuracy |\n",
    "| --- |  --- |\n",
    "| Original* | .5753 |\n",
    "| Binned* | .5812 |\n",
    "| 50 PC's  | .9425 |\n",
    "| 100 PC's | .9231 |\n",
    "| 200 PC's | .9120 |\n",
    "| 360 PC's | .9033 |\n",
    "| Lower section* | .6233 |\n",
    "| Middle section* | .2629 |\n",
    "| Upper section* | .2468 |\n",
    "\n",
    "(*) This result appears in another notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nn still outperforms MLP in the multiclass problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Binary  Classification of  some analytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list(range(1,41))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyte #18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:\n",
      "(12600, 50)\n",
      "Test dimension:\n",
      "(5400, 50)\n"
     ]
    }
   ],
   "source": [
    "yclass=y.copy()\n",
    "yclass[yclass!=16]=0\n",
    "yclass[yclass==16]=1\n",
    "X_train, X_test, yclass_train, yclass_test = train_test_split(b,yclass,test_size=0.3,random_state=0)\n",
    "print('Train dimension:');print(X_train.shape)\n",
    "print('Test dimension:');print(X_test.shape)\n",
    "Y_train = to_categorical(yclass_train, num_classes)\n",
    "Y_test = to_categorical(yclass_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (50,)\n",
      "WARNING:tensorflow:From C:\\Users\\eacun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               15300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 18000)             1818000   \n",
      "=================================================================\n",
      "Total params: 1,863,400\n",
      "Trainable params: 1,863,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the input shape\n",
    "input_shape = (feature_vector_length,)\n",
    "print(f'Feature shape: {input_shape}')\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.1, input_shape=input_shape))\n",
    "model.add(Dense(300, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eacun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10080 samples, validate on 2520 samples\n",
      "Epoch 1/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 1.1791 - accuracy: 1.0000 - precision: 0.9767 - recall: 0.8228 - val_loss: 0.1328 - val_accuracy: 1.0000 - val_precision: 0.9742 - val_recall: 0.9742\n",
      "Epoch 2/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.1223 - accuracy: 1.0000 - precision: 0.9766 - recall: 0.9751 - val_loss: 0.1132 - val_accuracy: 1.0000 - val_precision: 0.9746 - val_recall: 0.9742\n",
      "Epoch 3/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0988 - accuracy: 1.0000 - precision: 0.9770 - recall: 0.9769 - val_loss: 0.1022 - val_accuracy: 1.0000 - val_precision: 0.9770 - val_recall: 0.9766\n",
      "Epoch 4/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0842 - accuracy: 1.0000 - precision: 0.9799 - recall: 0.9795 - val_loss: 0.0776 - val_accuracy: 1.0000 - val_precision: 0.9802 - val_recall: 0.9802\n",
      "Epoch 5/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0733 - accuracy: 1.0000 - precision: 0.9824 - recall: 0.9824 - val_loss: 0.0682 - val_accuracy: 1.0000 - val_precision: 0.9806 - val_recall: 0.9806\n",
      "Epoch 6/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0598 - accuracy: 1.0000 - precision: 0.9838 - recall: 0.9838 - val_loss: 0.0516 - val_accuracy: 1.0000 - val_precision: 0.9810 - val_recall: 0.9810\n",
      "Epoch 7/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0531 - accuracy: 1.0000 - precision: 0.9852 - recall: 0.9852 - val_loss: 0.0389 - val_accuracy: 1.0000 - val_precision: 0.9853 - val_recall: 0.9853\n",
      "Epoch 8/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0505 - accuracy: 1.0000 - precision: 0.9868 - recall: 0.9867 - val_loss: 0.0357 - val_accuracy: 1.0000 - val_precision: 0.9913 - val_recall: 0.9913\n",
      "Epoch 9/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0410 - accuracy: 1.0000 - precision: 0.9886 - recall: 0.9885 - val_loss: 0.0252 - val_accuracy: 1.0000 - val_precision: 0.9940 - val_recall: 0.9940\n",
      "Epoch 10/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0374 - accuracy: 1.0000 - precision: 0.9892 - recall: 0.9892 - val_loss: 0.0248 - val_accuracy: 1.0000 - val_precision: 0.9925 - val_recall: 0.9925\n",
      "Epoch 11/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0376 - accuracy: 1.0000 - precision: 0.9902 - recall: 0.9902 - val_loss: 0.0211 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 12/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0380 - accuracy: 1.0000 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.0466 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 13/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0301 - accuracy: 1.0000 - precision: 0.9913 - recall: 0.9912 - val_loss: 0.0200 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 14/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0316 - accuracy: 1.0000 - precision: 0.9914 - recall: 0.9912 - val_loss: 0.0205 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 15/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0324 - accuracy: 1.0000 - precision: 0.9912 - recall: 0.9912 - val_loss: 0.0386 - val_accuracy: 1.0000 - val_precision: 0.9893 - val_recall: 0.9893\n",
      "Epoch 16/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0297 - accuracy: 1.0000 - precision: 0.9917 - recall: 0.9916 - val_loss: 0.0171 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 17/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0317 - accuracy: 1.0000 - precision: 0.9908 - recall: 0.9907 - val_loss: 0.0198 - val_accuracy: 1.0000 - val_precision: 0.9937 - val_recall: 0.9937\n",
      "Epoch 18/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0296 - accuracy: 1.0000 - precision: 0.9918 - recall: 0.9918 - val_loss: 0.0188 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 19/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0270 - accuracy: 1.0000 - precision: 0.9920 - recall: 0.9920 - val_loss: 0.0165 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 20/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0281 - accuracy: 1.0000 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.0213 - val_accuracy: 1.0000 - val_precision: 0.9940 - val_recall: 0.9940\n",
      "Epoch 21/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0269 - accuracy: 1.0000 - precision: 0.9925 - recall: 0.9925 - val_loss: 0.0282 - val_accuracy: 1.0000 - val_precision: 0.9921 - val_recall: 0.9921\n",
      "Epoch 22/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0319 - accuracy: 1.0000 - precision: 0.9908 - recall: 0.9907 - val_loss: 0.0237 - val_accuracy: 1.0000 - val_precision: 0.9921 - val_recall: 0.9921\n",
      "Epoch 23/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0274 - accuracy: 1.0000 - precision: 0.9928 - recall: 0.9927 - val_loss: 0.0189 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 24/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0282 - accuracy: 1.0000 - precision: 0.9928 - recall: 0.9927 - val_loss: 0.0470 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 25/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0290 - accuracy: 1.0000 - precision: 0.9925 - recall: 0.9924 - val_loss: 0.0203 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 26/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0270 - accuracy: 1.0000 - precision: 0.9931 - recall: 0.9930 - val_loss: 0.0220 - val_accuracy: 1.0000 - val_precision: 0.9929 - val_recall: 0.9929\n",
      "Epoch 27/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0250 - accuracy: 1.0000 - precision: 0.9927 - recall: 0.9926 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_precision: 0.9937 - val_recall: 0.9937\n",
      "Epoch 28/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0289 - accuracy: 1.0000 - precision: 0.9921 - recall: 0.9920 - val_loss: 0.0203 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 29/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0277 - accuracy: 1.0000 - precision: 0.9923 - recall: 0.9923 - val_loss: 0.0194 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 30/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0245 - accuracy: 1.0000 - precision: 0.9933 - recall: 0.9932 - val_loss: 0.0170 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 31/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0263 - accuracy: 1.0000 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.0269 - val_accuracy: 1.0000 - val_precision: 0.9917 - val_recall: 0.9917\n",
      "Epoch 32/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0233 - accuracy: 1.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.0194 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 33/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0276 - accuracy: 1.0000 - precision: 0.9925 - recall: 0.9925 - val_loss: 0.0164 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 34/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0261 - accuracy: 1.0000 - precision: 0.9933 - recall: 0.9933 - val_loss: 0.0166 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 35/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0244 - accuracy: 1.0000 - precision: 0.9926 - recall: 0.9926 - val_loss: 0.0197 - val_accuracy: 1.0000 - val_precision: 0.9940 - val_recall: 0.9940\n",
      "Epoch 36/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0236 - accuracy: 1.0000 - precision: 0.9935 - recall: 0.9933 - val_loss: 0.0202 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 37/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0255 - accuracy: 1.0000 - precision: 0.9925 - recall: 0.9925 - val_loss: 0.0179 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 38/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0253 - accuracy: 1.0000 - precision: 0.9923 - recall: 0.9923 - val_loss: 0.0178 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 39/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0270 - accuracy: 1.0000 - precision: 0.9922 - recall: 0.9922 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 40/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0251 - accuracy: 1.0000 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.0156 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 41/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0245 - accuracy: 1.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.0211 - val_accuracy: 1.0000 - val_precision: 0.9940 - val_recall: 0.9940\n",
      "Epoch 42/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0242 - accuracy: 1.0000 - precision: 0.9931 - recall: 0.9931 - val_loss: 0.0250 - val_accuracy: 1.0000 - val_precision: 0.9925 - val_recall: 0.9925\n",
      "Epoch 43/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0246 - accuracy: 1.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.0220 - val_accuracy: 1.0000 - val_precision: 0.9940 - val_recall: 0.9940\n",
      "Epoch 44/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0231 - accuracy: 1.0000 - precision: 0.9926 - recall: 0.9926 - val_loss: 0.0155 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 45/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0252 - accuracy: 1.0000 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.0202 - val_accuracy: 1.0000 - val_precision: 0.9940 - val_recall: 0.9940\n",
      "Epoch 46/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0264 - accuracy: 1.0000 - precision: 0.9922 - recall: 0.9922 - val_loss: 0.0190 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 47/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0282 - accuracy: 1.0000 - precision: 0.9925 - recall: 0.9925 - val_loss: 0.0167 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 48/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0245 - accuracy: 1.0000 - precision: 0.9927 - recall: 0.9926 - val_loss: 0.0166 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 49/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0238 - accuracy: 1.0000 - precision: 0.9934 - recall: 0.9933 - val_loss: 0.0179 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 50/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0222 - accuracy: 1.0000 - precision: 0.9937 - recall: 0.9936 - val_loss: 0.0239 - val_accuracy: 1.0000 - val_precision: 0.9929 - val_recall: 0.9929\n",
      "Epoch 51/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0239 - accuracy: 1.0000 - precision: 0.9933 - recall: 0.9933 - val_loss: 0.0169 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 52/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0228 - accuracy: 1.0000 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 53/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0252 - accuracy: 1.0000 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.0204 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 54/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0228 - accuracy: 1.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.0183 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 55/100\n",
      "10080/10080 [==============================] - 21s 2ms/step - loss: 0.0258 - accuracy: 1.0000 - precision: 0.9923 - recall: 0.9923 - val_loss: 0.0155 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 56/100\n",
      "10080/10080 [==============================] - 21s 2ms/step - loss: 0.0228 - accuracy: 1.0000 - precision: 0.9930 - recall: 0.9929 - val_loss: 0.0161 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 57/100\n",
      "10080/10080 [==============================] - 21s 2ms/step - loss: 0.0217 - accuracy: 1.0000 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.0143 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 58/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0225 - accuracy: 1.0000 - precision: 0.9935 - recall: 0.9935 - val_loss: 0.0157 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 59/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0230 - accuracy: 1.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.0205 - val_accuracy: 1.0000 - val_precision: 0.9940 - val_recall: 0.9940\n",
      "Epoch 60/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0233 - accuracy: 1.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.0171 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 61/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0222 - accuracy: 1.0000 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.0152 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 62/100\n",
      "10080/10080 [==============================] - 20s 2ms/step - loss: 0.0231 - accuracy: 1.0000 - precision: 0.9931 - recall: 0.9931 - val_loss: 0.0227 - val_accuracy: 1.0000 - val_precision: 0.9925 - val_recall: 0.9925\n",
      "Epoch 63/100\n",
      "10080/10080 [==============================] - 21s 2ms/step - loss: 0.0246 - accuracy: 1.0000 - precision: 0.9933 - recall: 0.9933 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 64/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0249 - accuracy: 1.0000 - precision: 0.9935 - recall: 0.9935 - val_loss: 0.0216 - val_accuracy: 1.0000 - val_precision: 0.9933 - val_recall: 0.9933\n",
      "Epoch 65/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0250 - accuracy: 1.0000 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.0180 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 66/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0216 - accuracy: 1.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.0165 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 67/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0239 - accuracy: 1.0000 - precision: 0.9931 - recall: 0.9930 - val_loss: 0.0170 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 68/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0223 - accuracy: 1.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.0166 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 69/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0221 - accuracy: 1.0000 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.0193 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0220 - accuracy: 1.0000 - precision: 0.9932 - recall: 0.9932 - val_loss: 0.0246 - val_accuracy: 1.0000 - val_precision: 0.9929 - val_recall: 0.9929\n",
      "Epoch 71/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0225 - accuracy: 1.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.0182 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 72/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0228 - accuracy: 1.0000 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.0155 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 73/100\n",
      "10080/10080 [==============================] - 20s 2ms/step - loss: 0.0234 - accuracy: 1.0000 - precision: 0.9936 - recall: 0.9934 - val_loss: 0.0255 - val_accuracy: 1.0000 - val_precision: 0.9925 - val_recall: 0.9925\n",
      "Epoch 74/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0210 - accuracy: 1.0000 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.0227 - val_accuracy: 1.0000 - val_precision: 0.9933 - val_recall: 0.9933\n",
      "Epoch 75/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0217 - accuracy: 1.0000 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.0199 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 76/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0209 - accuracy: 1.0000 - precision: 0.9945 - recall: 0.9945 - val_loss: 0.0250 - val_accuracy: 1.0000 - val_precision: 0.9925 - val_recall: 0.9925\n",
      "Epoch 77/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0223 - accuracy: 1.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.0174 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 78/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0220 - accuracy: 1.0000 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.0158 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 79/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0198 - accuracy: 1.0000 - precision: 0.9946 - recall: 0.9946 - val_loss: 0.0156 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 80/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0206 - accuracy: 1.0000 - precision: 0.9945 - recall: 0.9945 - val_loss: 0.0163 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 81/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0218 - accuracy: 1.0000 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.0149 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 82/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0214 - accuracy: 1.0000 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.0170 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 83/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0212 - accuracy: 1.0000 - precision: 0.9946 - recall: 0.9946 - val_loss: 0.0153 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 84/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0205 - accuracy: 1.0000 - precision: 0.9947 - recall: 0.9947 - val_loss: 0.0155 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.996091 - accuracy: 1.0000 - precision: 0.994\n",
      "Epoch 85/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0220 - accuracy: 1.0000 - precision: 0.9938 - recall: 0.9937 - val_loss: 0.0226 - val_accuracy: 1.0000 - val_precision: 0.9933 - val_recall: 0.9933\n",
      "Epoch 86/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0247 - accuracy: 1.0000 - precision: 0.9932 - recall: 0.9932 - val_loss: 0.0186 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 87/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0220 - accuracy: 1.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.0269 - val_accuracy: 1.0000 - val_precision: 0.9925 - val_recall: 0.9925\n",
      "Epoch 88/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0210 - accuracy: 1.0000 - precision: 0.9934 - recall: 0.9933 - val_loss: 0.0152 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 89/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0203 - accuracy: 1.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.0147 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 90/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0239 - accuracy: 1.0000 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.0154 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 91/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0203 - accuracy: 1.0000 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.0147 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 92/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0220 - accuracy: 1.0000 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.0141 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 93/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0193 - accuracy: 1.0000 - precision: 0.9948 - recall: 0.9948 - val_loss: 0.0146 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 94/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0208 - accuracy: 1.0000 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.0188 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 95/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0188 - accuracy: 1.0000 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.0133 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 96/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0211 - accuracy: 1.0000 - precision: 0.9940 - recall: 0.9939 - val_loss: 0.0175 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 97/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0219 - accuracy: 1.0000 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.0157 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 98/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0219 - accuracy: 1.0000 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.0172 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 99/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0201 - accuracy: 1.0000 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.0151 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 100/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0197 - accuracy: 1.0000 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.0134 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\"), keras.metrics.Precision(name=\"precision\"),keras.metrics.Recall(name=\"recall\")])\n",
    "baseline_history=model.fit(X_train, Y_train, epochs=100, batch_size=50, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400/5400 [==============================] - 4s 670us/step\n",
      "Test results - Loss: 0.021241165391272968 - Accuracy: 0.9999995231628418% -Precision: 0.9933333396911621% -Recall: 0.9933333396911621%\n"
     ]
    }
   ],
   "source": [
    "# Test the model after training\n",
    "test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}% -Precision: {test_results[2]}% -Recall: {test_results[3]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for plotting\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_metrics(history):\n",
    "  metrics =  ['loss', 'accuracy','precision','recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(baseline_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores, training set [0.9980108  0.91358025] f1_scores in testing set [0.99658314 0.86363636]\n"
     ]
    }
   ],
   "source": [
    "#Computing F1-score\n",
    "train_features = np.array(X_train)\n",
    "test_features = np.array(X_test)\n",
    "train_labels=np.array(yclass_train)\n",
    "test_labels=np.array(yclass_test)\n",
    "train_predictions_baseline = model.predict_classes(train_features, batch_size=150)\n",
    "f1_train=sklearn.metrics.f1_score(train_labels, train_predictions_baseline, average=None)\n",
    "test_predictions_baseline = model.predict_classes(test_features, batch_size=150)\n",
    "f1_test=sklearn.metrics.f1_score(test_labels, test_predictions_baseline, average=None)\n",
    "print('f1_scores, training set',f1_train,'f1_scores in testing set',f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ROC curve\n",
    "fp, tp, _ = sklearn.metrics.roc_curve(train_labels, train_predictions_baseline)\n",
    "fp1, tp1, _ = sklearn.metrics.roc_curve(test_labels, test_predictions_baseline)\n",
    "roc_auc = sklearn.metrics.auc(fp,tp)\n",
    "roc_auc1 = sklearn.metrics.auc(fp1,tp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(fp, tp, 'b', label='AUC-train = %0.2f'% roc_auc)\n",
    "ax.plot(fp1, tp1, 'b--', label='AUC-test = %0.2f'% roc_auc1)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([0,1.0])\n",
    "plt.ylim([0,1.0])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyte #24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:\n",
      "(12600, 50)\n",
      "Test dimension:\n",
      "(5400, 50)\n"
     ]
    }
   ],
   "source": [
    "yclass=y.copy()\n",
    "yclass[yclass!=17]=0\n",
    "yclass[yclass==17]=1\n",
    "X_train, X_test, yclass_train, yclass_test = train_test_split(b,yclass,test_size=0.3,random_state=0)\n",
    "print('Train dimension:');print(X_train.shape)\n",
    "print('Test dimension:');print(X_test.shape)\n",
    "Y_train = to_categorical(yclass_train, num_classes)\n",
    "Y_test = to_categorical(yclass_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (50,)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               15300     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 18000)             1818000   \n",
      "=================================================================\n",
      "Total params: 1,863,400\n",
      "Trainable params: 1,863,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the input shape\n",
    "input_shape = (feature_vector_length,)\n",
    "print(f'Feature shape: {input_shape}')\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.1, input_shape=input_shape))\n",
    "model.add(Dense(300, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10080 samples, validate on 2520 samples\n",
      "Epoch 1/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.1102 - accuracy: 1.0000 - precision: 0.9762 - recall: 0.8293 - val_loss: 0.1265 - val_accuracy: 1.0000 - val_precision: 0.9746 - val_recall: 0.9746\n",
      "Epoch 2/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.1159 - accuracy: 1.0000 - precision: 0.9765 - recall: 0.9758 - val_loss: 0.1189 - val_accuracy: 1.0000 - val_precision: 0.9746 - val_recall: 0.9746\n",
      "Epoch 3/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0980 - accuracy: 1.0000 - precision: 0.9769 - recall: 0.9766 - val_loss: 0.1084 - val_accuracy: 1.0000 - val_precision: 0.9746 - val_recall: 0.9746\n",
      "Epoch 4/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0801 - accuracy: 1.0000 - precision: 0.9806 - recall: 0.9803 - val_loss: 0.0720 - val_accuracy: 1.0000 - val_precision: 0.9798 - val_recall: 0.9798\n",
      "Epoch 5/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0653 - accuracy: 1.0000 - precision: 0.9831 - recall: 0.9831 - val_loss: 0.0563 - val_accuracy: 1.0000 - val_precision: 0.9813 - val_recall: 0.9813\n",
      "Epoch 6/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0523 - accuracy: 1.0000 - precision: 0.9855 - recall: 0.9855 - val_loss: 0.0415 - val_accuracy: 1.0000 - val_precision: 0.9833 - val_recall: 0.9833\n",
      "Epoch 7/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0458 - accuracy: 1.0000 - precision: 0.9867 - recall: 0.9867 - val_loss: 0.0325 - val_accuracy: 1.0000 - val_precision: 0.9881 - val_recall: 0.9881\n",
      "Epoch 8/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0390 - accuracy: 1.0000 - precision: 0.9892 - recall: 0.9891 - val_loss: 0.0303 - val_accuracy: 1.0000 - val_precision: 0.9909 - val_recall: 0.9909\n",
      "Epoch 9/100\n",
      "10080/10080 [==============================] - 27s 3ms/step - loss: 0.0349 - accuracy: 1.0000 - precision: 0.9898 - recall: 0.9898 - val_loss: 0.0299 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 10/100\n",
      "10080/10080 [==============================] - 27s 3ms/step - loss: 0.0337 - accuracy: 1.0000 - precision: 0.9897 - recall: 0.9897 - val_loss: 0.0227 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 11/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0346 - accuracy: 1.0000 - precision: 0.9903 - recall: 0.9903 - val_loss: 0.0244 - val_accuracy: 1.0000 - val_precision: 0.9901 - val_recall: 0.9901\n",
      "Epoch 12/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0299 - accuracy: 1.0000 - precision: 0.9920 - recall: 0.9919 - val_loss: 0.0201 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 13/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0290 - accuracy: 1.0000 - precision: 0.9914 - recall: 0.9914 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 14/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0300 - accuracy: 1.0000 - precision: 0.9908 - recall: 0.9908 - val_loss: 0.0205 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 15/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0283 - accuracy: 1.0000 - precision: 0.9905 - recall: 0.9905 - val_loss: 0.0321 - val_accuracy: 1.0000 - val_precision: 0.9893 - val_recall: 0.9893\n",
      "Epoch 16/100\n",
      "10080/10080 [==============================] - 25s 2ms/step - loss: 0.0280 - accuracy: 1.0000 - precision: 0.9915 - recall: 0.9914 - val_loss: 0.0204 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 17/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0275 - accuracy: 1.0000 - precision: 0.9920 - recall: 0.9920 - val_loss: 0.0231 - val_accuracy: 1.0000 - val_precision: 0.9929 - val_recall: 0.9929\n",
      "Epoch 18/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0271 - accuracy: 1.0000 - precision: 0.9925 - recall: 0.9923 - val_loss: 0.0242 - val_accuracy: 1.0000 - val_precision: 0.9921 - val_recall: 0.9921\n",
      "Epoch 19/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0265 - accuracy: 1.0000 - precision: 0.9918 - recall: 0.9917 - val_loss: 0.0245 - val_accuracy: 1.0000 - val_precision: 0.9933 - val_recall: 0.9933\n",
      "Epoch 20/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0240 - accuracy: 1.0000 - precision: 0.9927 - recall: 0.9926 - val_loss: 0.0239 - val_accuracy: 1.0000 - val_precision: 0.9921 - val_recall: 0.9921\n",
      "Epoch 21/100\n",
      "10080/10080 [==============================] - 25s 3ms/step - loss: 0.0267 - accuracy: 1.0000 - precision: 0.9919 - recall: 0.9919 - val_loss: 0.0211 - val_accuracy: 1.0000 - val_precision: 0.9933 - val_recall: 0.9933\n",
      "Epoch 22/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0276 - accuracy: 1.0000 - precision: 0.9920 - recall: 0.9920 - val_loss: 0.0211 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 23/100\n",
      "10080/10080 [==============================] - 26s 3ms/step - loss: 0.0264 - accuracy: 1.0000 - precision: 0.9924 - recall: 0.9923 - val_loss: 0.0226 - val_accuracy: 1.0000 - val_precision: 0.9933 - val_recall: 0.9933\n",
      "Epoch 24/100\n",
      "10080/10080 [==============================] - 25s 3ms/step - loss: 0.0274 - accuracy: 1.0000 - precision: 0.9919 - recall: 0.9919 - val_loss: 0.0161 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 25/100\n",
      "10080/10080 [==============================] - 25s 2ms/step - loss: 0.0260 - accuracy: 1.0000 - precision: 0.9932 - recall: 0.9932 - val_loss: 0.0209 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 26/100\n",
      "10080/10080 [==============================] - 25s 2ms/step - loss: 0.0237 - accuracy: 1.0000 - precision: 0.9925 - recall: 0.9924 - val_loss: 0.0315 - val_accuracy: 1.0000 - val_precision: 0.9933 - val_recall: 0.9933\n",
      "Epoch 27/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0276 - accuracy: 1.0000 - precision: 0.9920 - recall: 0.9920 - val_loss: 0.0172 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 28/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0251 - accuracy: 1.0000 - precision: 0.9914 - recall: 0.9913 - val_loss: 0.0171 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 29/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0270 - accuracy: 1.0000 - precision: 0.9926 - recall: 0.9926 - val_loss: 0.0183 - val_accuracy: 1.0000 - val_precision: 0.9940 - val_recall: 0.9940\n",
      "Epoch 30/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0249 - accuracy: 1.0000 - precision: 0.9925 - recall: 0.9925 - val_loss: 0.0202 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9952\n",
      "Epoch 31/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0248 - accuracy: 1.0000 - precision: 0.9923 - recall: 0.9922 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 32/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0259 - accuracy: 1.0000 - precision: 0.9926 - recall: 0.9926 - val_loss: 0.0160 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 33/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0244 - accuracy: 1.0000 - precision: 0.9931 - recall: 0.9930 - val_loss: 0.0192 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 34/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0275 - accuracy: 1.0000 - precision: 0.9922 - recall: 0.9921 - val_loss: 0.0198 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 35/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0238 - accuracy: 1.0000 - precision: 0.9926 - recall: 0.9926 - val_loss: 0.0181 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 36/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0244 - accuracy: 1.0000 - precision: 0.9930 - recall: 0.9929 - val_loss: 0.0212 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 37/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0221 - accuracy: 1.0000 - precision: 0.9932 - recall: 0.9930 - val_loss: 0.0234 - val_accuracy: 1.0000 - val_precision: 0.9925 - val_recall: 0.9925\n",
      "Epoch 38/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0225 - accuracy: 1.0000 - precision: 0.9932 - recall: 0.9932 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9952\n",
      "Epoch 39/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0229 - accuracy: 1.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.0183 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9960\n",
      "Epoch 40/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0234 - accuracy: 1.0000 - precision: 0.9932 - recall: 0.9932 - val_loss: 0.0180 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 41/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0222 - accuracy: 1.0000 - precision: 0.9931 - recall: 0.9931 - val_loss: 0.0267 - val_accuracy: 1.0000 - val_precision: 0.9913 - val_recall: 0.9913\n",
      "Epoch 42/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0226 - accuracy: 1.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.0190 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9944\n",
      "Epoch 43/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0234 - accuracy: 1.0000 - precision: 0.9929 - recall: 0.9926 - val_loss: 0.0318 - val_accuracy: 1.0000 - val_precision: 0.9905 - val_recall: 0.9905\n",
      "Epoch 44/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0255 - accuracy: 1.0000 - precision: 0.9928 - recall: 0.9926 - val_loss: 0.0201 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 45/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0222 - accuracy: 1.0000 - precision: 0.9931 - recall: 0.9931 - val_loss: 0.0174 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 46/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0229 - accuracy: 1.0000 - precision: 0.9923 - recall: 0.9923 - val_loss: 0.0215 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9944\n",
      "Epoch 47/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0225 - accuracy: 1.0000 - precision: 0.9935 - recall: 0.9934 - val_loss: 0.0150 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 48/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0227 - accuracy: 1.0000 - precision: 0.9931 - recall: 0.9931 - val_loss: 0.0151 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 49/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0223 - accuracy: 1.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.0171 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 50/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0220 - accuracy: 1.0000 - precision: 0.9932 - recall: 0.9932 - val_loss: 0.0179 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9944\n",
      "Epoch 51/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0239 - accuracy: 1.0000 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.0181 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 52/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0240 - accuracy: 1.0000 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.0164 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 53/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0216 - accuracy: 1.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.0225 - val_accuracy: 1.0000 - val_precision: 0.9933 - val_recall: 0.9933\n",
      "Epoch 54/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0214 - accuracy: 1.0000 - precision: 0.9937 - recall: 0.9936 - val_loss: 0.0159 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 55/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0216 - accuracy: 1.0000 - precision: 0.9933 - recall: 0.9933 - val_loss: 0.0187 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 56/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0213 - accuracy: 1.0000 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.0180 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 57/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0235 - accuracy: 1.0000 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.0225 - val_accuracy: 1.0000 - val_precision: 0.9940 - val_recall: 0.9940\n",
      "Epoch 58/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0221 - accuracy: 1.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.0153 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 59/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0223 - accuracy: 1.0000 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.0187 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 60/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0224 - accuracy: 1.0000 - precision: 0.9932 - recall: 0.9932 - val_loss: 0.0161 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 61/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0224 - accuracy: 1.0000 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.0155 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 62/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0201 - accuracy: 1.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.0170 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 63/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0199 - accuracy: 1.0000 - precision: 0.9943 - recall: 0.9943 - val_loss: 0.0164 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 64/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0199 - accuracy: 1.0000 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.0172 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 65/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0195 - accuracy: 1.0000 - precision: 0.9932 - recall: 0.9932 - val_loss: 0.0171 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 66/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0218 - accuracy: 1.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.0182 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 67/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0191 - accuracy: 1.0000 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.0164 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 68/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0192 - accuracy: 1.0000 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.0173 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 69/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0225 - accuracy: 1.0000 - precision: 0.9931 - recall: 0.9930 - val_loss: 0.0171 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 70/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0178 - accuracy: 1.0000 - precision: 0.9945 - recall: 0.9945 - val_loss: 0.0188 - val_accuracy: 1.0000 - val_precision: 0.9940 - val_recall: 0.9940\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0220 - accuracy: 1.0000 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.0163 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 72/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0187 - accuracy: 1.0000 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.0177 - val_accuracy: 1.0000 - val_precision: 0.9948 - val_recall: 0.9948\n",
      "Epoch 73/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0217 - accuracy: 1.0000 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.0169 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 74/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0189 - accuracy: 1.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.0174 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 75/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0169 - accuracy: 1.0000 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.0160 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 76/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0180 - accuracy: 1.0000 - precision: 0.9946 - recall: 0.9946 - val_loss: 0.0175 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 77/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0185 - accuracy: 1.0000 - precision: 0.9946 - recall: 0.9946 - val_loss: 0.0171 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 78/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0186 - accuracy: 1.0000 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.0159 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 79/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0187 - accuracy: 1.0000 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.0163 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 80/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0179 - accuracy: 1.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.0139 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 81/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0185 - accuracy: 1.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.0166 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 82/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0201 - accuracy: 1.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.0152 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 83/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0193 - accuracy: 1.0000 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.0133 - val_accuracy: 1.0000 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 84/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0184 - accuracy: 1.0000 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0169 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 85/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0176 - accuracy: 1.0000 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.0137 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 86/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0170 - accuracy: 1.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.0148 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 87/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0184 - accuracy: 1.0000 - precision: 0.9943 - recall: 0.9943 - val_loss: 0.0150 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 88/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0197 - accuracy: 1.0000 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.0158 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 89/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0172 - accuracy: 1.0000 - precision: 0.9951 - recall: 0.9951 - val_loss: 0.0203 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9948\n",
      "Epoch 90/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0182 - accuracy: 1.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.0175 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 91/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0179 - accuracy: 1.0000 - precision: 0.9938 - recall: 0.9937 - val_loss: 0.0205 - val_accuracy: 1.0000 - val_precision: 0.9960 - val_recall: 0.9960\n",
      "Epoch 92/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0182 - accuracy: 1.0000 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0177 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 93/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0181 - accuracy: 1.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.0156 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 94/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0194 - accuracy: 1.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.0146 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 95/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0184 - accuracy: 1.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.0143 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 96/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0160 - accuracy: 1.0000 - precision: 0.9949 - recall: 0.9949 - val_loss: 0.0139 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n",
      "Epoch 97/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0178 - accuracy: 1.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.0155 - val_accuracy: 1.0000 - val_precision: 0.9952 - val_recall: 0.9952\n",
      "Epoch 98/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0167 - accuracy: 1.0000 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.0150 - val_accuracy: 1.0000 - val_precision: 0.9956 - val_recall: 0.9956\n",
      "Epoch 99/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0169 - accuracy: 1.0000 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.0148 - val_accuracy: 1.0000 - val_precision: 0.9968 - val_recall: 0.9968\n",
      "Epoch 100/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0179 - accuracy: 1.0000 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.0130 - val_accuracy: 1.0000 - val_precision: 0.9964 - val_recall: 0.9964\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\"), keras.metrics.Precision(name=\"precision\"),keras.metrics.Recall(name=\"recall\")])\n",
    "baseline_history=model.fit(X_train, Y_train, epochs=100, batch_size=50, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400/5400 [==============================] - 3s 544us/step\n",
      "Test results - Loss: 0.013717163269994436 - Accuracy: 0.9999997019767761% -Precision: 0.9951851963996887% -Recall: 0.9951851963996887%\n"
     ]
    }
   ],
   "source": [
    "# Test the model after training\n",
    "test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}% -Precision: {test_results[2]}% -Recall: {test_results[3]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores, training set [0.99805132 0.91549296] f1_scores in testing set [0.99752852 0.90714286]\n"
     ]
    }
   ],
   "source": [
    "#Computing F1-score\n",
    "train_features = np.array(X_train)\n",
    "test_features = np.array(X_test)\n",
    "train_labels=np.array(yclass_train)\n",
    "test_labels=np.array(yclass_test)\n",
    "train_predictions_baseline = model.predict_classes(train_features, batch_size=150)\n",
    "f1_train=sklearn.metrics.f1_score(train_labels, train_predictions_baseline, average=None)\n",
    "test_predictions_baseline = model.predict_classes(test_features, batch_size=150)\n",
    "f1_test=sklearn.metrics.f1_score(test_labels, test_predictions_baseline, average=None)\n",
    "print('f1_scores, training set',f1_train,'f1_scores in testing set',f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
