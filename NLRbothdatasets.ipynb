{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf7e561",
   "metadata": {},
   "source": [
    "### Using 55-analytes dataset as training dataset and 40-analytes dataset as testing dataset\n",
    "### July 27,  2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "73e6908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mat = scipy.io.loadmat('C:/Users/eacun/Downloads/dataset55_release2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7029a604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('__header__', b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Jul 22 14:13:11 2020'), ('__version__', '1.0'), ('__globals__', []), ('addedNoisePercent', array([[0.1],\n",
       "       [0.5],\n",
       "       [0. ],\n",
       "       ...,\n",
       "       [1. ],\n",
       "       [0.1],\n",
       "       [0. ]])), ('labels', array([[ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       ...,\n",
       "       [55],\n",
       "       [55],\n",
       "       [55]], dtype=uint8)), ('massLoadings', array([[90.48134734],\n",
       "       [90.48134734],\n",
       "       [90.48134734],\n",
       "       ...,\n",
       "       [93.56603952],\n",
       "       [93.56603952],\n",
       "       [93.56603952]])), ('spectra', array([[0.01684698, 0.01575019, 0.01553012, ..., 0.01631328, 0.01523777,\n",
       "        0.01464116],\n",
       "       [0.01862416, 0.01217942, 0.02092375, ..., 0.01522821, 0.02158774,\n",
       "        0.01224737],\n",
       "       [0.01634829, 0.01627708, 0.01620733, ..., 0.01681628, 0.01679286,\n",
       "        0.0167685 ],\n",
       "       ...,\n",
       "       [0.01777366, 0.02470746, 0.04042846, ..., 0.52899222, 0.53342443,\n",
       "        0.54125978],\n",
       "       [0.03112273, 0.02996503, 0.03299245, ..., 0.54179967, 0.53942979,\n",
       "        0.54275879],\n",
       "       [0.03236588, 0.0324536 , 0.03238276, ..., 0.54378712, 0.54383177,\n",
       "        0.54386556]])), ('substrateIDs', array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [8],\n",
       "       [8],\n",
       "       [8]], dtype=uint8)), ('substrateSpectra', array([[0.008192, 0.008116, 0.008042, ..., 0.010792, 0.010765, 0.010737],\n",
       "       [0.035105, 0.035617, 0.036458, ..., 0.041036, 0.041051, 0.04107 ],\n",
       "       [0.585617, 0.585672, 0.585179, ..., 0.559301, 0.559264, 0.55923 ],\n",
       "       ...,\n",
       "       [0.035515, 0.035251, 0.034737, ..., 0.247776, 0.246856, 0.245963],\n",
       "       [0.031312, 0.031438, 0.031556, ..., 0.569884, 0.56993 , 0.569966],\n",
       "       [0.00088 , 0.001132, 0.004165, ..., 0.008746, 0.008464, 0.008364]]))])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aefc9570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       ...,\n",
       "       [55],\n",
       "       [55],\n",
       "       [55]], dtype=uint8)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=mat['labels']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b0e0d99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49500, 1701)\n"
     ]
    }
   ],
   "source": [
    "df=mat['spectra']\n",
    "df=pd.DataFrame(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6de54b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass=mat['massLoadings']\n",
    "noise=mat[\"addedNoisePercent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "84abd2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys=mat['substrateIDs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0ecceaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008192</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.007830</td>\n",
       "      <td>0.007763</td>\n",
       "      <td>0.007697</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.010943</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>0.010895</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010845</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.010792</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.010737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035105</td>\n",
       "      <td>0.035617</td>\n",
       "      <td>0.036458</td>\n",
       "      <td>0.037003</td>\n",
       "      <td>0.037084</td>\n",
       "      <td>0.036102</td>\n",
       "      <td>0.035552</td>\n",
       "      <td>0.035033</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040834</td>\n",
       "      <td>0.040778</td>\n",
       "      <td>0.040760</td>\n",
       "      <td>0.040794</td>\n",
       "      <td>0.040865</td>\n",
       "      <td>0.040946</td>\n",
       "      <td>0.041008</td>\n",
       "      <td>0.041036</td>\n",
       "      <td>0.041051</td>\n",
       "      <td>0.041070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585617</td>\n",
       "      <td>0.585672</td>\n",
       "      <td>0.585179</td>\n",
       "      <td>0.584104</td>\n",
       "      <td>0.585759</td>\n",
       "      <td>0.587581</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.589407</td>\n",
       "      <td>0.590642</td>\n",
       "      <td>0.591676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559620</td>\n",
       "      <td>0.559569</td>\n",
       "      <td>0.559520</td>\n",
       "      <td>0.559472</td>\n",
       "      <td>0.559426</td>\n",
       "      <td>0.559382</td>\n",
       "      <td>0.559341</td>\n",
       "      <td>0.559301</td>\n",
       "      <td>0.559264</td>\n",
       "      <td>0.559230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026414</td>\n",
       "      <td>0.026214</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>0.025770</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.025250</td>\n",
       "      <td>0.025171</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>0.025165</td>\n",
       "      <td>0.025351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546925</td>\n",
       "      <td>0.547225</td>\n",
       "      <td>0.547537</td>\n",
       "      <td>0.547909</td>\n",
       "      <td>0.548301</td>\n",
       "      <td>0.548652</td>\n",
       "      <td>0.548971</td>\n",
       "      <td>0.549233</td>\n",
       "      <td>0.549387</td>\n",
       "      <td>0.549484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011060</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.011618</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023413</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>0.023243</td>\n",
       "      <td>0.023115</td>\n",
       "      <td>0.023055</td>\n",
       "      <td>0.023158</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.023359</td>\n",
       "      <td>0.023251</td>\n",
       "      <td>0.023180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.064528</td>\n",
       "      <td>0.064613</td>\n",
       "      <td>0.064131</td>\n",
       "      <td>0.063398</td>\n",
       "      <td>0.062792</td>\n",
       "      <td>0.062214</td>\n",
       "      <td>0.061542</td>\n",
       "      <td>0.060586</td>\n",
       "      <td>0.059307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277668</td>\n",
       "      <td>0.277010</td>\n",
       "      <td>0.276353</td>\n",
       "      <td>0.275671</td>\n",
       "      <td>0.274983</td>\n",
       "      <td>0.274299</td>\n",
       "      <td>0.273613</td>\n",
       "      <td>0.272943</td>\n",
       "      <td>0.272329</td>\n",
       "      <td>0.271673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.035515</td>\n",
       "      <td>0.035251</td>\n",
       "      <td>0.034737</td>\n",
       "      <td>0.034093</td>\n",
       "      <td>0.033518</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>0.032536</td>\n",
       "      <td>0.032043</td>\n",
       "      <td>0.031658</td>\n",
       "      <td>0.031341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253511</td>\n",
       "      <td>0.252787</td>\n",
       "      <td>0.252041</td>\n",
       "      <td>0.251235</td>\n",
       "      <td>0.250392</td>\n",
       "      <td>0.249560</td>\n",
       "      <td>0.248698</td>\n",
       "      <td>0.247776</td>\n",
       "      <td>0.246856</td>\n",
       "      <td>0.245963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.031312</td>\n",
       "      <td>0.031438</td>\n",
       "      <td>0.031556</td>\n",
       "      <td>0.031777</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.031608</td>\n",
       "      <td>0.031588</td>\n",
       "      <td>0.031441</td>\n",
       "      <td>0.031011</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569969</td>\n",
       "      <td>0.569996</td>\n",
       "      <td>0.570024</td>\n",
       "      <td>0.570030</td>\n",
       "      <td>0.570001</td>\n",
       "      <td>0.569943</td>\n",
       "      <td>0.569884</td>\n",
       "      <td>0.569884</td>\n",
       "      <td>0.569930</td>\n",
       "      <td>0.569966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010077</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.010808</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.009309</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.008364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 1701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.008192  0.008116  0.008042  0.007970  0.007899  0.007830  0.007763   \n",
       "1  0.035105  0.035617  0.036458  0.037003  0.037084  0.036102  0.035552   \n",
       "2  0.585617  0.585672  0.585179  0.584104  0.585759  0.587581  0.588336   \n",
       "3  0.026414  0.026214  0.026014  0.025770  0.025449  0.025250  0.025171   \n",
       "4  0.011060  0.011381  0.011618  0.011406  0.010922  0.010713  0.010692   \n",
       "5  0.064400  0.064528  0.064613  0.064131  0.063398  0.062792  0.062214   \n",
       "6  0.035515  0.035251  0.034737  0.034093  0.033518  0.033043  0.032536   \n",
       "7  0.031312  0.031438  0.031556  0.031777  0.031780  0.031608  0.031588   \n",
       "8  0.000880  0.001132  0.004165  0.006112  0.005633  0.004667  0.003701   \n",
       "\n",
       "       7         8         9     ...      1691      1692      1693      1694  \\\n",
       "0  0.007697  0.007633  0.007570  ...  0.010966  0.010943  0.010919  0.010895   \n",
       "1  0.035033  0.034687  0.034424  ...  0.040834  0.040778  0.040760  0.040794   \n",
       "2  0.589407  0.590642  0.591676  ...  0.559620  0.559569  0.559520  0.559472   \n",
       "3  0.025119  0.025165  0.025351  ...  0.546925  0.547225  0.547537  0.547909   \n",
       "4  0.010628  0.010722  0.010908  ...  0.023413  0.023356  0.023243  0.023115   \n",
       "5  0.061542  0.060586  0.059307  ...  0.277668  0.277010  0.276353  0.275671   \n",
       "6  0.032043  0.031658  0.031341  ...  0.253511  0.252787  0.252041  0.251235   \n",
       "7  0.031441  0.031011  0.030551  ...  0.569969  0.569996  0.570024  0.570030   \n",
       "8  0.002964  0.002877  0.002152  ...  0.010077  0.010496  0.010808  0.010552   \n",
       "\n",
       "       1695      1696      1697      1698      1699      1700  \n",
       "0  0.010870  0.010845  0.010818  0.010792  0.010765  0.010737  \n",
       "1  0.040865  0.040946  0.041008  0.041036  0.041051  0.041070  \n",
       "2  0.559426  0.559382  0.559341  0.559301  0.559264  0.559230  \n",
       "3  0.548301  0.548652  0.548971  0.549233  0.549387  0.549484  \n",
       "4  0.023055  0.023158  0.023328  0.023359  0.023251  0.023180  \n",
       "5  0.274983  0.274299  0.273613  0.272943  0.272329  0.271673  \n",
       "6  0.250392  0.249560  0.248698  0.247776  0.246856  0.245963  \n",
       "7  0.570001  0.569943  0.569884  0.569884  0.569930  0.569966  \n",
       "8  0.010001  0.009687  0.009309  0.008746  0.008464  0.008364  \n",
       "\n",
       "[9 rows x 1701 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs=mat['substrateSpectra']\n",
    "subs=pd.DataFrame(subs)\n",
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "82ac2f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49500, 1705)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfset2=df.copy()\n",
    "dfset2['Analyte']=y\n",
    "dfset2['substrate']=ys\n",
    "dfset2['MassLoadings']=mass\n",
    "dfset2['AddedNoisePerc']=noise\n",
    "dfset2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26747d",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a13a4372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22030, 1705)\n"
     ]
    }
   ],
   "source": [
    "#hard=[27,30,40,55]\n",
    "#dfset2=dfset2[-dfset2[\"Analyte\"].isin(hard)]\n",
    "crit1=dfset2['MassLoadings']<50\n",
    "#crit2=dfset2['AddedNoisePerc']>10\n",
    "#dfset2.head()\n",
    "dfset2=dfset2[crit1]\n",
    "crit2=dfset2['MassLoadings']>5\n",
    "dfset2=dfset2[crit2]\n",
    "print(dfset2.shape)\n",
    "#dfset2.MassLoadings.describe()\n",
    "#dfset2['Analyte'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c8dfa5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub1=dfset2[dfset2['substrate']==1]\n",
    "dfsub2=dfset2[dfset2['substrate']==2]\n",
    "dfsub3=dfset2[dfset2['substrate']==3]\n",
    "dfsub4=dfset2[dfset2['substrate']==4]\n",
    "dfsub5=dfset2[dfset2['substrate']==5]\n",
    "dfsub6=dfset2[dfset2['substrate']==6]\n",
    "dfsub7=dfset2[dfset2['substrate']==7]\n",
    "dfsub8=dfset2[dfset2['substrate']==8]\n",
    "dfsub9=dfset2[dfset2['substrate']==9]\n",
    "#dfset1=pd.DataFrame(dfset1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d5903",
   "metadata": {},
   "source": [
    "### Substrate's effect correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6532fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfsub1=dfsub1.iloc[:,0:1701]\n",
    "mdfsub2=dfsub2.iloc[:,0:1701]\n",
    "mdfsub3=dfsub3.iloc[:,0:1701]\n",
    "mdfsub4=dfsub4.iloc[:,0:1701]\n",
    "mdfsub5=dfsub5.iloc[:,0:1701]\n",
    "mdfsub6=dfsub6.iloc[:,0:1701]\n",
    "mdfsub7=dfsub7.iloc[:,0:1701]\n",
    "mdfsub8=dfsub8.iloc[:,0:1701]\n",
    "mdfsub9=dfsub9.iloc[:,0:1701]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f5628ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1701)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cf975ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=subs.loc[0,:]\n",
    "s2=subs.loc[1,:]\n",
    "s3=subs.loc[2,:]\n",
    "s4=subs.loc[3,:]\n",
    "s5=subs.loc[4,:]\n",
    "s6=subs.loc[5,:]\n",
    "s7=subs.loc[6,:]\n",
    "s8=subs.loc[7,:]\n",
    "s9=subs.loc[8,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d8c6c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "modsub1=mdfsub1.apply(lambda x : x -(np.sum(np.array(x)*np.array(s1))/np.sum(np.array(s1)*np.array(s1)))*s1,axis=1)\n",
    "modsub2=mdfsub2.apply(lambda x : x -(np.sum(np.array(x)*np.array(s2))/np.sum(np.array(s2)*np.array(s2)))*s2,axis=1)\n",
    "modsub3=mdfsub3.apply(lambda x : x -(np.sum(np.array(x)*np.array(s3))/np.sum(np.array(s3)*np.array(s3)))*s3,axis=1)\n",
    "modsub4=mdfsub4.apply(lambda x : x -(np.sum(np.array(x)*np.array(s4))/np.sum(np.array(s4)*np.array(s4)))*s4,axis=1)\n",
    "modsub5=mdfsub5.apply(lambda x : x -(np.sum(np.array(x)*np.array(s5))/np.sum(np.array(s5)*np.array(s5)))*s5,axis=1)\n",
    "modsub6=mdfsub6.apply(lambda x : x -(np.sum(np.array(x)*np.array(s6))/np.sum(np.array(s6)*np.array(s6)))*s6,axis=1)\n",
    "modsub7=mdfsub7.apply(lambda x : x -(np.sum(np.array(x)*np.array(s7))/np.sum(np.array(s7)*np.array(s7)))*s7,axis=1)\n",
    "modsub8=mdfsub8.apply(lambda x : x -(np.sum(np.array(x)*np.array(s8))/np.sum(np.array(s8)*np.array(s8)))*s8,axis=1)\n",
    "modsub9=mdfsub9.apply(lambda x : x -(np.sum(np.array(x)*np.array(s9))/np.sum(np.array(s9)*np.array(s9)))*s9,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "95e7b8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001170</td>\n",
       "      <td>-0.001161</td>\n",
       "      <td>-0.001153</td>\n",
       "      <td>-0.001144</td>\n",
       "      <td>-0.001135</td>\n",
       "      <td>-0.001126</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>-0.001107</td>\n",
       "      <td>-0.001097</td>\n",
       "      <td>-0.001087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>-0.001079</td>\n",
       "      <td>-0.001072</td>\n",
       "      <td>-0.001064</td>\n",
       "      <td>-0.001057</td>\n",
       "      <td>-0.001049</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>-0.001033</td>\n",
       "      <td>-0.001025</td>\n",
       "      <td>-0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>-0.006850</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>-0.001021</td>\n",
       "      <td>-0.001588</td>\n",
       "      <td>-0.001298</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005334</td>\n",
       "      <td>-0.002616</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.004403</td>\n",
       "      <td>-0.003833</td>\n",
       "      <td>-0.000457</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>-0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.003182</td>\n",
       "      <td>-0.003302</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>-0.003019</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>-0.006302</td>\n",
       "      <td>-0.000598</td>\n",
       "      <td>-0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.013545</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.011527</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>-0.003192</td>\n",
       "      <td>0.015883</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>0.012369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.008603</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>-0.008864</td>\n",
       "      <td>0.018592</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>-0.014096</td>\n",
       "      <td>-0.011350</td>\n",
       "      <td>-0.005666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "60  0.000386  0.000408  0.000429  0.000449  0.000468  0.000470  0.000451   \n",
       "61  0.000324  0.000344  0.000363  0.000381  0.000398  0.000401  0.000385   \n",
       "62  0.000129  0.003153  0.003458 -0.006850 -0.000848 -0.001021 -0.001588   \n",
       "63  0.003109  0.002209 -0.001824  0.003783  0.000274 -0.003182 -0.003302   \n",
       "64 -0.013545  0.013857  0.007351  0.001239  0.011527 -0.001279 -0.003192   \n",
       "\n",
       "        7         8         9     ...      1691      1692      1693      1694  \\\n",
       "60  0.000433  0.000453  0.000504  ... -0.001170 -0.001161 -0.001153 -0.001144   \n",
       "61  0.000370  0.000388  0.000434  ... -0.001086 -0.001079 -0.001072 -0.001064   \n",
       "62 -0.001298  0.005516  0.002293  ... -0.005334 -0.002616  0.000887 -0.000122   \n",
       "63 -0.001582  0.000320  0.003344  ... -0.000398  0.001017  0.001215  0.000245   \n",
       "64  0.015883 -0.000459  0.012369  ... -0.000226 -0.008603 -0.012210  0.003325   \n",
       "\n",
       "        1695      1696      1697      1698      1699      1700  \n",
       "60 -0.001135 -0.001126 -0.001116 -0.001107 -0.001097 -0.001087  \n",
       "61 -0.001057 -0.001049 -0.001041 -0.001033 -0.001025 -0.001017  \n",
       "62 -0.000927 -0.004403 -0.003833 -0.000457  0.001131 -0.002453  \n",
       "63  0.002858 -0.003019  0.001533 -0.006302 -0.000598 -0.000801  \n",
       "64 -0.008864  0.018592  0.002939 -0.014096 -0.011350 -0.005666  \n",
       "\n",
       "[5 rows x 1701 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf=[modsub1,modsub2,modsub3,modsub4,modsub5,modsub6,modsub7,modsub8,modsub9]\n",
    "cent_subs=pd.concat(subdf)\n",
    "cent_subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a5e4c570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001170</td>\n",
       "      <td>-0.001161</td>\n",
       "      <td>-0.001153</td>\n",
       "      <td>-0.001144</td>\n",
       "      <td>-0.001135</td>\n",
       "      <td>-0.001126</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>-0.001107</td>\n",
       "      <td>-0.001097</td>\n",
       "      <td>-0.001087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>-0.001079</td>\n",
       "      <td>-0.001072</td>\n",
       "      <td>-0.001064</td>\n",
       "      <td>-0.001057</td>\n",
       "      <td>-0.001049</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>-0.001033</td>\n",
       "      <td>-0.001025</td>\n",
       "      <td>-0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>-0.006850</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>-0.001021</td>\n",
       "      <td>-0.001588</td>\n",
       "      <td>-0.001298</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005334</td>\n",
       "      <td>-0.002616</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.004403</td>\n",
       "      <td>-0.003833</td>\n",
       "      <td>-0.000457</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>-0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.003182</td>\n",
       "      <td>-0.003302</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>-0.003019</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>-0.006302</td>\n",
       "      <td>-0.000598</td>\n",
       "      <td>-0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.013545</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.011527</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>-0.003192</td>\n",
       "      <td>0.015883</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>0.012369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.008603</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>-0.008864</td>\n",
       "      <td>0.018592</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>-0.014096</td>\n",
       "      <td>-0.011350</td>\n",
       "      <td>-0.005666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "60  0.000386  0.000408  0.000429  0.000449  0.000468  0.000470  0.000451   \n",
       "61  0.000324  0.000344  0.000363  0.000381  0.000398  0.000401  0.000385   \n",
       "62  0.000129  0.003153  0.003458 -0.006850 -0.000848 -0.001021 -0.001588   \n",
       "63  0.003109  0.002209 -0.001824  0.003783  0.000274 -0.003182 -0.003302   \n",
       "64 -0.013545  0.013857  0.007351  0.001239  0.011527 -0.001279 -0.003192   \n",
       "\n",
       "        7         8         9     ...      1691      1692      1693      1694  \\\n",
       "60  0.000433  0.000453  0.000504  ... -0.001170 -0.001161 -0.001153 -0.001144   \n",
       "61  0.000370  0.000388  0.000434  ... -0.001086 -0.001079 -0.001072 -0.001064   \n",
       "62 -0.001298  0.005516  0.002293  ... -0.005334 -0.002616  0.000887 -0.000122   \n",
       "63 -0.001582  0.000320  0.003344  ... -0.000398  0.001017  0.001215  0.000245   \n",
       "64  0.015883 -0.000459  0.012369  ... -0.000226 -0.008603 -0.012210  0.003325   \n",
       "\n",
       "        1695      1696      1697      1698      1699      1700  \n",
       "60 -0.001135 -0.001126 -0.001116 -0.001107 -0.001097 -0.001087  \n",
       "61 -0.001057 -0.001049 -0.001041 -0.001033 -0.001025 -0.001017  \n",
       "62 -0.000927 -0.004403 -0.003833 -0.000457  0.001131 -0.002453  \n",
       "63  0.002858 -0.003019  0.001533 -0.006302 -0.000598 -0.000801  \n",
       "64 -0.008864  0.018592  0.002939 -0.014096 -0.011350 -0.005666  \n",
       "\n",
       "[5 rows x 1701 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "b=cent_subs.iloc[:,0:1701]\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b0251c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22030, 1701)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize(b)\n",
    "b1=b.apply(lambda x: x/(x**2).sum()**.5, axis=1)\n",
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8c03d443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempo=b1.iloc[55,0:1701]\n",
    "(tempo**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0aad1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=np.array(dfsub1['Analyte'].values.tolist())\n",
    "a2=np.array(dfsub2['Analyte'].values.tolist())\n",
    "a3=np.array(dfsub3['Analyte'].values.tolist())\n",
    "a4=np.array(dfsub4['Analyte'].values.tolist())\n",
    "a5=np.array(dfsub5['Analyte'].values.tolist())\n",
    "a6=np.array(dfsub6['Analyte'].values.tolist())\n",
    "a7=np.array(dfsub7['Analyte'].values.tolist())\n",
    "a8=np.array(dfsub8['Analyte'].values.tolist())\n",
    "a9=np.array(dfsub9['Analyte'].values.tolist())\n",
    "y=np.concatenate((a1,a2,a3,a4,a5,a6,a7,a8,a9),axis=None)\n",
    "#print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a258b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
      "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
      "       52, 53, 54, 55]), array([400, 380, 400, 430, 480, 500, 450, 430, 390, 350, 430, 350, 430,\n",
      "       420, 470, 390, 400, 340, 380, 340, 310, 420, 430, 380, 370, 350,\n",
      "       420, 300, 450, 370, 330, 320, 400, 430, 380, 370, 430, 400, 380,\n",
      "       420, 400, 450, 400, 430, 430, 320, 400, 470, 430, 370, 390, 430,\n",
      "       430, 390, 470], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y,return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb81ae",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cee74b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=78.05%\n",
      "k=3, accuracy=78.23%\n",
      "k=5, accuracy=78.12%\n",
      "k=7, accuracy=77.42%\n",
      "k=9, accuracy=75.69%\n",
      "k=11, accuracy=74.06%\n",
      "k=13, accuracy=71.88%\n",
      "k=15, accuracy=69.68%\n",
      "k=17, accuracy=67.75%\n",
      "k=19, accuracy=66.43%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# We will find by inspection the best k according to the classifier accuracy on the test set\n",
    "accuracies = []\n",
    "kVals = range(1, 20, 2)\n",
    "X=b1.iloc[:,0:1701]\n",
    "# We will find by inspection the best k according to the classifier accuracy on the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "for k in range(1, 20, 2):\n",
    "    # Entrenar el clasificador  con el valor actual de  `k`\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar los modelos e imprimiendo sus predicciones\n",
    "    score = neigh.score(X_test, y_test)\n",
    "    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "    accuracies.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "98f5b71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3 gave the best accuracy 78.23%\n"
     ]
    }
   ],
   "source": [
    "# Hallando el k para el cual la precision es mayor\n",
    "i = np.argmax(accuracies)\n",
    "print(\"k=%d gave the best accuracy %.2f%%\" % (kVals[i],\n",
    "    accuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "31dd8128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy estimated by resubstitution 0.8541534271448026\n",
      "--- 3.263550281524658 seconds ---\n",
      "The accuracy is= 0.7823422605537903\n"
     ]
    }
   ],
   "source": [
    "#metrics for k=13\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, roc_auc_score\n",
    "neigh = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "X=b1.iloc[:,0:1701]\n",
    "neigh.fit(X, y) \n",
    "print(\"Accuracy estimated by resubstitution\", neigh.score(X,y))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "start_time = time.time()\n",
    "neigh = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "neigh.fit(X_train, y_train) \n",
    "#Calculating  metrics of prediction\n",
    "predictions = neigh.predict(X_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"The accuracy is=\",neigh.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a34466db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82926829 0.66197183 0.91463415 0.7195122  0.9009901  0.91509434\n",
      " 0.80952381 0.72619048 0.84285714 0.73333333 0.8625     0.76923077\n",
      " 0.79166667 0.76086957 0.77906977 0.67123288 0.76829268 0.72368421\n",
      " 0.7972973  0.78378378 0.78688525 0.8115942  0.89690722 0.78082192\n",
      " 0.82758621 0.61971831 0.66315789 0.72222222 0.69791667 0.78125\n",
      " 0.890625   0.71698113 0.63013699 0.7816092  0.82926829 0.83333333\n",
      " 0.82352941 0.77380952 0.56140351 0.69411765 0.86904762 0.74117647\n",
      " 0.89411765 0.77173913 0.89795918 0.68253968 0.75268817 0.73809524\n",
      " 0.81333333 0.725      0.88235294 0.85882353 0.78651685 0.86904762\n",
      " 0.63157895]\n"
     ]
    }
   ],
   "source": [
    "#Calculating metrics for each class\n",
    "#print(\"EVALUATION ON TESTING DATA\")\n",
    "#print(classification_report(y_test, predictions))\n",
    "cm=confusion_matrix(y_test, predictions)\n",
    "#print(cm)\n",
    "good=np.diag(cm)/np.unique(y_test,return_counts=True)[1]\n",
    "print(good)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe104af2",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0888c018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is= 0.728551974580118\n",
      "--- 39.94409894943237 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "X=b1.iloc[:,0:1701]\n",
    "#model.fit(X,y)\n",
    "#model.score(X,y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "start_time = time.time()\n",
    "modelg = LogisticRegression(solver=\"newton-cg\",multi_class=\"multinomial\",max_iter=5000)\n",
    "modelg.fit(X_train,y_train)\n",
    "#Calculating  metrics of prediction\n",
    "print(\"The accuracy is=\",modelg.score(X_test,y_test))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "predictions = modelg.predict(X_test)\n",
    "#print(predictions)\n",
    "#print(\"F1-score is=\",f1_score(y_test,predictions, average=\"weighted\"))\n",
    "#print(\"precision=\",precision_score(y_test,predictions,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "402b3696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76829268 0.6056338  0.79268293 0.69512195 0.86138614 0.8490566\n",
      " 0.76190476 0.61904762 0.78571429 0.66666667 0.8125     0.72307692\n",
      " 0.78125    0.70652174 0.77906977 0.69863014 0.67073171 0.61842105\n",
      " 0.77027027 0.67567568 0.72131148 0.82608696 0.80412371 0.79452055\n",
      " 0.66666667 0.66197183 0.6        0.64814815 0.67708333 0.734375\n",
      " 0.765625   0.66037736 0.54794521 0.75862069 0.7195122  0.79166667\n",
      " 0.74117647 0.78571429 0.68421053 0.70588235 0.76190476 0.78823529\n",
      " 0.8        0.7173913  0.86734694 0.46031746 0.51612903 0.70238095\n",
      " 0.77333333 0.7        0.83529412 0.8        0.75280899 0.77380952\n",
      " 0.67368421]\n"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix(y_test, predictions)\n",
    "#print(cm)\n",
    "good=np.diag(cm)/np.unique(y_test,return_counts=True)[1]\n",
    "print(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f00793a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 1702)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yfortest=pd.read_csv(\"c:/Users/eacun/NRL/newy.csv\",header=None)\n",
    "Xfortest=pd.read_csv(\"c:/Users/eacun/NRL/newdata.csv\",header=None)\n",
    "Xfortest.shape\n",
    "yfortest=yfortest.astype(int)\n",
    "Xfortest[\"Analyte\"]=yfortest\n",
    "Xfortest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "86727e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "      <th>Analyte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.007476</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.010072</td>\n",
       "      <td>0.010446</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.014528</td>\n",
       "      <td>0.013623</td>\n",
       "      <td>0.017932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007268</td>\n",
       "      <td>-0.006155</td>\n",
       "      <td>-0.012700</td>\n",
       "      <td>-0.008968</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>-0.003519</td>\n",
       "      <td>-0.004037</td>\n",
       "      <td>-0.008019</td>\n",
       "      <td>-0.006984</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.016333</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.001737</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>0.009170</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.011766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005718</td>\n",
       "      <td>-0.015373</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>-0.011386</td>\n",
       "      <td>-0.009255</td>\n",
       "      <td>-0.001060</td>\n",
       "      <td>-0.001612</td>\n",
       "      <td>-0.016363</td>\n",
       "      <td>-0.002559</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005348</td>\n",
       "      <td>0.036134</td>\n",
       "      <td>0.030431</td>\n",
       "      <td>0.011412</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>-0.032478</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>0.008123</td>\n",
       "      <td>0.009853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038647</td>\n",
       "      <td>-0.039608</td>\n",
       "      <td>-0.013988</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>0.010057</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.038902</td>\n",
       "      <td>0.035069</td>\n",
       "      <td>0.016243</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.007465</td>\n",
       "      <td>0.007738</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016340</td>\n",
       "      <td>-0.016247</td>\n",
       "      <td>-0.016168</td>\n",
       "      <td>-0.016075</td>\n",
       "      <td>-0.015967</td>\n",
       "      <td>-0.015840</td>\n",
       "      <td>-0.015707</td>\n",
       "      <td>-0.015558</td>\n",
       "      <td>-0.015445</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003245</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.006083</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.005934</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.005932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019043</td>\n",
       "      <td>-0.015090</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>-0.014209</td>\n",
       "      <td>-0.016319</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.016972</td>\n",
       "      <td>-0.014881</td>\n",
       "      <td>-0.016518</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1702 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.006593  0.007476  0.006800  0.010072  0.010446  0.010157  0.013928   \n",
       "1 -0.016333  0.011538  0.001048 -0.000179 -0.000770 -0.001737  0.007633   \n",
       "2 -0.005348  0.036134  0.030431  0.011412  0.007818  0.013162 -0.032478   \n",
       "3  0.004714  0.005182  0.005515  0.005790  0.006058  0.006349  0.006700   \n",
       "4 -0.003245  0.000118  0.003326  0.006083  0.004984  0.005934  0.000673   \n",
       "\n",
       "          7         8         9  ...      1692      1693      1694      1695  \\\n",
       "0  0.014528  0.013623  0.017932  ... -0.007268 -0.006155 -0.012700 -0.008968   \n",
       "1  0.009170  0.002870  0.011766  ... -0.005718 -0.015373 -0.005127 -0.011386   \n",
       "2  0.008999  0.008123  0.009853  ... -0.038647 -0.039608 -0.013988  0.020456   \n",
       "3  0.007108  0.007465  0.007738  ... -0.016340 -0.016247 -0.016168 -0.016075   \n",
       "4  0.003487  0.005428  0.005932  ... -0.019043 -0.015090 -0.016453 -0.014209   \n",
       "\n",
       "       1696      1697      1698      1699      1700  Analyte  \n",
       "0 -0.002538 -0.003519 -0.004037 -0.008019 -0.006984       30  \n",
       "1 -0.009255 -0.001060 -0.001612 -0.016363 -0.002559       20  \n",
       "2  0.010057  0.000856  0.038902  0.035069  0.016243       39  \n",
       "3 -0.015967 -0.015840 -0.015707 -0.015558 -0.015445        6  \n",
       "4 -0.016319 -0.013047 -0.016972 -0.014881 -0.016518        6  \n",
       "\n",
       "[5 rows x 1702 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfortest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e1b9f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=b1.copy()\n",
    "X2[\"Analyte\"]=y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab14bf4",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bda32602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tempfile\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, roc_auc_score, plot_confusion_matrix\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ba6a2643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:\n",
      "(17624, 1701)\n",
      "Test dimension:\n",
      "(4406, 1701)\n"
     ]
    }
   ],
   "source": [
    "# Configuration options\n",
    "feature_vector_length = 1701\n",
    "num_classes = 55\n",
    "X=b1.iloc[:,0:1701]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "# Convert target classes to categorical ones\n",
    "ytrain=Y_train-1\n",
    "ytest=Y_test-1\n",
    "Y_train = to_categorical(ytrain, num_classes)\n",
    "Y_test = to_categorical(ytest, num_classes)\n",
    "print('Train dimension:')\n",
    "print(X_train.shape)\n",
    "print('Test dimension:')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5e94dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (1701,)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 300)               510600    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 55)                11055     \n",
      "=================================================================\n",
      "Total params: 581,855\n",
      "Trainable params: 581,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the input shape\n",
    "input_shape = (feature_vector_length,)\n",
    "print(f'Feature shape: {input_shape}')\n",
    "\n",
    "# Create the model\n",
    "model1 = Sequential()\n",
    "#model.add(Dropout(0.3, input_shape=input_shape))\n",
    "model1.add(Dense(300, input_shape=input_shape, activation='relu'))\n",
    "model1.add(Dense(200, activation='relu'))\n",
    "model1.add(Dense(num_classes, activation='softmax'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0940d9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 3.5276 - accuracy: 0.1727 - val_loss: 2.5104 - val_accuracy: 0.4715\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1.7286 - accuracy: 0.6312 - val_loss: 1.4360 - val_accuracy: 0.6882\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1.0807 - accuracy: 0.7551 - val_loss: 1.2854 - val_accuracy: 0.6999\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.8113 - accuracy: 0.8055 - val_loss: 1.2502 - val_accuracy: 0.7070\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.6219 - accuracy: 0.8574 - val_loss: 1.2662 - val_accuracy: 0.7118\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.4779 - accuracy: 0.8965 - val_loss: 1.3183 - val_accuracy: 0.7038\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.3485 - accuracy: 0.9350 - val_loss: 1.3771 - val_accuracy: 0.7072\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.2454 - accuracy: 0.9646 - val_loss: 1.4469 - val_accuracy: 0.7010\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.1671 - accuracy: 0.9852 - val_loss: 1.5317 - val_accuracy: 0.6990\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.1115 - accuracy: 0.9940 - val_loss: 1.6076 - val_accuracy: 0.6984\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0726 - accuracy: 0.9990 - val_loss: 1.6822 - val_accuracy: 0.6987\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0497 - accuracy: 0.9999 - val_loss: 1.7329 - val_accuracy: 0.7010\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9999 - val_loss: 1.7901 - val_accuracy: 0.7007\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0275 - accuracy: 0.9999 - val_loss: 1.8421 - val_accuracy: 0.7007\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.8875 - val_accuracy: 0.7016\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0174 - accuracy: 0.9998 - val_loss: 1.9291 - val_accuracy: 0.6996\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0156 - accuracy: 0.9994 - val_loss: 1.9694 - val_accuracy: 0.7001\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.0014 - val_accuracy: 0.7010\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.0414 - val_accuracy: 0.6999\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.0708 - val_accuracy: 0.7013\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.1028 - val_accuracy: 0.7007\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.1298 - val_accuracy: 0.6999\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1561 - val_accuracy: 0.7013\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1848 - val_accuracy: 0.6987\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 2.2088 - val_accuracy: 0.7007\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.2346 - val_accuracy: 0.7001\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.2582 - val_accuracy: 0.6996\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.2816 - val_accuracy: 0.6990\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3025 - val_accuracy: 0.6999\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3294 - val_accuracy: 0.6999\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3473 - val_accuracy: 0.7010\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.3688 - val_accuracy: 0.6996\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.3927 - val_accuracy: 0.6999\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4061 - val_accuracy: 0.6999\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.4273 - val_accuracy: 0.7007\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 2.5421 - val_accuracy: 0.6809\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0150 - accuracy: 0.9972 - val_loss: 2.4371 - val_accuracy: 0.6967\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4601 - val_accuracy: 0.6999\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.4889 - val_accuracy: 0.7010\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5131 - val_accuracy: 0.6984\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5344 - val_accuracy: 0.6999\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5571 - val_accuracy: 0.6990\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 9.9185e-04 - accuracy: 1.0000 - val_loss: 2.5761 - val_accuracy: 0.6993\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 9.0994e-04 - accuracy: 1.0000 - val_loss: 2.5941 - val_accuracy: 0.7001\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 8.3985e-04 - accuracy: 1.0000 - val_loss: 2.6116 - val_accuracy: 0.6987\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 7.7748e-04 - accuracy: 1.0000 - val_loss: 2.6303 - val_accuracy: 0.6987\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 7.2266e-04 - accuracy: 1.0000 - val_loss: 2.6452 - val_accuracy: 0.6993\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 6.7613e-04 - accuracy: 1.0000 - val_loss: 2.6620 - val_accuracy: 0.6996\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 6.2963e-04 - accuracy: 1.0000 - val_loss: 2.6791 - val_accuracy: 0.6990\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 5.8881e-04 - accuracy: 1.0000 - val_loss: 2.6931 - val_accuracy: 0.6987\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "import time\n",
    "start_time = time.time()\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "baseline_history=model1.fit(X_train, Y_train, epochs=50, batch_size=150, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fc3adec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:---  33.82125949859619 seconds ---\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 2.5834 - accuracy: 0.6950\n",
      "(4406, 55)\n",
      "[2.583383083343506, 0.694961428642273]\n",
      "Test results - Loss: 2.583383083343506 - Accuracy: 0.694961428642273%\n",
      "--- 0.275684118270874 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Training time:---  %s seconds ---\" % (time.time() - start_time))\n",
    "#Test the model after training\n",
    "start_time=time.time()\n",
    "test_results = model1.evaluate(X_test, Y_test, verbose=1)\n",
    "print(Y_test.shape)\n",
    "print(test_results)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0316cc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6300, 1701)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista=[1,2,4,5,8,9,12,15,17,25,26,28,35,37]\n",
    "lista1=[26]\n",
    "smalltest=Xfortest[Xfortest[\"Analyte\"].isin(lista)]\n",
    "smalltest[\"Analyte\"].replace({1: 45, 2: 32, 4: 33, 5: 34, 8: 35, 9: 38, 12: 39, 15: 41, 17: 42, 25: 54, 26:43,  28: 44, 35: 53, 37: 37}, inplace=True)\n",
    "#smalltest[\"Analyte\"].replace({26: 43}, inplace=True)\n",
    "#smalltest=X2[X2[\"Analyte\"].isin(lista1)]\n",
    "A=smalltest.iloc[:,0:1701]\n",
    "B=smalltest.iloc[:,1701:1702]\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0c73da03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is= 0.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42    685\n",
       "44    571\n",
       "53    463\n",
       "45    450\n",
       "38    436\n",
       "32    433\n",
       "35    395\n",
       "54    344\n",
       "6     307\n",
       "37    266\n",
       "33    265\n",
       "3     219\n",
       "22    205\n",
       "20    162\n",
       "15    144\n",
       "34    134\n",
       "39    131\n",
       "29    101\n",
       "40     76\n",
       "28     62\n",
       "51     53\n",
       "27     52\n",
       "18     49\n",
       "12     46\n",
       "19     37\n",
       "10     36\n",
       "43     36\n",
       "2      16\n",
       "11     14\n",
       "30     10\n",
       "9      10\n",
       "16      9\n",
       "23      9\n",
       "5       8\n",
       "46      7\n",
       "8       7\n",
       "21      6\n",
       "49      6\n",
       "24      6\n",
       "17      6\n",
       "55      5\n",
       "36      5\n",
       "13      4\n",
       "26      3\n",
       "4       3\n",
       "25      2\n",
       "50      2\n",
       "41      1\n",
       "52      1\n",
       "7       1\n",
       "1       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape\n",
    "C=B.to_numpy()\n",
    "#print(type(C))\n",
    "print(\"The accuracy is=\",neigh.score(A,C))\n",
    "predictions = neigh.predict(A)\n",
    "pk=pd.DataFrame(predictions)\n",
    "pk.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "362b9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is= 0.5814285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy is=\",modelg.score(A,C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5cc20b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42    879\n",
       "53    451\n",
       "45    451\n",
       "44    428\n",
       "35    418\n",
       "32    393\n",
       "38    387\n",
       "37    341\n",
       "54    223\n",
       "20    214\n",
       "34    206\n",
       "33    198\n",
       "22    189\n",
       "3     172\n",
       "27    158\n",
       "6     151\n",
       "10    146\n",
       "15    133\n",
       "43    133\n",
       "40     94\n",
       "23     75\n",
       "55     58\n",
       "51     50\n",
       "39     44\n",
       "2      41\n",
       "30     38\n",
       "41     33\n",
       "29     33\n",
       "19     28\n",
       "18     25\n",
       "46     13\n",
       "11     10\n",
       "49     10\n",
       "24     10\n",
       "48     10\n",
       "28      7\n",
       "13      7\n",
       "12      6\n",
       "52      5\n",
       "16      5\n",
       "47      5\n",
       "9       4\n",
       "5       4\n",
       "8       3\n",
       "7       3\n",
       "4       2\n",
       "26      2\n",
       "31      1\n",
       "17      1\n",
       "36      1\n",
       "1       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1 = modelg.predict(A)\n",
    "plog=pd.DataFrame(predictions1)\n",
    "plog.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "174442ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300, 1701)\n"
     ]
    }
   ],
   "source": [
    "#Ccat= to_categorical(C, 55)\n",
    "A1=A.to_numpy()\n",
    "print(A1.shape)\n",
    "#test_results = np.argmax(model.predict(A))\n",
    "train_predictions_baseline = model1.predict_classes(A1, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "32ef58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01282051 0.04109589 0.01265823 0.01190476 0.03125    0.02272727\n",
      " 0.01234568 0.03529412 0.         0.         0.01086957 0.\n",
      " 0.         0.03125    0.04807692 0.0125     0.03846154 0.\n",
      " 0.04761905 0.01234568 0.         0.04123711 0.06756757 0.01315789\n",
      " 0.03448276 0.02531646 0.02702703 0.02985075 0.0212766  0.\n",
      " 0.02631579 0.         0.         0.         0.01176471 0.\n",
      " 0.03947368 0.01010101 0.01449275 0.         0.01149425 0.03896104\n",
      " 0.04347826 0.01298701 0.03333333 0.         0.01298701 0.\n",
      " 0.         0.         0.04054054 0.         0.0125     0.01470588\n",
      " 0.02702703]\n"
     ]
    }
   ],
   "source": [
    "test_features = np.array(X_test)\n",
    "test_predictions_baseline = model1.predict_classes(test_features, batch_size=150)\n",
    "cm=confusion_matrix(ytest, test_predictions_baseline)\n",
    "#print(cm)\n",
    "good=np.diag(cm)/np.unique(ytest,return_counts=True)[1]\n",
    "print(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7dbf843a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42    785\n",
       "44    478\n",
       "53    443\n",
       "38    422\n",
       "45    421\n",
       "32    418\n",
       "35    409\n",
       "37    335\n",
       "28    274\n",
       "22    238\n",
       "54    210\n",
       "3     203\n",
       "6     174\n",
       "27    163\n",
       "15    159\n",
       "34    140\n",
       "33    113\n",
       "20    102\n",
       "40     97\n",
       "39     81\n",
       "18     79\n",
       "29     79\n",
       "46     66\n",
       "43     61\n",
       "55     32\n",
       "10     26\n",
       "19     25\n",
       "25     24\n",
       "51     18\n",
       "30     18\n",
       "2      16\n",
       "5      15\n",
       "23     15\n",
       "12     12\n",
       "17     12\n",
       "49     11\n",
       "21     11\n",
       "52     11\n",
       "41     11\n",
       "50     10\n",
       "13     10\n",
       "11     10\n",
       "8       8\n",
       "26      8\n",
       "31      7\n",
       "24      7\n",
       "16      6\n",
       "9       5\n",
       "4       5\n",
       "48      4\n",
       "14      4\n",
       "36      3\n",
       "1       3\n",
       "47      2\n",
       "7       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=train_predictions_baseline\n",
    "p1=pred.reshape(6300,1)\n",
    "p1=p1+1\n",
    "p2=pd.DataFrame(p1)\n",
    "p2.value_counts()\n",
    "#print(np.unique(p1,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e45d7330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5315873]\n"
     ]
    }
   ],
   "source": [
    "#p1=pred.reshape(450,1)\n",
    "#p1\n",
    "actual=C\n",
    "print(sum(p1==actual)/6300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e63ef",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "048de7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import load_iris\n",
    "from numpy import unique\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d89fbafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22030, 1701, 1)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54]\n"
     ]
    }
   ],
   "source": [
    "x=b1.iloc[:,0:1701].to_numpy()\n",
    "x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "print(x.shape)\n",
    "y=y-1\n",
    "print(unique(y))\n",
    "#print(unique(y).sum())\n",
    "\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5599878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 1699, 32)          128       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1699, 64)          2112      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 566, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 566, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 564, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 564, 64)           2112      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 188, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 188, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12032)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 55)                661815    \n",
      "=================================================================\n",
      "Total params: 672,343\n",
      "Trainable params: 672,343\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "56/56 [==============================] - 34s 602ms/step - loss: 3.7612 - accuracy: 0.0944 - val_loss: 2.7214 - val_accuracy: 0.3234\n",
      "Epoch 2/30\n",
      "56/56 [==============================] - 34s 602ms/step - loss: 1.7478 - accuracy: 0.5714 - val_loss: 1.2482 - val_accuracy: 0.6902\n",
      "Epoch 3/30\n",
      "56/56 [==============================] - 34s 613ms/step - loss: 1.1566 - accuracy: 0.7146 - val_loss: 1.0993 - val_accuracy: 0.7382\n",
      "Epoch 4/30\n",
      "56/56 [==============================] - 34s 606ms/step - loss: 1.0345 - accuracy: 0.7385 - val_loss: 1.0904 - val_accuracy: 0.7382\n",
      "Epoch 5/30\n",
      "56/56 [==============================] - 35s 617ms/step - loss: 0.9408 - accuracy: 0.7598 - val_loss: 1.0909 - val_accuracy: 0.7356\n",
      "Epoch 6/30\n",
      "56/56 [==============================] - 34s 599ms/step - loss: 0.8785 - accuracy: 0.7699 - val_loss: 1.0904 - val_accuracy: 0.7359\n",
      "Epoch 7/30\n",
      "56/56 [==============================] - 32s 565ms/step - loss: 0.8348 - accuracy: 0.7822 - val_loss: 1.0970 - val_accuracy: 0.7350\n",
      "Epoch 8/30\n",
      "56/56 [==============================] - 32s 565ms/step - loss: 0.7841 - accuracy: 0.7935 - val_loss: 1.1192 - val_accuracy: 0.7330\n",
      "Epoch 9/30\n",
      "56/56 [==============================] - 32s 565ms/step - loss: 0.7576 - accuracy: 0.7988 - val_loss: 1.1755 - val_accuracy: 0.7296\n",
      "Epoch 10/30\n",
      "56/56 [==============================] - 32s 565ms/step - loss: 0.7172 - accuracy: 0.8053 - val_loss: 1.1932 - val_accuracy: 0.7223\n",
      "Epoch 11/30\n",
      "56/56 [==============================] - 32s 565ms/step - loss: 0.6915 - accuracy: 0.8102 - val_loss: 1.1927 - val_accuracy: 0.7262\n",
      "Epoch 12/30\n",
      "56/56 [==============================] - 32s 568ms/step - loss: 0.6747 - accuracy: 0.8119 - val_loss: 1.3181 - val_accuracy: 0.7160\n",
      "Epoch 13/30\n",
      "56/56 [==============================] - 32s 566ms/step - loss: 0.6596 - accuracy: 0.8138 - val_loss: 1.2307 - val_accuracy: 0.7220\n",
      "Epoch 14/30\n",
      "56/56 [==============================] - 32s 572ms/step - loss: 0.6195 - accuracy: 0.8254 - val_loss: 1.2837 - val_accuracy: 0.7211\n",
      "Epoch 15/30\n",
      "56/56 [==============================] - 32s 576ms/step - loss: 0.6006 - accuracy: 0.8325 - val_loss: 1.2947 - val_accuracy: 0.7217\n",
      "Epoch 16/30\n",
      "56/56 [==============================] - 32s 577ms/step - loss: 0.5786 - accuracy: 0.8338 - val_loss: 1.3111 - val_accuracy: 0.7174\n",
      "Epoch 17/30\n",
      "56/56 [==============================] - 34s 606ms/step - loss: 0.5572 - accuracy: 0.8425 - val_loss: 1.3414 - val_accuracy: 0.7152\n",
      "Epoch 18/30\n",
      "56/56 [==============================] - 33s 590ms/step - loss: 0.5454 - accuracy: 0.8398 - val_loss: 1.3893 - val_accuracy: 0.7084\n",
      "Epoch 19/30\n",
      "56/56 [==============================] - 33s 591ms/step - loss: 0.5054 - accuracy: 0.8507 - val_loss: 1.4004 - val_accuracy: 0.7118\n",
      "Epoch 20/30\n",
      "56/56 [==============================] - 33s 592ms/step - loss: 0.5002 - accuracy: 0.8499 - val_loss: 1.4318 - val_accuracy: 0.7123\n",
      "Epoch 21/30\n",
      "56/56 [==============================] - 33s 591ms/step - loss: 0.4888 - accuracy: 0.8537 - val_loss: 1.4306 - val_accuracy: 0.7157\n",
      "Epoch 22/30\n",
      "56/56 [==============================] - 33s 592ms/step - loss: 0.4627 - accuracy: 0.8594 - val_loss: 1.5027 - val_accuracy: 0.7101\n",
      "Epoch 23/30\n",
      "56/56 [==============================] - 33s 592ms/step - loss: 0.4354 - accuracy: 0.8684 - val_loss: 1.5416 - val_accuracy: 0.7132\n",
      "Epoch 24/30\n",
      "56/56 [==============================] - 33s 592ms/step - loss: 0.4361 - accuracy: 0.8679 - val_loss: 1.4924 - val_accuracy: 0.7098\n",
      "Epoch 25/30\n",
      "56/56 [==============================] - 33s 592ms/step - loss: 0.4173 - accuracy: 0.8705 - val_loss: 1.5569 - val_accuracy: 0.7152\n",
      "Epoch 26/30\n",
      "56/56 [==============================] - 33s 592ms/step - loss: 0.4015 - accuracy: 0.8764 - val_loss: 1.5096 - val_accuracy: 0.7155\n",
      "Epoch 27/30\n",
      "56/56 [==============================] - 33s 592ms/step - loss: 0.3710 - accuracy: 0.8842 - val_loss: 1.5565 - val_accuracy: 0.7129\n",
      "Epoch 28/30\n",
      "56/56 [==============================] - 33s 590ms/step - loss: 0.3569 - accuracy: 0.8911 - val_loss: 1.6264 - val_accuracy: 0.7115\n",
      "Epoch 29/30\n",
      "56/56 [==============================] - 33s 591ms/step - loss: 0.3293 - accuracy: 0.8974 - val_loss: 1.6246 - val_accuracy: 0.7101\n",
      "Epoch 30/30\n",
      "56/56 [==============================] - 33s 594ms/step - loss: 0.3237 - accuracy: 0.8957 - val_loss: 1.7131 - val_accuracy: 0.7129\n",
      "551/551 [==============================] - 11s 20ms/step - loss: 0.4336 - accuracy: 0.9262\n",
      "Loss: 0.43364980816841125  Accuracy: 0.9261801838874817\n",
      "Training time --- 1015.5935316085815 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(32, 3, activation=\"relu\", input_shape=(1701,1)))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(32, 3, activation=\"relu\", input_shape=(1701,1)))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(55, activation = 'softmax'))\n",
    "start_time = time.time()\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "model.summary()\n",
    "baseline_history=model.fit(xtrain, ytrain, epochs=30, batch_size=256, verbose=1, validation_split=0.2)\n",
    "#model.fit(xtrain, ytrain, batch_size=256,epochs=25,  validation_split=.2, verbose=1)\n",
    "acc = model.evaluate(xtrain, ytrain)\n",
    "print(\"Loss:\", acc[0], \" Accuracy:\", acc[1])\n",
    "print(\"Training time --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b3114bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 3s 20ms/step - loss: 1.7692 - accuracy: 0.7004\n",
      "[1.7691601514816284, 0.7004085183143616]\n",
      "Test results - Loss: 1.7691601514816284 - Accuracy: 0.7004085183143616%\n",
      "Testing Time--- 2.8616952896118164 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Test the model after training\n",
    "start_time=time.time()\n",
    "test_results = model.evaluate(xtest, ytest, verbose=1)\n",
    "print(test_results)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "print(\"Testing Time--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "61d6c7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80769231 0.7260274  0.78481013 0.6547619  0.76041667 0.76136364\n",
      " 0.81481481 0.64705882 0.81818182 0.62337662 0.76086957 0.77941176\n",
      " 0.71764706 0.76041667 0.73076923 0.6625     0.78205128 0.50684932\n",
      " 0.66666667 0.65432099 0.66101695 0.75257732 0.81081081 0.73684211\n",
      " 0.56321839 0.82278481 0.74324324 0.65671642 0.58510638 0.67857143\n",
      " 0.68421053 0.60869565 0.53333333 0.67567568 0.71764706 0.79104478\n",
      " 0.68421053 0.71717172 0.5942029  0.55128205 0.70114943 0.57142857\n",
      " 0.76086957 0.74025974 0.83333333 0.61016949 0.63636364 0.68181818\n",
      " 0.67105263 0.68       0.81081081 0.83333333 0.6625     0.61764706\n",
      " 0.63063063]\n"
     ]
    }
   ],
   "source": [
    "test_features = np.array(xtest)\n",
    "test_predictions_baseline1 = model.predict_classes(test_features, batch_size=150)\n",
    "cm=confusion_matrix(ytest, test_predictions_baseline1)\n",
    "#print(cm)\n",
    "good=np.diag(cm)/np.unique(ytest,return_counts=True)[1]\n",
    "print(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d58868d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42    735\n",
       "44    723\n",
       "53    467\n",
       "45    402\n",
       "32    385\n",
       "38    367\n",
       "27    324\n",
       "35    318\n",
       "22    290\n",
       "54    223\n",
       "6     190\n",
       "34    173\n",
       "23    151\n",
       "20    137\n",
       "51    127\n",
       "3     119\n",
       "2     115\n",
       "43    105\n",
       "55     79\n",
       "39     78\n",
       "26     71\n",
       "40     71\n",
       "10     70\n",
       "33     66\n",
       "52     66\n",
       "29     56\n",
       "16     55\n",
       "19     55\n",
       "25     47\n",
       "15     34\n",
       "24     21\n",
       "12     20\n",
       "9      18\n",
       "49     18\n",
       "37     16\n",
       "18     14\n",
       "41     12\n",
       "11     10\n",
       "46      8\n",
       "28      7\n",
       "30      7\n",
       "21      7\n",
       "13      7\n",
       "5       6\n",
       "31      5\n",
       "36      4\n",
       "14      3\n",
       "48      3\n",
       "50      3\n",
       "4       3\n",
       "1       3\n",
       "17      2\n",
       "8       2\n",
       "7       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2 = A1.reshape(A1.shape[0], A1.shape[1], 1)\n",
    "train_predictions_baseline1 = model.predict_classes(A2,batch_size=64)\n",
    "pred1=train_predictions_baseline1\n",
    "p3=pred1.reshape(6300,1)\n",
    "p3=p3+1\n",
    "p4=pd.DataFrame(p3)\n",
    "p4.value_counts()\n",
    "#print(np.unique(p1,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b113d859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4747619]\n"
     ]
    }
   ],
   "source": [
    "#p3=pred1.reshape(450,1)\n",
    "#p1\n",
    "actual1=C\n",
    "print(sum(p3==actual1)/6300)\n",
    "#print(np.unique(p1,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "32438fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 53, 54],\n",
      "      dtype=int64), array([450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450,\n",
      "       450], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(actual1,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b60d00f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01818181818181818"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/55"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
