{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0f769b",
   "metadata": {},
   "source": [
    "### CNN-LSTM\n",
    "### Edgar Acuna\n",
    "### July 27, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a16dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn lstm model\n",
    "from numpy import mean\n",
    "from numpy import std, unique\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None)\n",
    "    return dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c28e3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    " # load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    loaded = dstack(loaded)\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e4c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Subs/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['X_'+group+'.csv']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.csv')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5beb7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'NRLDataset/')\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'NRLDataset/')\n",
    "    print(testX.shape, testy.shape)\n",
    "    # zero-offset class values\n",
    "    trainy = trainy.astype(int)\n",
    "    testy = testy.astype(int)\n",
    "    #For PCA\n",
    "    #trainy = trainy.astype(int)-1\n",
    "    #testy = testy.astype(int)-1\n",
    "    print(unique(testy))\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a55543",
   "metadata": {},
   "outputs": [],
   "source": [
    " # fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    # define model\n",
    "    verbose, epochs, batch_size = 1, 25, 256\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    # reshape data into time steps of sub-sequences\n",
    "    n_steps, n_length = 9, 189\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    print(\"number of features\",n_features)\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(300))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    #Computing F1-score\n",
    "    import numpy as np\n",
    "    import sklearn\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, roc_auc_score\n",
    "    train_features = np.array(trainX)\n",
    "    test_features = np.array(testX)\n",
    "    train_labels=np.array(trainy)\n",
    "    #train_labels=pd.DataFrame(trainy)\n",
    "    #n_values = train_labels.idxmax(axis=1)\n",
    "    y_values=np.argmax(train_labels,axis=1)\n",
    "    #print(y_values)\n",
    "    test_labels=np.array(testy)\n",
    "    yt_values=np.argmax(test_labels,axis=1)\n",
    "    train_predictions_baseline = model.predict_classes(train_features, batch_size=150)\n",
    "    prob2=pd.DataFrame(model.predict_proba(test_features,batch_size=150))\n",
    "    a=prob2.max(axis=1)\n",
    "    print('Probability of classification',(a[a>.80].shape[0])/prob2.shape[0])\n",
    "    #f1_train=sklearn.metrics.f1_score(ytrain, train_predictions_baseline, average=\"weighted\")\n",
    "    test_predictions_baseline = model.predict_classes(test_features, batch_size=150)\n",
    "    #print(test_predictions_baseline)\n",
    "    #f1_test=sklearn.metrics.f1_score(test_labels, test_predictions_baseline, average=\"weighted\")\n",
    "    #print('f1_scores in testing set',f1_test)\n",
    "    #Calculating metrics for each class\n",
    "    print(\"EVALUATION ON TESTING DATA\")\n",
    "    print(classification_report(yt_values, test_predictions_baseline))\n",
    "    return accuracy\n",
    " \n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34cf4659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39600, 1701, 1) (39600, 1)\n",
      "(9900, 1701, 1) (9900, 1)\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55]\n",
      "(39600, 1701, 1) (39600, 56) (9900, 1701, 1) (9900, 56)\n",
      "number of features 1\n",
      "Epoch 1/25\n",
      "155/155 [==============================] - 276s 2s/step - loss: 3.9491 - accuracy: 0.0301\n",
      "Epoch 2/25\n",
      "155/155 [==============================] - 260s 2s/step - loss: 2.2310 - accuracy: 0.3874\n",
      "Epoch 3/25\n",
      "155/155 [==============================] - 249s 2s/step - loss: 1.3683 - accuracy: 0.6307\n",
      "Epoch 4/25\n",
      "155/155 [==============================] - 251s 2s/step - loss: 1.1535 - accuracy: 0.6928\n",
      "Epoch 5/25\n",
      "155/155 [==============================] - 248s 2s/step - loss: 1.0212 - accuracy: 0.7279\n",
      "Epoch 6/25\n",
      "155/155 [==============================] - 250s 2s/step - loss: 0.9363 - accuracy: 0.7485\n",
      "Epoch 7/25\n",
      "155/155 [==============================] - 251s 2s/step - loss: 0.8669 - accuracy: 0.7669\n",
      "Epoch 8/25\n",
      "155/155 [==============================] - 252s 2s/step - loss: 0.8125 - accuracy: 0.7805\n",
      "Epoch 9/25\n",
      "155/155 [==============================] - 256s 2s/step - loss: 0.7625 - accuracy: 0.7948\n",
      "Epoch 10/25\n",
      "155/155 [==============================] - 288s 2s/step - loss: 0.7150 - accuracy: 0.8050\n",
      "Epoch 11/25\n",
      "155/155 [==============================] - 251s 2s/step - loss: 0.6761 - accuracy: 0.8156\n",
      "Epoch 12/25\n",
      "155/155 [==============================] - 247s 2s/step - loss: 0.6340 - accuracy: 0.8267\n",
      "Epoch 13/25\n",
      "155/155 [==============================] - 248s 2s/step - loss: 0.6094 - accuracy: 0.8323\n",
      "Epoch 14/25\n",
      "155/155 [==============================] - 248s 2s/step - loss: 0.5784 - accuracy: 0.8432\n",
      "Epoch 15/25\n",
      "155/155 [==============================] - 247s 2s/step - loss: 0.5418 - accuracy: 0.8513\n",
      "Epoch 16/25\n",
      "155/155 [==============================] - 248s 2s/step - loss: 0.5102 - accuracy: 0.8576\n",
      "Epoch 17/25\n",
      "155/155 [==============================] - 248s 2s/step - loss: 0.4813 - accuracy: 0.8663\n",
      "Epoch 18/25\n",
      "155/155 [==============================] - 274s 2s/step - loss: 0.4546 - accuracy: 0.8728\n",
      "Epoch 19/25\n",
      "155/155 [==============================] - 301s 2s/step - loss: 0.4328 - accuracy: 0.8786\n",
      "Epoch 20/25\n",
      "155/155 [==============================] - 281s 2s/step - loss: 0.3964 - accuracy: 0.8883\n",
      "Epoch 21/25\n",
      "155/155 [==============================] - 343s 2s/step - loss: 0.3755 - accuracy: 0.8930\n",
      "Epoch 22/25\n",
      "155/155 [==============================] - 284s 2s/step - loss: 0.3595 - accuracy: 0.8978\n",
      "Epoch 23/25\n",
      "155/155 [==============================] - 283s 2s/step - loss: 0.3354 - accuracy: 0.9042\n",
      "Epoch 24/25\n",
      "155/155 [==============================] - 284s 2s/step - loss: 0.3185 - accuracy: 0.9053\n",
      "Epoch 25/25\n",
      "155/155 [==============================] - 287s 2s/step - loss: 0.2925 - accuracy: 0.9138\n",
      "WARNING:tensorflow:From <ipython-input-5-608a9fd81ccb>:41: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "WARNING:tensorflow:From <ipython-input-5-608a9fd81ccb>:42: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "Probability of classification 0.7739393939393939\n",
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.83      0.84       179\n",
      "           2       0.75      0.78      0.77       172\n",
      "           3       0.96      0.81      0.88       194\n",
      "           4       0.74      0.75      0.74       174\n",
      "           5       0.87      0.79      0.83       183\n",
      "           6       0.92      0.83      0.87       189\n",
      "           7       0.80      0.84      0.82       172\n",
      "           8       0.91      0.76      0.82       196\n",
      "           9       0.97      0.83      0.89       174\n",
      "          10       0.64      0.77      0.70       163\n",
      "          11       0.88      0.79      0.83       185\n",
      "          12       0.94      0.80      0.87       183\n",
      "          13       0.68      0.78      0.73       185\n",
      "          14       0.92      0.78      0.84       193\n",
      "          15       0.84      0.74      0.79       183\n",
      "          16       0.85      0.73      0.79       194\n",
      "          17       0.79      0.77      0.78       158\n",
      "          18       0.79      0.81      0.80       189\n",
      "          19       0.84      0.85      0.84       176\n",
      "          20       0.79      0.82      0.80       185\n",
      "          21       0.86      0.80      0.83       178\n",
      "          22       0.74      0.85      0.79       165\n",
      "          23       0.81      0.83      0.82       174\n",
      "          24       0.80      0.87      0.83       179\n",
      "          25       0.72      0.79      0.75       187\n",
      "          26       0.78      0.73      0.75       166\n",
      "          27       0.78      0.65      0.71       201\n",
      "          28       0.70      0.75      0.72       157\n",
      "          29       0.89      0.69      0.78       196\n",
      "          30       0.60      0.74      0.66       164\n",
      "          31       0.90      0.79      0.84       183\n",
      "          32       0.64      0.87      0.74       180\n",
      "          33       0.47      0.84      0.60       174\n",
      "          34       0.70      0.86      0.78       190\n",
      "          35       0.81      0.84      0.83       178\n",
      "          36       0.88      0.91      0.89       195\n",
      "          37       0.92      0.76      0.83       176\n",
      "          38       0.85      0.80      0.83       173\n",
      "          39       0.85      0.63      0.73       164\n",
      "          40       0.53      0.72      0.61       161\n",
      "          41       0.86      0.89      0.88       178\n",
      "          42       0.87      0.68      0.76       198\n",
      "          43       0.66      0.84      0.74       180\n",
      "          44       0.87      0.78      0.82       176\n",
      "          45       0.95      0.89      0.92       169\n",
      "          46       0.85      0.85      0.85       177\n",
      "          47       0.78      0.66      0.71       197\n",
      "          48       0.57      0.84      0.68       181\n",
      "          49       0.92      0.79      0.85       179\n",
      "          50       0.82      0.77      0.80       171\n",
      "          51       0.90      0.80      0.84       176\n",
      "          52       0.95      0.85      0.90       206\n",
      "          53       0.78      0.80      0.79       181\n",
      "          54       0.74      0.75      0.75       182\n",
      "          55       0.73      0.62      0.67       181\n",
      "\n",
      "    accuracy                           0.79      9900\n",
      "   macro avg       0.80      0.79      0.79      9900\n",
      "weighted avg       0.81      0.79      0.79      9900\n",
      "\n",
      ">#1: 78.899\n",
      "[78.89899015426636]\n",
      "Accuracy: 78.899% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=1):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy = load_dataset()\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    " \n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269feca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cac651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
