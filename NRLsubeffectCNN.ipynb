{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyte classification using CNN\n",
    "#### Edgar Acuna\n",
    "#### Reviewed  June 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import load_iris\n",
    "from numpy import unique\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataframe: (18000, 1701)\n"
     ]
    }
   ],
   "source": [
    "df1=pd.read_csv(\"c://onr2020/NRLset1_part1.csv\",header=None)\n",
    "df2=pd.read_csv(\"c://onr2020/NRLset1_part2.csv\",header=None)\n",
    "df3=pd.read_csv(\"c://onr2020/NRLset1_part3.csv\",header=None)\n",
    "df4=pd.read_csv(\"c://onr2020/NRLset1_part4.csv\",header=None)\n",
    "df5=pd.read_csv(\"c://onr2020/NRLset1_part5.csv\",header=None)\n",
    "df6=pd.read_csv(\"c://onr2020/NRLset1_part6.csv\",header=None)\n",
    "df7=pd.read_csv(\"c://onr2020/NRLset1_part7.csv\",header=None)\n",
    "df8=pd.read_csv(\"c://onr2020/NRLset1_part8.csv\",header=None)\n",
    "y=pd.read_csv(\"c://onr2020/labels.csv\",header=None)\n",
    "ys=pd.read_csv(\"c://onr2020/substrateIDs.csv\",header=None)\n",
    "subs=pd.read_csv(\"c://onr2020/substrates.csv\",header=None)\n",
    "dfset1=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8],ignore_index=True)\n",
    "print('Size of the dataframe: {}'.format(dfset1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfset2=dfset1.copy()\n",
    "dfset2['Analyte']=y\n",
    "dfset2['substrate']=ys\n",
    "dfsub1=dfset2[dfset2['substrate']==1]\n",
    "dfsub2=dfset2[dfset2['substrate']==2]\n",
    "dfsub3=dfset2[dfset2['substrate']==3]\n",
    "dfsub4=dfset2[dfset2['substrate']==4]\n",
    "dfsub5=dfset2[dfset2['substrate']==5]\n",
    "dfsub6=dfset2[dfset2['substrate']==6]\n",
    "dfsub7=dfset2[dfset2['substrate']==7]\n",
    "dfsub8=dfset2[dfset2['substrate']==8]\n",
    "dfsub9=dfset2[dfset2['substrate']==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfsub1=dfsub1.iloc[:,0:1701]\n",
    "mdfsub2=dfsub2.iloc[:,0:1701]\n",
    "mdfsub3=dfsub3.iloc[:,0:1701]\n",
    "mdfsub4=dfsub4.iloc[:,0:1701]\n",
    "mdfsub5=dfsub5.iloc[:,0:1701]\n",
    "mdfsub6=dfsub6.iloc[:,0:1701]\n",
    "mdfsub7=dfsub7.iloc[:,0:1701]\n",
    "mdfsub8=dfsub8.iloc[:,0:1701]\n",
    "mdfsub9=dfsub9.iloc[:,0:1701]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=subs.loc[0,:]\n",
    "y2=subs.loc[1,:]\n",
    "y3=subs.loc[2,:]\n",
    "y4=subs.loc[3,:]\n",
    "y5=subs.loc[4,:]\n",
    "y6=subs.loc[5,:]\n",
    "y7=subs.loc[6,:]\n",
    "y8=subs.loc[7,:]\n",
    "y9=subs.loc[8,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modsub1=mdfsub1.apply(lambda x : x -(np.sum(np.array(x)*np.array(y1))/np.sum(np.array(y1)*np.array(y1)))*y1,axis=1)\n",
    "modsub2=mdfsub2.apply(lambda x : x -(np.sum(np.array(x)*np.array(y2))/np.sum(np.array(y2)*np.array(y2)))*y2,axis=1)\n",
    "modsub3=mdfsub3.apply(lambda x : x -(np.sum(np.array(x)*np.array(y3))/np.sum(np.array(y3)*np.array(y3)))*y3,axis=1)\n",
    "modsub4=mdfsub4.apply(lambda x : x -(np.sum(np.array(x)*np.array(y4))/np.sum(np.array(y4)*np.array(y4)))*y4,axis=1)\n",
    "modsub5=mdfsub5.apply(lambda x : x -(np.sum(np.array(x)*np.array(y5))/np.sum(np.array(y5)*np.array(y5)))*y5,axis=1)\n",
    "modsub6=mdfsub6.apply(lambda x : x -(np.sum(np.array(x)*np.array(y6))/np.sum(np.array(y6)*np.array(y6)))*y6,axis=1)\n",
    "modsub7=mdfsub7.apply(lambda x : x -(np.sum(np.array(x)*np.array(y7))/np.sum(np.array(y7)*np.array(y7)))*y7,axis=1)\n",
    "modsub8=mdfsub8.apply(lambda x : x -(np.sum(np.array(x)*np.array(y8))/np.sum(np.array(y8)*np.array(y8)))*y8,axis=1)\n",
    "modsub9=mdfsub9.apply(lambda x : x -(np.sum(np.array(x)*np.array(y9))/np.sum(np.array(y9)*np.array(y9)))*y9,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001858</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>-0.002143</td>\n",
       "      <td>-0.004422</td>\n",
       "      <td>-0.003123</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>-0.001225</td>\n",
       "      <td>-0.001406</td>\n",
       "      <td>-0.002792</td>\n",
       "      <td>-0.002432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.005471</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>-0.005149</td>\n",
       "      <td>-0.001717</td>\n",
       "      <td>-0.003814</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.005481</td>\n",
       "      <td>-0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.002496</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>-0.015160</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>-0.018040</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.006529</td>\n",
       "      <td>0.009548</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.018158</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.007582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004576</td>\n",
       "      <td>-0.004550</td>\n",
       "      <td>-0.004524</td>\n",
       "      <td>-0.004502</td>\n",
       "      <td>-0.004476</td>\n",
       "      <td>-0.004446</td>\n",
       "      <td>-0.004411</td>\n",
       "      <td>-0.004373</td>\n",
       "      <td>-0.004332</td>\n",
       "      <td>-0.004301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.001097</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>-0.006438</td>\n",
       "      <td>-0.005102</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>-0.004804</td>\n",
       "      <td>-0.005517</td>\n",
       "      <td>-0.004411</td>\n",
       "      <td>-0.005738</td>\n",
       "      <td>-0.005031</td>\n",
       "      <td>-0.005584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "4   0.002296  0.002603  0.002368  0.003507  0.003637  0.003537  0.004850   \n",
       "5  -0.005471  0.003865  0.000351 -0.000060 -0.000258 -0.000582  0.002557   \n",
       "8  -0.002496  0.016867  0.014204  0.005327  0.003649  0.006143 -0.015160   \n",
       "28  0.001313  0.001443  0.001536  0.001612  0.001687  0.001768  0.001866   \n",
       "46 -0.001097  0.000040  0.001125  0.002056  0.001685  0.002006  0.000228   \n",
       "\n",
       "        7         8         9     ...      1691      1692      1693      1694  \\\n",
       "4   0.005059  0.004744  0.006244  ... -0.001858 -0.002531 -0.002143 -0.004422   \n",
       "5   0.003072  0.000961  0.003941  ... -0.004245 -0.001915 -0.005149 -0.001717   \n",
       "8   0.004201  0.003791  0.004599  ...  0.002574 -0.018040 -0.018488 -0.006529   \n",
       "28  0.001979  0.002079  0.002155  ... -0.004576 -0.004550 -0.004524 -0.004502   \n",
       "46  0.001179  0.001835  0.002005  ... -0.004655 -0.006438 -0.005102 -0.005563   \n",
       "\n",
       "        1695      1696      1697      1698      1699      1700  \n",
       "4  -0.003123 -0.000884 -0.001225 -0.001406 -0.002792 -0.002432  \n",
       "5  -0.003814 -0.003100 -0.000355 -0.000540 -0.005481 -0.000857  \n",
       "8   0.009548  0.004694  0.000399  0.018158  0.016369  0.007582  \n",
       "28 -0.004476 -0.004446 -0.004411 -0.004373 -0.004332 -0.004301  \n",
       "46 -0.004804 -0.005517 -0.004411 -0.005738 -0.005031 -0.005584  \n",
       "\n",
       "[5 rows x 1701 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf=[modsub1,modsub2,modsub3,modsub4,modsub5,modsub6,modsub7,modsub8,modsub9]\n",
    "cent_subs=pd.concat(subdf)\n",
    "cent_subs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001858</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>-0.002143</td>\n",
       "      <td>-0.004422</td>\n",
       "      <td>-0.003123</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>-0.001225</td>\n",
       "      <td>-0.001406</td>\n",
       "      <td>-0.002792</td>\n",
       "      <td>-0.002432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.005471</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>-0.005149</td>\n",
       "      <td>-0.001717</td>\n",
       "      <td>-0.003814</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.005481</td>\n",
       "      <td>-0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.002496</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>-0.015160</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>-0.018040</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.006529</td>\n",
       "      <td>0.009548</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.018158</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.007582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004576</td>\n",
       "      <td>-0.004550</td>\n",
       "      <td>-0.004524</td>\n",
       "      <td>-0.004502</td>\n",
       "      <td>-0.004476</td>\n",
       "      <td>-0.004446</td>\n",
       "      <td>-0.004411</td>\n",
       "      <td>-0.004373</td>\n",
       "      <td>-0.004332</td>\n",
       "      <td>-0.004301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.001097</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>-0.006438</td>\n",
       "      <td>-0.005102</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>-0.004804</td>\n",
       "      <td>-0.005517</td>\n",
       "      <td>-0.004411</td>\n",
       "      <td>-0.005738</td>\n",
       "      <td>-0.005031</td>\n",
       "      <td>-0.005584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "4   0.002296  0.002603  0.002368  0.003507  0.003637  0.003537  0.004850   \n",
       "5  -0.005471  0.003865  0.000351 -0.000060 -0.000258 -0.000582  0.002557   \n",
       "8  -0.002496  0.016867  0.014204  0.005327  0.003649  0.006143 -0.015160   \n",
       "28  0.001313  0.001443  0.001536  0.001612  0.001687  0.001768  0.001866   \n",
       "46 -0.001097  0.000040  0.001125  0.002056  0.001685  0.002006  0.000228   \n",
       "\n",
       "        7         8         9     ...      1691      1692      1693      1694  \\\n",
       "4   0.005059  0.004744  0.006244  ... -0.001858 -0.002531 -0.002143 -0.004422   \n",
       "5   0.003072  0.000961  0.003941  ... -0.004245 -0.001915 -0.005149 -0.001717   \n",
       "8   0.004201  0.003791  0.004599  ...  0.002574 -0.018040 -0.018488 -0.006529   \n",
       "28  0.001979  0.002079  0.002155  ... -0.004576 -0.004550 -0.004524 -0.004502   \n",
       "46  0.001179  0.001835  0.002005  ... -0.004655 -0.006438 -0.005102 -0.005563   \n",
       "\n",
       "        1695      1696      1697      1698      1699      1700  \n",
       "4  -0.003123 -0.000884 -0.001225 -0.001406 -0.002792 -0.002432  \n",
       "5  -0.003814 -0.003100 -0.000355 -0.000540 -0.005481 -0.000857  \n",
       "8   0.009548  0.004694  0.000399  0.018158  0.016369  0.007582  \n",
       "28 -0.004476 -0.004446 -0.004411 -0.004373 -0.004332 -0.004301  \n",
       "46 -0.004804 -0.005517 -0.004411 -0.005738 -0.005031 -0.005584  \n",
       "\n",
       "[5 rows x 1701 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=cent_subs.iloc[:,0:1701]\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 1701)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize(b)\n",
    "b1=b.apply(lambda x: x/(x**2).sum()**.5, axis=1)\n",
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=np.array(dfsub1['Analyte'].values.tolist())\n",
    "a2=np.array(dfsub2['Analyte'].values.tolist())\n",
    "a3=np.array(dfsub3['Analyte'].values.tolist())\n",
    "a4=np.array(dfsub4['Analyte'].values.tolist())\n",
    "a5=np.array(dfsub5['Analyte'].values.tolist())\n",
    "a6=np.array(dfsub6['Analyte'].values.tolist())\n",
    "a7=np.array(dfsub7['Analyte'].values.tolist())\n",
    "a8=np.array(dfsub8['Analyte'].values.tolist())\n",
    "a9=np.array(dfsub9['Analyte'].values.tolist())\n",
    "y=np.concatenate((a1,a2,a3,a4,a5,a6,a7,a8,a9),axis=None)\n",
    "#print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 1701, 1)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n",
      "780\n"
     ]
    }
   ],
   "source": [
    "x=b1.iloc[:,0:1701].to_numpy()\n",
    "x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "print(x.shape)\n",
    "y=y-1\n",
    "print(unique(y))\n",
    "print(unique(y).sum())\n",
    "\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 1700, 64)          192       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1700, 16)          1040      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 850, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 850, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                544040    \n",
      "=================================================================\n",
      "Total params: 545,272\n",
      "Trainable params: 545,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "180/180 [==============================] - 12s 68ms/step - loss: 2.1062 - accuracy: 0.5037 - val_loss: 0.4327 - val_accuracy: 0.9108\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.2426 - accuracy: 0.9525 - val_loss: 0.1786 - val_accuracy: 0.9580\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.0935 - accuracy: 0.9812 - val_loss: 0.1500 - val_accuracy: 0.9566\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0385 - accuracy: 0.9944 - val_loss: 0.1616 - val_accuracy: 0.9531\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.0196 - accuracy: 0.9974 - val_loss: 0.1228 - val_accuracy: 0.9642\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.0123 - accuracy: 0.9984 - val_loss: 0.1221 - val_accuracy: 0.9642\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.1196 - val_accuracy: 0.9653\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.1224 - val_accuracy: 0.9663\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.1229 - val_accuracy: 0.9656\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9684\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9670\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.1401 - val_accuracy: 0.9597\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.1894 - val_accuracy: 0.9510\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0232 - accuracy: 0.9954 - val_loss: 0.1894 - val_accuracy: 0.9503\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.1294 - val_accuracy: 0.9618\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9642\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1337 - val_accuracy: 0.9646\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 6.9170e-04 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9580\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.1390 - val_accuracy: 0.9663\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 4.7647e-04 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9663\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.2889 - val_accuracy: 0.9389\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 0.0279 - accuracy: 0.9914 - val_loss: 0.1481 - val_accuracy: 0.9632\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 8.1480e-04 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9639\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 6.4206e-04 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9622\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1507 - val_accuracy: 0.9611\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 4.0030e-04 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9653\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 2.3533e-04 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9635\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.1839 - val_accuracy: 0.9594\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.2760 - val_accuracy: 0.9396\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.2370 - val_accuracy: 0.9493\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.1789 - val_accuracy: 0.9597\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 11s 61ms/step - loss: 2.8346e-04 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9615\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 11s 62ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2028 - val_accuracy: 0.9573\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 12s 64ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.1831 - val_accuracy: 0.9583\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 1.8931e-04 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9608\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 11s 61ms/step - loss: 1.2599e-04 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9611\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2024 - val_accuracy: 0.9587\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 2.7475e-04 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9628\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 8.4716e-05 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9622\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 8.9581e-05 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9601\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 12s 65ms/step - loss: 2.2924e-04 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9622\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 11s 62ms/step - loss: 5.2428e-05 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9611\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 6.2591e-05 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9615\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 11s 62ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.4138 - val_accuracy: 0.9253\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 11s 61ms/step - loss: 0.0295 - accuracy: 0.9914 - val_loss: 0.2348 - val_accuracy: 0.9524\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2041 - val_accuracy: 0.9601\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 11s 64ms/step - loss: 7.5899e-04 - accuracy: 0.9999 - val_loss: 0.1987 - val_accuracy: 0.9604\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 12s 66ms/step - loss: 1.3936e-04 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9618\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 11s 63ms/step - loss: 1.2696e-04 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9601\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 11s 63ms/step - loss: 1.4318e-04 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9611\n",
      "450/450 [==============================] - 6s 14ms/step - loss: 0.0419 - accuracy: 0.9922\n",
      "Loss: 0.041927747428417206  Accuracy: 0.992222249507904\n",
      "--- 586.5150573253632 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 2, activation=\"relu\", input_shape=(1701,1)))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(40, activation = 'softmax'))\n",
    "start_time = time.time()\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "model.summary()\n",
    "model.fit(xtrain, ytrain, batch_size=64,epochs=50,  validation_split=.2, verbose=1)\n",
    "\n",
    "acc = model.evaluate(xtrain, ytrain)\n",
    "print(\"Loss:\", acc[0], \" Accuracy:\", acc[1])\n",
    "\n",
    "pred = model.predict(xtest)\n",
    "pred_y = pred.argmax(axis=-1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 2s 15ms/step - loss: 0.1883 - accuracy: 0.9617\n",
      "[0.1883438378572464, 0.9616666436195374]\n",
      "Test results - Loss: 0.1883438378572464 - Accuracy: 0.9616666436195374%\n",
      "--- 588.6291143894196 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Test the model after training\n",
    "test_results = model.evaluate(xtest, ytest, verbose=1)\n",
    "print(test_results)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-dff844e38cba>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "f1_scores in training set 0.9922333573503361 f1_scores in testing set 0.9619282032136905\n"
     ]
    }
   ],
   "source": [
    "#Computing F1-score\n",
    "import sklearn\n",
    "train_features = np.array(xtrain)\n",
    "test_features = np.array(xtest)\n",
    "train_labels=np.array(ytrain)\n",
    "test_labels=np.array(ytest)\n",
    "train_predictions_baseline = model.predict_classes(train_features, batch_size=64)\n",
    "#train_predictions_baseline =np.argmax(model.predict(train_features, batch_size=64)>0.5).astype(\"int32\")\n",
    "f1_train=sklearn.metrics.f1_score(ytrain, train_predictions_baseline, average=\"weighted\")\n",
    "test_predictions_baseline = model.predict_classes(test_features, batch_size=64)\n",
    "f1_test=sklearn.metrics.f1_score(ytest, test_predictions_baseline, average=\"weighted\")\n",
    "print('f1_scores in training set',f1_train,'f1_scores in testing set',f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing metrics per analyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1700, 64)          192       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1700, 16)          1040      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 850, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 850, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 13600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 13601     \n",
      "=================================================================\n",
      "Total params: 14,833\n",
      "Trainable params: 14,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.1482 - accuracy: 0.9708 - val_loss: 0.1129 - val_accuracy: 0.9757\n",
      "Epoch 2/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.1153 - accuracy: 0.9742 - val_loss: 0.1039 - val_accuracy: 0.9757\n",
      "Epoch 3/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0919 - accuracy: 0.9747 - val_loss: 0.0823 - val_accuracy: 0.9747\n",
      "Epoch 4/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0699 - accuracy: 0.9756 - val_loss: 0.0620 - val_accuracy: 0.9760\n",
      "Epoch 5/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0571 - accuracy: 0.9788 - val_loss: 0.0552 - val_accuracy: 0.9781\n",
      "Epoch 6/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0449 - accuracy: 0.9826 - val_loss: 0.0451 - val_accuracy: 0.9799\n",
      "Epoch 7/20\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 0.0359 - val_accuracy: 0.9823\n",
      "Epoch 8/20\n",
      "180/180 [==============================] - 7s 38ms/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 0.0245 - val_accuracy: 0.9958\n",
      "Epoch 9/20\n",
      "180/180 [==============================] - 7s 39ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.0240 - val_accuracy: 0.9885\n",
      "Epoch 10/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0329 - val_accuracy: 0.9837\n",
      "Epoch 11/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.0193 - val_accuracy: 0.9927\n",
      "Epoch 12/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.0172 - val_accuracy: 0.9955\n",
      "Epoch 13/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0126 - accuracy: 0.9952 - val_loss: 0.0204 - val_accuracy: 0.9931\n",
      "Epoch 14/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0168 - val_accuracy: 0.9965\n",
      "Epoch 15/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0157 - val_accuracy: 0.9962\n",
      "Epoch 16/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0129 - accuracy: 0.9952 - val_loss: 0.0168 - val_accuracy: 0.9958\n",
      "Epoch 17/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0174 - val_accuracy: 0.9962\n",
      "Epoch 18/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.0168 - val_accuracy: 0.9962\n",
      "Epoch 19/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0164 - val_accuracy: 0.9962\n",
      "Epoch 20/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0085 - accuracy: 0.9966 - val_loss: 0.0170 - val_accuracy: 0.9965\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0049 - accuracy: 0.9992\n",
      "Loss: 0.0048916274681687355  Accuracy: 0.9991666674613953\n",
      "--- 133.27871990203857 seconds ---\n",
      "The confusion matrix\n",
      " [[3517    0]\n",
      " [  17   66]]\n",
      "Analyte is 13\n",
      "f1_scores in training set 0.9991621940322615 f1_scores in testing set 0.9950140819136936\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 1700, 64)          192       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1700, 16)          1040      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 850, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 850, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 13600)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 13601     \n",
      "=================================================================\n",
      "Total params: 14,833\n",
      "Trainable params: 14,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "180/180 [==============================] - 7s 38ms/step - loss: 0.1386 - accuracy: 0.9727 - val_loss: 0.1261 - val_accuracy: 0.9722\n",
      "Epoch 2/20\n",
      "180/180 [==============================] - 7s 39ms/step - loss: 0.1077 - accuracy: 0.9758 - val_loss: 0.1091 - val_accuracy: 0.9722\n",
      "Epoch 3/20\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.0781 - accuracy: 0.9771 - val_loss: 0.0609 - val_accuracy: 0.9795\n",
      "Epoch 4/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0600 - accuracy: 0.9813 - val_loss: 0.0512 - val_accuracy: 0.9865\n",
      "Epoch 5/20\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.0455 - accuracy: 0.9857 - val_loss: 0.0354 - val_accuracy: 0.9865\n",
      "Epoch 6/20\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.0358 - accuracy: 0.9886 - val_loss: 0.0275 - val_accuracy: 0.9924\n",
      "Epoch 7/20\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 0.0234 - val_accuracy: 0.9927\n",
      "Epoch 8/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.0240 - val_accuracy: 0.9927\n",
      "Epoch 9/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.0194 - val_accuracy: 0.9937\n",
      "Epoch 10/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0334 - val_accuracy: 0.9885\n",
      "Epoch 11/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.0228 - val_accuracy: 0.9931\n",
      "Epoch 12/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.0231 - val_accuracy: 0.9934\n",
      "Epoch 13/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.0244 - val_accuracy: 0.9944\n",
      "Epoch 14/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.0184 - val_accuracy: 0.9955\n",
      "Epoch 15/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.0179 - val_accuracy: 0.9958\n",
      "Epoch 16/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.0198 - val_accuracy: 0.9955\n",
      "Epoch 17/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0085 - accuracy: 0.9967 - val_loss: 0.0213 - val_accuracy: 0.9951\n",
      "Epoch 18/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0228 - val_accuracy: 0.9955\n",
      "Epoch 19/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0184 - val_accuracy: 0.9955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 0.0200 - val_accuracy: 0.9955\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0053 - accuracy: 0.9991\n",
      "Loss: 0.005255263298749924  Accuracy: 0.9990972280502319\n",
      "--- 133.70451760292053 seconds ---\n",
      "The confusion matrix\n",
      " [[3505    4]\n",
      " [  11   80]]\n",
      "Analyte is 34\n",
      "f1_scores in training set 0.9990966087434614 f1_scores in testing set 0.9957520759193357\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 1700, 64)          192       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1700, 16)          1040      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 850, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 850, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 13600)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 13601     \n",
      "=================================================================\n",
      "Total params: 14,833\n",
      "Trainable params: 14,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.1448 - accuracy: 0.9719 - val_loss: 0.1174 - val_accuracy: 0.9743\n",
      "Epoch 2/20\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.1076 - accuracy: 0.9746 - val_loss: 0.0937 - val_accuracy: 0.9743\n",
      "Epoch 3/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0750 - accuracy: 0.9762 - val_loss: 0.0669 - val_accuracy: 0.9785\n",
      "Epoch 4/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0541 - accuracy: 0.9821 - val_loss: 0.0840 - val_accuracy: 0.9781\n",
      "Epoch 5/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0433 - accuracy: 0.9859 - val_loss: 0.0462 - val_accuracy: 0.9819\n",
      "Epoch 6/20\n",
      "180/180 [==============================] - 7s 36ms/step - loss: 0.0340 - accuracy: 0.9891 - val_loss: 0.0359 - val_accuracy: 0.9892\n",
      "Epoch 7/20\n",
      "180/180 [==============================] - 7s 38ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.0267 - val_accuracy: 0.9958\n",
      "Epoch 8/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 0.0273 - val_accuracy: 0.9937\n",
      "Epoch 9/20\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.0244 - val_accuracy: 0.9951\n",
      "Epoch 10/20\n",
      "180/180 [==============================] - 7s 39ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0252 - val_accuracy: 0.9941\n",
      "Epoch 11/20\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.0243 - val_accuracy: 0.9955\n",
      "Epoch 12/20\n",
      "180/180 [==============================] - 6s 36ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0193 - val_accuracy: 0.9955\n",
      "Epoch 13/20\n",
      "180/180 [==============================] - 8s 44ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0216 - val_accuracy: 0.9951\n",
      "Epoch 14/20\n",
      "180/180 [==============================] - 9s 50ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0177 - val_accuracy: 0.9955\n",
      "Epoch 15/20\n",
      "180/180 [==============================] - 9s 50ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0264 - val_accuracy: 0.9951\n",
      "Epoch 16/20\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0259 - val_accuracy: 0.9951\n",
      "Epoch 17/20\n",
      "180/180 [==============================] - 9s 49ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0220 - val_accuracy: 0.9958\n",
      "Epoch 18/20\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0296 - val_accuracy: 0.9955\n",
      "Epoch 19/20\n",
      "180/180 [==============================] - 7s 41ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0222 - val_accuracy: 0.9958\n",
      "Epoch 20/20\n",
      "180/180 [==============================] - 7s 37ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0369 - val_accuracy: 0.9937\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0098 - accuracy: 0.9983\n",
      "Loss: 0.009832151234149933  Accuracy: 0.9982638955116272\n",
      "--- 150.0461552143097 seconds ---\n",
      "The confusion matrix\n",
      " [[3516    1]\n",
      " [  20   63]]\n",
      "Analyte is 37\n",
      "f1_scores in training set 0.9982340529807889 f1_scores in testing set 0.9937975397162978\n"
     ]
    }
   ],
   "source": [
    "labels1=[12,33,36]\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "start_time=time.time()\n",
    "for j in labels1:\n",
    "    yclass=y.copy()\n",
    "    #unique_elements, counts_elements = np.unique(yclass, return_counts=True)\n",
    "    #print(\"Frequency of unique values of the said array:\") \n",
    "    #print(np.asarray((unique_elements, counts_elements)))\n",
    "    #print(yclass)\n",
    "    yclass[yclass!=j]=0 \n",
    "    yclass[yclass==j]=1\n",
    "    xtrain, xtest, yclasstrain, yclasstest = train_test_split(x,yclass,test_size=0.2,random_state=0)\n",
    "    #print(xtrain.shape)\n",
    "    #print(xtest.shape)\n",
    "    #ytrain = to_categorical(yclass_train, num_classes)\n",
    "    #ytest = to_categorical(yclass_test, num_classes)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 2, activation=\"relu\", input_shape=(1701,1)))\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    start_time = time.time()\n",
    "    #model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(xtrain, yclasstrain, batch_size=64,epochs=20,  validation_split=.2, verbose=1)\n",
    "    acc = model.evaluate(xtrain, yclasstrain)\n",
    "    print(\"Loss:\", acc[0], \" Accuracy:\", acc[1])\n",
    "    pred = model.predict_classes(xtest)\n",
    "    #pred_y = pred.argmax(axis=-1)\n",
    "    #cm = confusion_matrix(ytest, pred)\n",
    "    #print(cm)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    #pred = model.predict(xtest)\n",
    "    #pred_y = pred.argmax(axis=-1)\n",
    "    #cm = confusion_matrix(ytest, pred)\n",
    "    #print(pred)\n",
    "    #Computing F1-score\n",
    "    import sklearn\n",
    "    train_features = np.array(xtrain)\n",
    "    test_features = np.array(xtest)\n",
    "    train_labels=np.array(yclasstrain)\n",
    "    test_labels=np.array(yclasstest)\n",
    "    #print(\"obser\",np.count_nonzero(yclasstest))\n",
    "    train_predictions_baseline = model.predict_classes(train_features, batch_size=64)\n",
    "    f1_train=sklearn.metrics.f1_score(yclasstrain, train_predictions_baseline, average=\"weighted\")\n",
    "    test_predictions_baseline = model.predict_classes(test_features, batch_size=64)\n",
    "    #print(\"pred\",np.count_nonzero(test_predictions_baseline))\n",
    "    cm = confusion_matrix(yclasstest, test_predictions_baseline)\n",
    "    print(\"The confusion matrix\\n\",cm)\n",
    "    f1_test=sklearn.metrics.f1_score(yclasstest, test_predictions_baseline, average=\"weighted\")\n",
    "    print(\"Analyte is\",j+1)\n",
    "    print('f1_scores in training set',f1_train,'f1_scores in testing set',f1_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  PCA before performing analytes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "dfset3=b1.copy()\n",
    "pca = PCA(n_components=30)\n",
    "pca_result = pca.fit_transform(dfset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "x=pca_result\n",
    "x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 29, 16)            48        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 29, 8)             136       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 14, 8)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 14, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 40)                4520      \n",
      "=================================================================\n",
      "Total params: 4,704\n",
      "Trainable params: 4,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "180/180 [==============================] - 0s 3ms/step - loss: 3.5813 - accuracy: 0.1388 - val_loss: 3.2672 - val_accuracy: 0.4854\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 2.4765 - accuracy: 0.5230 - val_loss: 1.4954 - val_accuracy: 0.8177\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 1.2392 - accuracy: 0.7490 - val_loss: 0.7435 - val_accuracy: 0.8997\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.7725 - accuracy: 0.8305 - val_loss: 0.4818 - val_accuracy: 0.9236\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.5831 - accuracy: 0.8668 - val_loss: 0.3670 - val_accuracy: 0.9302\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.8873 - val_loss: 0.3115 - val_accuracy: 0.9358\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8999 - val_loss: 0.2744 - val_accuracy: 0.9392\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.9084 - val_loss: 0.2516 - val_accuracy: 0.9431\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.9169 - val_loss: 0.2359 - val_accuracy: 0.9424\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.9188 - val_loss: 0.2269 - val_accuracy: 0.9448\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.9235 - val_loss: 0.2166 - val_accuracy: 0.9455\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.9248 - val_loss: 0.2131 - val_accuracy: 0.9465\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.9206 - val_loss: 0.2085 - val_accuracy: 0.9479\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2764 - accuracy: 0.9283 - val_loss: 0.2043 - val_accuracy: 0.9479\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2746 - accuracy: 0.9308 - val_loss: 0.2019 - val_accuracy: 0.9490\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2714 - accuracy: 0.9275 - val_loss: 0.1980 - val_accuracy: 0.9490\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2657 - accuracy: 0.9306 - val_loss: 0.1978 - val_accuracy: 0.9497\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.9326 - val_loss: 0.1942 - val_accuracy: 0.9497\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2557 - accuracy: 0.9320 - val_loss: 0.1926 - val_accuracy: 0.9528\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2557 - accuracy: 0.9345 - val_loss: 0.1888 - val_accuracy: 0.9531\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2552 - accuracy: 0.9318 - val_loss: 0.1876 - val_accuracy: 0.9507\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.9350 - val_loss: 0.1883 - val_accuracy: 0.9514\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.9357 - val_loss: 0.1880 - val_accuracy: 0.9517\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.9341 - val_loss: 0.1872 - val_accuracy: 0.9524\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.9323 - val_loss: 0.1859 - val_accuracy: 0.9517\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2375 - accuracy: 0.9383 - val_loss: 0.1871 - val_accuracy: 0.9503\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2336 - accuracy: 0.9369 - val_loss: 0.1858 - val_accuracy: 0.9521\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2346 - accuracy: 0.9384 - val_loss: 0.1838 - val_accuracy: 0.9500\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2312 - accuracy: 0.9386 - val_loss: 0.1852 - val_accuracy: 0.9524\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2340 - accuracy: 0.9371 - val_loss: 0.1849 - val_accuracy: 0.9514\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2339 - accuracy: 0.9375 - val_loss: 0.1844 - val_accuracy: 0.9503\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9380 - val_loss: 0.1845 - val_accuracy: 0.9517\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9384 - val_loss: 0.1827 - val_accuracy: 0.9517\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2327 - accuracy: 0.9380 - val_loss: 0.1836 - val_accuracy: 0.9538\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.9381 - val_loss: 0.1817 - val_accuracy: 0.9535\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9391 - val_loss: 0.1848 - val_accuracy: 0.9490\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9372 - val_loss: 0.1850 - val_accuracy: 0.9493\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9385 - val_loss: 0.1806 - val_accuracy: 0.9528\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.9410 - val_loss: 0.1828 - val_accuracy: 0.9535\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9403 - val_loss: 0.1850 - val_accuracy: 0.9514\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.9372 - val_loss: 0.1827 - val_accuracy: 0.9535\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9383 - val_loss: 0.1825 - val_accuracy: 0.9521\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.9372 - val_loss: 0.1818 - val_accuracy: 0.9535\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9396 - val_loss: 0.1833 - val_accuracy: 0.9535\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.9428 - val_loss: 0.1826 - val_accuracy: 0.9531\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9392 - val_loss: 0.1847 - val_accuracy: 0.9524\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9388 - val_loss: 0.1831 - val_accuracy: 0.9528\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.9394 - val_loss: 0.1834 - val_accuracy: 0.9510\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9394 - val_loss: 0.1826 - val_accuracy: 0.9514\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 0.9436 - val_loss: 0.1811 - val_accuracy: 0.9535\n",
      "450/450 [==============================] - 0s 764us/step - loss: 0.1310 - accuracy: 0.9648\n",
      "Loss: 0.1310127079486847  Accuracy: 0.9647916555404663\n",
      "--- 11.431200504302979 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(16, 2, activation=\"relu\", input_shape=(30,1)))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(40, activation = 'softmax'))\n",
    "start_time = time.time()\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "model.summary()\n",
    "model.fit(xtrain, ytrain, batch_size=64,epochs=50,  validation_split=.2, verbose=1)\n",
    "\n",
    "acc = model.evaluate(xtrain, ytrain)\n",
    "print(\"Loss:\", acc[0], \" Accuracy:\", acc[1])\n",
    "\n",
    "pred = model.predict(xtest)\n",
    "pred_y = pred.argmax(axis=-1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 939us/step - loss: 0.1648 - accuracy: 0.9589\n",
      "[0.16482645273208618, 0.9588888883590698]\n",
      "Test results - Loss: 0.16482645273208618 - Accuracy: 0.9588888883590698%\n"
     ]
    }
   ],
   "source": [
    "# Test the model after training\n",
    "test_results = model.evaluate(xtest, ytest, verbose=1)\n",
    "print(test_results)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores in training set 0.9648452282775338 f1_scores in testing set 0.9588181401400551\n"
     ]
    }
   ],
   "source": [
    "#Computing F1-score\n",
    "import sklearn\n",
    "train_features = np.array(xtrain)\n",
    "test_features = np.array(xtest)\n",
    "train_labels=np.array(ytrain)\n",
    "test_labels=np.array(ytest)\n",
    "train_predictions_baseline = model.predict_classes(train_features, batch_size=64)\n",
    "f1_train=sklearn.metrics.f1_score(ytrain, train_predictions_baseline, average=\"weighted\")\n",
    "test_predictions_baseline = model.predict_classes(test_features, batch_size=64)\n",
    "f1_test=sklearn.metrics.f1_score(ytest, test_predictions_baseline, average=\"weighted\")\n",
    "print('f1_scores in training set',f1_train,'f1_scores in testing set',f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1=[0,1,2,3,4,5]\n",
    "import time\n",
    "start_time=time.time()\n",
    "for j in labels1:\n",
    "    yclass=y.copy()\n",
    "    yclass[yclass!=j]=0 \n",
    "    yclass[yclass==j]=1\n",
    "    xtrain, xtest, yclasstrain, yclasstest = train_test_split(x,yclass,test_size=0.2,random_state=0)\n",
    "    #print('Train dimension:');print(X_train.shape)\n",
    "    #print('Test dimension:');print(X_test.shape)\n",
    "    #ytrain = to_categorical(yclass_train, num_classes)\n",
    "    #ytest = to_categorical(yclass_test, num_classes)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(16, 2, activation=\"relu\", input_shape=(50,1)))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    start_time = time.time()\n",
    "    #model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")])\n",
    "    model.summary()\n",
    "    model.fit(xtrain, yclasstrain, batch_size=64,epochs=100,  validation_split=.2, verbose=1)\n",
    "    acc = model.evaluate(xtrain, yclasstrain)\n",
    "    print(\"Loss:\", acc[0], \" Accuracy:\", acc[1])\n",
    "    pred = model.predict(xtest)\n",
    "    pred_y = pred.argmax(axis=-1)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    #Computing F1-score\n",
    "    import sklearn\n",
    "    train_features = np.array(xtrain)\n",
    "    test_features = np.array(xtest)\n",
    "    train_labels=np.array(yclasstrain)\n",
    "    test_labels=np.array(yclasstest)\n",
    "    train_predictions_baseline = model.predict_classes(train_features, batch_size=64)\n",
    "    f1_train=sklearn.metrics.f1_score(yclasstrain, train_predictions_baseline, average=\"weighted\")\n",
    "    test_predictions_baseline = model.predict_classes(test_features, batch_size=64)\n",
    "    f1_test=sklearn.metrics.f1_score(yclasstest, test_predictions_baseline, average=\"weighted\")\n",
    "    print(\"Analyte is\",j+1)\n",
    "    print('f1_scores in training set',f1_train,'f1_scores in testing set',f1_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
