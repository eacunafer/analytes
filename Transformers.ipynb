{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557b8dd9",
   "metadata": {},
   "source": [
    "#### Transformers for 55 Analytes Dataset\n",
    "#### Author: Edgar Acuna\n",
    "#### Created: June 6,, 2023\n",
    "#### Reviewed: June 6, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0bfb86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64170c9d",
   "metadata": {},
   "source": [
    "#### Reading the data (in Matlab' format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4716fc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('__header__', b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Jul 22 14:13:11 2020'), ('__version__', '1.0'), ('__globals__', []), ('addedNoisePercent', array([[0.1],\n",
       "       [0.5],\n",
       "       [0. ],\n",
       "       ...,\n",
       "       [1. ],\n",
       "       [0.1],\n",
       "       [0. ]])), ('labels', array([[ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       ...,\n",
       "       [55],\n",
       "       [55],\n",
       "       [55]], dtype=uint8)), ('massLoadings', array([[90.48134734],\n",
       "       [90.48134734],\n",
       "       [90.48134734],\n",
       "       ...,\n",
       "       [93.56603952],\n",
       "       [93.56603952],\n",
       "       [93.56603952]])), ('spectra', array([[0.01684698, 0.01575019, 0.01553012, ..., 0.01631328, 0.01523777,\n",
       "        0.01464116],\n",
       "       [0.01862416, 0.01217942, 0.02092375, ..., 0.01522821, 0.02158774,\n",
       "        0.01224737],\n",
       "       [0.01634829, 0.01627708, 0.01620733, ..., 0.01681628, 0.01679286,\n",
       "        0.0167685 ],\n",
       "       ...,\n",
       "       [0.01777366, 0.02470746, 0.04042846, ..., 0.52899222, 0.53342443,\n",
       "        0.54125978],\n",
       "       [0.03112273, 0.02996503, 0.03299245, ..., 0.54179967, 0.53942979,\n",
       "        0.54275879],\n",
       "       [0.03236588, 0.0324536 , 0.03238276, ..., 0.54378712, 0.54383177,\n",
       "        0.54386556]])), ('substrateIDs', array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [8],\n",
       "       [8],\n",
       "       [8]], dtype=uint8)), ('substrateSpectra', array([[0.008192, 0.008116, 0.008042, ..., 0.010792, 0.010765, 0.010737],\n",
       "       [0.035105, 0.035617, 0.036458, ..., 0.041036, 0.041051, 0.04107 ],\n",
       "       [0.585617, 0.585672, 0.585179, ..., 0.559301, 0.559264, 0.55923 ],\n",
       "       ...,\n",
       "       [0.035515, 0.035251, 0.034737, ..., 0.247776, 0.246856, 0.245963],\n",
       "       [0.031312, 0.031438, 0.031556, ..., 0.569884, 0.56993 , 0.569966],\n",
       "       [0.00088 , 0.001132, 0.004165, ..., 0.008746, 0.008464, 0.008364]]))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = scipy.io.loadmat('C:/Users/Edgar Acuna/NRL2023/datasets/dataset55_release2.mat')\n",
    "mat.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b6f10cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       ...,\n",
       "       [55],\n",
       "       [55],\n",
       "       [55]], dtype=uint8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=mat['labels']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94c708a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49500, 1701)\n"
     ]
    }
   ],
   "source": [
    "df=mat['spectra']\n",
    "df=pd.DataFrame(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fe1cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys=mat['substrateIDs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "197346e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008192</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.007830</td>\n",
       "      <td>0.007763</td>\n",
       "      <td>0.007697</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.010943</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>0.010895</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010845</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.010792</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.010737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035105</td>\n",
       "      <td>0.035617</td>\n",
       "      <td>0.036458</td>\n",
       "      <td>0.037003</td>\n",
       "      <td>0.037084</td>\n",
       "      <td>0.036102</td>\n",
       "      <td>0.035552</td>\n",
       "      <td>0.035033</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040834</td>\n",
       "      <td>0.040778</td>\n",
       "      <td>0.040760</td>\n",
       "      <td>0.040794</td>\n",
       "      <td>0.040865</td>\n",
       "      <td>0.040946</td>\n",
       "      <td>0.041008</td>\n",
       "      <td>0.041036</td>\n",
       "      <td>0.041051</td>\n",
       "      <td>0.041070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585617</td>\n",
       "      <td>0.585672</td>\n",
       "      <td>0.585179</td>\n",
       "      <td>0.584104</td>\n",
       "      <td>0.585759</td>\n",
       "      <td>0.587581</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.589407</td>\n",
       "      <td>0.590642</td>\n",
       "      <td>0.591676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559620</td>\n",
       "      <td>0.559569</td>\n",
       "      <td>0.559520</td>\n",
       "      <td>0.559472</td>\n",
       "      <td>0.559426</td>\n",
       "      <td>0.559382</td>\n",
       "      <td>0.559341</td>\n",
       "      <td>0.559301</td>\n",
       "      <td>0.559264</td>\n",
       "      <td>0.559230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026414</td>\n",
       "      <td>0.026214</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>0.025770</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.025250</td>\n",
       "      <td>0.025171</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>0.025165</td>\n",
       "      <td>0.025351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546925</td>\n",
       "      <td>0.547225</td>\n",
       "      <td>0.547537</td>\n",
       "      <td>0.547909</td>\n",
       "      <td>0.548301</td>\n",
       "      <td>0.548652</td>\n",
       "      <td>0.548971</td>\n",
       "      <td>0.549233</td>\n",
       "      <td>0.549387</td>\n",
       "      <td>0.549484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011060</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.011618</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023413</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>0.023243</td>\n",
       "      <td>0.023115</td>\n",
       "      <td>0.023055</td>\n",
       "      <td>0.023158</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.023359</td>\n",
       "      <td>0.023251</td>\n",
       "      <td>0.023180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.064528</td>\n",
       "      <td>0.064613</td>\n",
       "      <td>0.064131</td>\n",
       "      <td>0.063398</td>\n",
       "      <td>0.062792</td>\n",
       "      <td>0.062214</td>\n",
       "      <td>0.061542</td>\n",
       "      <td>0.060586</td>\n",
       "      <td>0.059307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277668</td>\n",
       "      <td>0.277010</td>\n",
       "      <td>0.276353</td>\n",
       "      <td>0.275671</td>\n",
       "      <td>0.274983</td>\n",
       "      <td>0.274299</td>\n",
       "      <td>0.273613</td>\n",
       "      <td>0.272943</td>\n",
       "      <td>0.272329</td>\n",
       "      <td>0.271673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.035515</td>\n",
       "      <td>0.035251</td>\n",
       "      <td>0.034737</td>\n",
       "      <td>0.034093</td>\n",
       "      <td>0.033518</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>0.032536</td>\n",
       "      <td>0.032043</td>\n",
       "      <td>0.031658</td>\n",
       "      <td>0.031341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253511</td>\n",
       "      <td>0.252787</td>\n",
       "      <td>0.252041</td>\n",
       "      <td>0.251235</td>\n",
       "      <td>0.250392</td>\n",
       "      <td>0.249560</td>\n",
       "      <td>0.248698</td>\n",
       "      <td>0.247776</td>\n",
       "      <td>0.246856</td>\n",
       "      <td>0.245963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.031312</td>\n",
       "      <td>0.031438</td>\n",
       "      <td>0.031556</td>\n",
       "      <td>0.031777</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.031608</td>\n",
       "      <td>0.031588</td>\n",
       "      <td>0.031441</td>\n",
       "      <td>0.031011</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569969</td>\n",
       "      <td>0.569996</td>\n",
       "      <td>0.570024</td>\n",
       "      <td>0.570030</td>\n",
       "      <td>0.570001</td>\n",
       "      <td>0.569943</td>\n",
       "      <td>0.569884</td>\n",
       "      <td>0.569884</td>\n",
       "      <td>0.569930</td>\n",
       "      <td>0.569966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010077</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.010808</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.009309</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.008364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 1701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.008192  0.008116  0.008042  0.007970  0.007899  0.007830  0.007763   \n",
       "1  0.035105  0.035617  0.036458  0.037003  0.037084  0.036102  0.035552   \n",
       "2  0.585617  0.585672  0.585179  0.584104  0.585759  0.587581  0.588336   \n",
       "3  0.026414  0.026214  0.026014  0.025770  0.025449  0.025250  0.025171   \n",
       "4  0.011060  0.011381  0.011618  0.011406  0.010922  0.010713  0.010692   \n",
       "5  0.064400  0.064528  0.064613  0.064131  0.063398  0.062792  0.062214   \n",
       "6  0.035515  0.035251  0.034737  0.034093  0.033518  0.033043  0.032536   \n",
       "7  0.031312  0.031438  0.031556  0.031777  0.031780  0.031608  0.031588   \n",
       "8  0.000880  0.001132  0.004165  0.006112  0.005633  0.004667  0.003701   \n",
       "\n",
       "       7         8         9     ...      1691      1692      1693      1694  \\\n",
       "0  0.007697  0.007633  0.007570  ...  0.010966  0.010943  0.010919  0.010895   \n",
       "1  0.035033  0.034687  0.034424  ...  0.040834  0.040778  0.040760  0.040794   \n",
       "2  0.589407  0.590642  0.591676  ...  0.559620  0.559569  0.559520  0.559472   \n",
       "3  0.025119  0.025165  0.025351  ...  0.546925  0.547225  0.547537  0.547909   \n",
       "4  0.010628  0.010722  0.010908  ...  0.023413  0.023356  0.023243  0.023115   \n",
       "5  0.061542  0.060586  0.059307  ...  0.277668  0.277010  0.276353  0.275671   \n",
       "6  0.032043  0.031658  0.031341  ...  0.253511  0.252787  0.252041  0.251235   \n",
       "7  0.031441  0.031011  0.030551  ...  0.569969  0.569996  0.570024  0.570030   \n",
       "8  0.002964  0.002877  0.002152  ...  0.010077  0.010496  0.010808  0.010552   \n",
       "\n",
       "       1695      1696      1697      1698      1699      1700  \n",
       "0  0.010870  0.010845  0.010818  0.010792  0.010765  0.010737  \n",
       "1  0.040865  0.040946  0.041008  0.041036  0.041051  0.041070  \n",
       "2  0.559426  0.559382  0.559341  0.559301  0.559264  0.559230  \n",
       "3  0.548301  0.548652  0.548971  0.549233  0.549387  0.549484  \n",
       "4  0.023055  0.023158  0.023328  0.023359  0.023251  0.023180  \n",
       "5  0.274983  0.274299  0.273613  0.272943  0.272329  0.271673  \n",
       "6  0.250392  0.249560  0.248698  0.247776  0.246856  0.245963  \n",
       "7  0.570001  0.569943  0.569884  0.569884  0.569930  0.569966  \n",
       "8  0.010001  0.009687  0.009309  0.008746  0.008464  0.008364  \n",
       "\n",
       "[9 rows x 1701 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs=mat['substrateSpectra']\n",
    "subs=pd.DataFrame(subs)\n",
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "633e23ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfset2=df.copy()\n",
    "dfset2['Analyte']=y\n",
    "dfset2['substrate']=ys\n",
    "dfsub1=dfset2[dfset2['substrate']==1]\n",
    "dfsub2=dfset2[dfset2['substrate']==2]\n",
    "dfsub3=dfset2[dfset2['substrate']==3]\n",
    "dfsub4=dfset2[dfset2['substrate']==4]\n",
    "dfsub5=dfset2[dfset2['substrate']==5]\n",
    "dfsub6=dfset2[dfset2['substrate']==6]\n",
    "dfsub7=dfset2[dfset2['substrate']==7]\n",
    "dfsub8=dfset2[dfset2['substrate']==8]\n",
    "dfsub9=dfset2[dfset2['substrate']==9]\n",
    "#dfset1=pd.DataFrame(dfset1)\n",
    "df['Analyte']=y\n",
    "df['substrate']=ys\n",
    "#hard_subs['subtrate']=ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "222b3223",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfsub1=dfsub1.iloc[:,0:1701]\n",
    "mdfsub2=dfsub2.iloc[:,0:1701]\n",
    "mdfsub3=dfsub3.iloc[:,0:1701]\n",
    "mdfsub4=dfsub4.iloc[:,0:1701]\n",
    "mdfsub5=dfsub5.iloc[:,0:1701]\n",
    "mdfsub6=dfsub6.iloc[:,0:1701]\n",
    "mdfsub7=dfsub7.iloc[:,0:1701]\n",
    "mdfsub8=dfsub8.iloc[:,0:1701]\n",
    "mdfsub9=dfsub9.iloc[:,0:1701]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b2fd418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1701)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d95ec1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=subs.loc[0,:]\n",
    "s2=subs.loc[1,:]\n",
    "s3=subs.loc[2,:]\n",
    "s4=subs.loc[3,:]\n",
    "s5=subs.loc[4,:]\n",
    "s6=subs.loc[5,:]\n",
    "s7=subs.loc[6,:]\n",
    "s8=subs.loc[7,:]\n",
    "s9=subs.loc[8,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd2ae100",
   "metadata": {},
   "outputs": [],
   "source": [
    "modsub1=mdfsub1.apply(lambda x : x -(np.sum(np.array(x)*np.array(s1))/np.sum(np.array(s1)*np.array(s1)))*s1,axis=1)\n",
    "modsub2=mdfsub2.apply(lambda x : x -(np.sum(np.array(x)*np.array(s2))/np.sum(np.array(s2)*np.array(s2)))*s2,axis=1)\n",
    "modsub3=mdfsub3.apply(lambda x : x -(np.sum(np.array(x)*np.array(s3))/np.sum(np.array(s3)*np.array(s3)))*s3,axis=1)\n",
    "modsub4=mdfsub4.apply(lambda x : x -(np.sum(np.array(x)*np.array(s4))/np.sum(np.array(s4)*np.array(s4)))*s4,axis=1)\n",
    "modsub5=mdfsub5.apply(lambda x : x -(np.sum(np.array(x)*np.array(s5))/np.sum(np.array(s5)*np.array(s5)))*s5,axis=1)\n",
    "modsub6=mdfsub6.apply(lambda x : x -(np.sum(np.array(x)*np.array(s6))/np.sum(np.array(s6)*np.array(s6)))*s6,axis=1)\n",
    "modsub7=mdfsub7.apply(lambda x : x -(np.sum(np.array(x)*np.array(s7))/np.sum(np.array(s7)*np.array(s7)))*s7,axis=1)\n",
    "modsub8=mdfsub8.apply(lambda x : x -(np.sum(np.array(x)*np.array(s8))/np.sum(np.array(s8)*np.array(s8)))*s8,axis=1)\n",
    "modsub9=mdfsub9.apply(lambda x : x -(np.sum(np.array(x)*np.array(s9))/np.sum(np.array(s9)*np.array(s9)))*s9,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ceabdf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003352</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>-0.002224</td>\n",
       "      <td>-0.002386</td>\n",
       "      <td>-0.003332</td>\n",
       "      <td>-0.003701</td>\n",
       "      <td>-0.003463</td>\n",
       "      <td>-0.004489</td>\n",
       "      <td>-0.005034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003758</td>\n",
       "      <td>-0.002548</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>-0.011134</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>-0.006294</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010454</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>-0.009114</td>\n",
       "      <td>-0.001578</td>\n",
       "      <td>-0.002636</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>-0.004356</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>-0.007237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003437</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>-0.003390</td>\n",
       "      <td>-0.003366</td>\n",
       "      <td>-0.003341</td>\n",
       "      <td>-0.003316</td>\n",
       "      <td>-0.003289</td>\n",
       "      <td>-0.003263</td>\n",
       "      <td>-0.003236</td>\n",
       "      <td>-0.003209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>-0.000733</td>\n",
       "      <td>-0.003121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002536</td>\n",
       "      <td>-0.007373</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>-0.007754</td>\n",
       "      <td>-0.006247</td>\n",
       "      <td>-0.003583</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>-0.002472</td>\n",
       "      <td>-0.008282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.009750</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.004424</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>-0.004758</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003264</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>-0.008510</td>\n",
       "      <td>-0.000614</td>\n",
       "      <td>-0.004077</td>\n",
       "      <td>-0.013175</td>\n",
       "      <td>-0.004247</td>\n",
       "      <td>-0.002622</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.003888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.001835  0.000878  0.000793  0.000247  0.000728  0.001072  0.002347   \n",
       "1  0.003758 -0.002548  0.006330 -0.011134  0.000164  0.005120 -0.002903   \n",
       "2  0.001106  0.001177  0.001245  0.001310  0.001369  0.001383  0.001337   \n",
       "3  0.000363  0.003034  0.003668  0.002877  0.002038  0.000546  0.002638   \n",
       "4  0.003795  0.009750  0.001765  0.005447  0.004424  0.003195  0.001814   \n",
       "\n",
       "       7         8         9     ...      1691      1692      1693      1694  \\\n",
       "0  0.000115  0.000966  0.001123  ... -0.003352 -0.004829 -0.003905 -0.002224   \n",
       "1 -0.003049 -0.006294  0.003996  ... -0.010454  0.004719 -0.009114 -0.001578   \n",
       "2  0.001292  0.001355  0.001509  ... -0.003437 -0.003414 -0.003390 -0.003366   \n",
       "3 -0.002580 -0.000733 -0.003121  ... -0.002536 -0.007373 -0.000276 -0.002173   \n",
       "4 -0.004758  0.005961  0.005176  ... -0.003264  0.001135 -0.008510 -0.000614   \n",
       "\n",
       "       1695      1696      1697      1698      1699      1700  \n",
       "0 -0.002386 -0.003332 -0.003701 -0.003463 -0.004489 -0.005034  \n",
       "1 -0.002636 -0.001219  0.000561 -0.004356  0.002053 -0.007237  \n",
       "2 -0.003341 -0.003316 -0.003289 -0.003263 -0.003236 -0.003209  \n",
       "3 -0.007754 -0.006247 -0.003583 -0.004043 -0.002472 -0.008282  \n",
       "4 -0.004077 -0.013175 -0.004247 -0.002622 -0.000083 -0.003888  \n",
       "\n",
       "[5 rows x 1701 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf=[modsub1,modsub2,modsub3,modsub4,modsub5,modsub6,modsub7,modsub8,modsub9]\n",
    "cent_subs=pd.concat(subdf)\n",
    "cent_subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9739b452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "      <th>substrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>-0.002224</td>\n",
       "      <td>-0.002386</td>\n",
       "      <td>-0.003332</td>\n",
       "      <td>-0.003701</td>\n",
       "      <td>-0.003463</td>\n",
       "      <td>-0.004489</td>\n",
       "      <td>-0.005034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003758</td>\n",
       "      <td>-0.002548</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>-0.011134</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>-0.006294</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>-0.009114</td>\n",
       "      <td>-0.001578</td>\n",
       "      <td>-0.002636</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>-0.004356</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>-0.007237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>-0.003390</td>\n",
       "      <td>-0.003366</td>\n",
       "      <td>-0.003341</td>\n",
       "      <td>-0.003316</td>\n",
       "      <td>-0.003289</td>\n",
       "      <td>-0.003263</td>\n",
       "      <td>-0.003236</td>\n",
       "      <td>-0.003209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>-0.000733</td>\n",
       "      <td>-0.003121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007373</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>-0.007754</td>\n",
       "      <td>-0.006247</td>\n",
       "      <td>-0.003583</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>-0.002472</td>\n",
       "      <td>-0.008282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.009750</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.004424</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>-0.004758</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>-0.008510</td>\n",
       "      <td>-0.000614</td>\n",
       "      <td>-0.004077</td>\n",
       "      <td>-0.013175</td>\n",
       "      <td>-0.004247</td>\n",
       "      <td>-0.002622</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1702 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.001835  0.000878  0.000793  0.000247  0.000728  0.001072  0.002347   \n",
       "1  0.003758 -0.002548  0.006330 -0.011134  0.000164  0.005120 -0.002903   \n",
       "2  0.001106  0.001177  0.001245  0.001310  0.001369  0.001383  0.001337   \n",
       "3  0.000363  0.003034  0.003668  0.002877  0.002038  0.000546  0.002638   \n",
       "4  0.003795  0.009750  0.001765  0.005447  0.004424  0.003195  0.001814   \n",
       "\n",
       "          7         8         9  ...      1692      1693      1694      1695  \\\n",
       "0  0.000115  0.000966  0.001123  ... -0.004829 -0.003905 -0.002224 -0.002386   \n",
       "1 -0.003049 -0.006294  0.003996  ...  0.004719 -0.009114 -0.001578 -0.002636   \n",
       "2  0.001292  0.001355  0.001509  ... -0.003414 -0.003390 -0.003366 -0.003341   \n",
       "3 -0.002580 -0.000733 -0.003121  ... -0.007373 -0.000276 -0.002173 -0.007754   \n",
       "4 -0.004758  0.005961  0.005176  ...  0.001135 -0.008510 -0.000614 -0.004077   \n",
       "\n",
       "       1696      1697      1698      1699      1700  substrate  \n",
       "0 -0.003332 -0.003701 -0.003463 -0.004489 -0.005034          1  \n",
       "1 -0.001219  0.000561 -0.004356  0.002053 -0.007237          1  \n",
       "2 -0.003316 -0.003289 -0.003263 -0.003236 -0.003209          1  \n",
       "3 -0.006247 -0.003583 -0.004043 -0.002472 -0.008282          1  \n",
       "4 -0.013175 -0.004247 -0.002622 -0.000083 -0.003888          1  \n",
       "\n",
       "[5 rows x 1702 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cent_subs['substrate']=ys\n",
    "cent_subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a936a6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003352</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>-0.003905</td>\n",
       "      <td>-0.002224</td>\n",
       "      <td>-0.002386</td>\n",
       "      <td>-0.003332</td>\n",
       "      <td>-0.003701</td>\n",
       "      <td>-0.003463</td>\n",
       "      <td>-0.004489</td>\n",
       "      <td>-0.005034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003758</td>\n",
       "      <td>-0.002548</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>-0.011134</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>-0.006294</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010454</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>-0.009114</td>\n",
       "      <td>-0.001578</td>\n",
       "      <td>-0.002636</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>-0.004356</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>-0.007237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003437</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>-0.003390</td>\n",
       "      <td>-0.003366</td>\n",
       "      <td>-0.003341</td>\n",
       "      <td>-0.003316</td>\n",
       "      <td>-0.003289</td>\n",
       "      <td>-0.003263</td>\n",
       "      <td>-0.003236</td>\n",
       "      <td>-0.003209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>-0.000733</td>\n",
       "      <td>-0.003121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002536</td>\n",
       "      <td>-0.007373</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>-0.007754</td>\n",
       "      <td>-0.006247</td>\n",
       "      <td>-0.003583</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>-0.002472</td>\n",
       "      <td>-0.008282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.009750</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.004424</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>-0.004758</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003264</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>-0.008510</td>\n",
       "      <td>-0.000614</td>\n",
       "      <td>-0.004077</td>\n",
       "      <td>-0.013175</td>\n",
       "      <td>-0.004247</td>\n",
       "      <td>-0.002622</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.003888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.001835  0.000878  0.000793  0.000247  0.000728  0.001072  0.002347   \n",
       "1  0.003758 -0.002548  0.006330 -0.011134  0.000164  0.005120 -0.002903   \n",
       "2  0.001106  0.001177  0.001245  0.001310  0.001369  0.001383  0.001337   \n",
       "3  0.000363  0.003034  0.003668  0.002877  0.002038  0.000546  0.002638   \n",
       "4  0.003795  0.009750  0.001765  0.005447  0.004424  0.003195  0.001814   \n",
       "\n",
       "       7         8         9     ...      1691      1692      1693      1694  \\\n",
       "0  0.000115  0.000966  0.001123  ... -0.003352 -0.004829 -0.003905 -0.002224   \n",
       "1 -0.003049 -0.006294  0.003996  ... -0.010454  0.004719 -0.009114 -0.001578   \n",
       "2  0.001292  0.001355  0.001509  ... -0.003437 -0.003414 -0.003390 -0.003366   \n",
       "3 -0.002580 -0.000733 -0.003121  ... -0.002536 -0.007373 -0.000276 -0.002173   \n",
       "4 -0.004758  0.005961  0.005176  ... -0.003264  0.001135 -0.008510 -0.000614   \n",
       "\n",
       "       1695      1696      1697      1698      1699      1700  \n",
       "0 -0.002386 -0.003332 -0.003701 -0.003463 -0.004489 -0.005034  \n",
       "1 -0.002636 -0.001219  0.000561 -0.004356  0.002053 -0.007237  \n",
       "2 -0.003341 -0.003316 -0.003289 -0.003263 -0.003236 -0.003209  \n",
       "3 -0.007754 -0.006247 -0.003583 -0.004043 -0.002472 -0.008282  \n",
       "4 -0.004077 -0.013175 -0.004247 -0.002622 -0.000083 -0.003888  \n",
       "\n",
       "[5 rows x 1701 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "b=cent_subs.iloc[:,0:1701]\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd11175f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009607</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.012284</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.005881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017547</td>\n",
       "      <td>-0.025276</td>\n",
       "      <td>-0.020442</td>\n",
       "      <td>-0.011642</td>\n",
       "      <td>-0.012491</td>\n",
       "      <td>-0.017440</td>\n",
       "      <td>-0.019376</td>\n",
       "      <td>-0.018127</td>\n",
       "      <td>-0.023498</td>\n",
       "      <td>-0.026352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013683</td>\n",
       "      <td>-0.009277</td>\n",
       "      <td>0.023046</td>\n",
       "      <td>-0.040534</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.018640</td>\n",
       "      <td>-0.010568</td>\n",
       "      <td>-0.011098</td>\n",
       "      <td>-0.022913</td>\n",
       "      <td>0.014546</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038060</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>-0.033179</td>\n",
       "      <td>-0.005745</td>\n",
       "      <td>-0.009596</td>\n",
       "      <td>-0.004439</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>-0.015857</td>\n",
       "      <td>0.007474</td>\n",
       "      <td>-0.026345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.006659</td>\n",
       "      <td>0.007008</td>\n",
       "      <td>0.007325</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018391</td>\n",
       "      <td>-0.018267</td>\n",
       "      <td>-0.018138</td>\n",
       "      <td>-0.018009</td>\n",
       "      <td>-0.017876</td>\n",
       "      <td>-0.017742</td>\n",
       "      <td>-0.017598</td>\n",
       "      <td>-0.017460</td>\n",
       "      <td>-0.017316</td>\n",
       "      <td>-0.017168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>0.017369</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.012490</td>\n",
       "      <td>-0.012215</td>\n",
       "      <td>-0.003470</td>\n",
       "      <td>-0.014777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012008</td>\n",
       "      <td>-0.034912</td>\n",
       "      <td>-0.001307</td>\n",
       "      <td>-0.010292</td>\n",
       "      <td>-0.036719</td>\n",
       "      <td>-0.029583</td>\n",
       "      <td>-0.016964</td>\n",
       "      <td>-0.019143</td>\n",
       "      <td>-0.011705</td>\n",
       "      <td>-0.039219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.036012</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.020120</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>-0.017573</td>\n",
       "      <td>0.022017</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>-0.031434</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.015060</td>\n",
       "      <td>-0.048664</td>\n",
       "      <td>-0.015689</td>\n",
       "      <td>-0.009685</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>-0.014363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.009607  0.004595  0.004153  0.001293  0.003809  0.005611  0.012284   \n",
       "1  0.013683 -0.009277  0.023046 -0.040534  0.000598  0.018640 -0.010568   \n",
       "2  0.005920  0.006296  0.006659  0.007008  0.007325  0.007399  0.007152   \n",
       "3  0.001720  0.014365  0.017369  0.013624  0.009649  0.002587  0.012490   \n",
       "4  0.014017  0.036012  0.006521  0.020120  0.016342  0.011801  0.006702   \n",
       "\n",
       "       7         8         9     ...      1691      1692      1693      1694  \\\n",
       "0  0.000603  0.005059  0.005881  ... -0.017547 -0.025276 -0.020442 -0.011642   \n",
       "1 -0.011098 -0.022913  0.014546  ... -0.038060  0.017181 -0.033179 -0.005745   \n",
       "2  0.006912  0.007250  0.008074  ... -0.018391 -0.018267 -0.018138 -0.018009   \n",
       "3 -0.012215 -0.003470 -0.014777  ... -0.012008 -0.034912 -0.001307 -0.010292   \n",
       "4 -0.017573  0.022017  0.019119  ... -0.012055  0.004192 -0.031434 -0.002269   \n",
       "\n",
       "       1695      1696      1697      1698      1699      1700  \n",
       "0 -0.012491 -0.017440 -0.019376 -0.018127 -0.023498 -0.026352  \n",
       "1 -0.009596 -0.004439  0.002042 -0.015857  0.007474 -0.026345  \n",
       "2 -0.017876 -0.017742 -0.017598 -0.017460 -0.017316 -0.017168  \n",
       "3 -0.036719 -0.029583 -0.016964 -0.019143 -0.011705 -0.039219  \n",
       "4 -0.015060 -0.048664 -0.015689 -0.009685 -0.000306 -0.014363  \n",
       "\n",
       "[5 rows x 1701 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize(b)\n",
    "b1=b.apply(lambda x: x/(x**2).sum()**.5, axis=1)\n",
    "b1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4f168b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "      <th>substrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009607</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.012284</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.005881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025276</td>\n",
       "      <td>-0.020442</td>\n",
       "      <td>-0.011642</td>\n",
       "      <td>-0.012491</td>\n",
       "      <td>-0.017440</td>\n",
       "      <td>-0.019376</td>\n",
       "      <td>-0.018127</td>\n",
       "      <td>-0.023498</td>\n",
       "      <td>-0.026352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013683</td>\n",
       "      <td>-0.009277</td>\n",
       "      <td>0.023046</td>\n",
       "      <td>-0.040534</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.018640</td>\n",
       "      <td>-0.010568</td>\n",
       "      <td>-0.011098</td>\n",
       "      <td>-0.022913</td>\n",
       "      <td>0.014546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>-0.033179</td>\n",
       "      <td>-0.005745</td>\n",
       "      <td>-0.009596</td>\n",
       "      <td>-0.004439</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>-0.015857</td>\n",
       "      <td>0.007474</td>\n",
       "      <td>-0.026345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.006659</td>\n",
       "      <td>0.007008</td>\n",
       "      <td>0.007325</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018267</td>\n",
       "      <td>-0.018138</td>\n",
       "      <td>-0.018009</td>\n",
       "      <td>-0.017876</td>\n",
       "      <td>-0.017742</td>\n",
       "      <td>-0.017598</td>\n",
       "      <td>-0.017460</td>\n",
       "      <td>-0.017316</td>\n",
       "      <td>-0.017168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>0.017369</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.012490</td>\n",
       "      <td>-0.012215</td>\n",
       "      <td>-0.003470</td>\n",
       "      <td>-0.014777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034912</td>\n",
       "      <td>-0.001307</td>\n",
       "      <td>-0.010292</td>\n",
       "      <td>-0.036719</td>\n",
       "      <td>-0.029583</td>\n",
       "      <td>-0.016964</td>\n",
       "      <td>-0.019143</td>\n",
       "      <td>-0.011705</td>\n",
       "      <td>-0.039219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.036012</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.020120</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>-0.017573</td>\n",
       "      <td>0.022017</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>-0.031434</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.015060</td>\n",
       "      <td>-0.048664</td>\n",
       "      <td>-0.015689</td>\n",
       "      <td>-0.009685</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>-0.014363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1702 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.009607  0.004595  0.004153  0.001293  0.003809  0.005611  0.012284   \n",
       "1  0.013683 -0.009277  0.023046 -0.040534  0.000598  0.018640 -0.010568   \n",
       "2  0.005920  0.006296  0.006659  0.007008  0.007325  0.007399  0.007152   \n",
       "3  0.001720  0.014365  0.017369  0.013624  0.009649  0.002587  0.012490   \n",
       "4  0.014017  0.036012  0.006521  0.020120  0.016342  0.011801  0.006702   \n",
       "\n",
       "          7         8         9  ...      1692      1693      1694      1695  \\\n",
       "0  0.000603  0.005059  0.005881  ... -0.025276 -0.020442 -0.011642 -0.012491   \n",
       "1 -0.011098 -0.022913  0.014546  ...  0.017181 -0.033179 -0.005745 -0.009596   \n",
       "2  0.006912  0.007250  0.008074  ... -0.018267 -0.018138 -0.018009 -0.017876   \n",
       "3 -0.012215 -0.003470 -0.014777  ... -0.034912 -0.001307 -0.010292 -0.036719   \n",
       "4 -0.017573  0.022017  0.019119  ...  0.004192 -0.031434 -0.002269 -0.015060   \n",
       "\n",
       "       1696      1697      1698      1699      1700  substrate  \n",
       "0 -0.017440 -0.019376 -0.018127 -0.023498 -0.026352          1  \n",
       "1 -0.004439  0.002042 -0.015857  0.007474 -0.026345          1  \n",
       "2 -0.017742 -0.017598 -0.017460 -0.017316 -0.017168          1  \n",
       "3 -0.029583 -0.016964 -0.019143 -0.011705 -0.039219          1  \n",
       "4 -0.048664 -0.015689 -0.009685 -0.000306 -0.014363          1  \n",
       "\n",
       "[5 rows x 1702 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1['substrate']=ys\n",
    "b1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f88dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=np.array(dfsub1['Analyte'].values.tolist())\n",
    "a2=np.array(dfsub2['Analyte'].values.tolist())\n",
    "a3=np.array(dfsub3['Analyte'].values.tolist())\n",
    "a4=np.array(dfsub4['Analyte'].values.tolist())\n",
    "a5=np.array(dfsub5['Analyte'].values.tolist())\n",
    "a6=np.array(dfsub6['Analyte'].values.tolist())\n",
    "a7=np.array(dfsub7['Analyte'].values.tolist())\n",
    "a8=np.array(dfsub8['Analyte'].values.tolist())\n",
    "a9=np.array(dfsub9['Analyte'].values.tolist())\n",
    "y=np.concatenate((a1,a2,a3,a4,a5,a6,a7,a8,a9),axis=None)\n",
    "#print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f523094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:\n",
      "(39600, 1701)\n",
      "Test dimension:\n",
      "(9900, 1701)\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39600, 55)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, roc_auc_score, ConfusionMatrixDisplay\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "# Configuration options\n",
    "feature_vector_length = 1701\n",
    "num_classes = 55\n",
    "X=b1.iloc[:,0:1701]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "# Convert target classes to categorical ones\n",
    "Ytrain=Y_train-1\n",
    "Ytest=Y_test-1\n",
    "Y_train = to_categorical(ytrain, num_classes)\n",
    "Y_test = to_categorical(ytest, num_classes)\n",
    "print('Train dimension:')\n",
    "print(X_train.shape)\n",
    "print('Test dimension:')\n",
    "print(X_test.shape)\n",
    "X_train=X_train.to_numpy()\n",
    "X_test=X_test.to_numpy()\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "n_classes = len(np.unique(Y_train))\n",
    "print(n_classes)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2e826e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c470b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e65d1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 1701, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 1701, 1)     2           ['input_3[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 1701, 1)     449         ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 1701, 1)      0           ['multi_head_attention_8[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 1701, 1)     0           ['dropout_18[0][0]',             \n",
      " ambda)                                                           'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 1701, 1)     2           ['tf.__operators__.add_16[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 1701, 4)      8           ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 1701, 4)      0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 1701, 1)      5           ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 1701, 1)     0           ['conv1d_17[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_16[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 1701, 1)     2           ['tf.__operators__.add_17[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 1701, 1)     449         ['layer_normalization_18[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 1701, 1)      0           ['multi_head_attention_9[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 1701, 1)     0           ['dropout_20[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_17[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 1701, 1)     2           ['tf.__operators__.add_18[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 1701, 4)      8           ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 1701, 4)      0           ['conv1d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 1701, 1)      5           ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 1701, 1)     0           ['conv1d_19[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_18[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 1701, 1)     2           ['tf.__operators__.add_19[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 1701, 1)     449         ['layer_normalization_20[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 1701, 1)      0           ['multi_head_attention_10[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 1701, 1)     0           ['dropout_22[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_19[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 1701, 1)     2           ['tf.__operators__.add_20[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 1701, 4)      8           ['layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 1701, 4)      0           ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 1701, 1)      5           ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 1701, 1)     0           ['conv1d_21[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_20[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 1701, 1)     2           ['tf.__operators__.add_21[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 1701, 1)     449         ['layer_normalization_22[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 1701, 1)      0           ['multi_head_attention_11[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (TFOpL  (None, 1701, 1)     0           ['dropout_24[0][0]',             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ambda)                                                           'tf.__operators__.add_21[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 1701, 1)     2           ['tf.__operators__.add_22[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 1701, 4)      8           ['layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 1701, 4)      0           ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 1701, 1)      5           ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  (None, 1701, 1)     0           ['conv1d_23[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_22[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 1701)        0           ['tf.__operators__.add_23[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 32)           54464       ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 32)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 55)           1815        ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 58,143\n",
      "Trainable params: 58,143\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      " 42/495 [=>............................] - ETA: 21:35:58 - loss: 4.0065 - accuracy: 0.0205"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=16,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[32],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8c6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
