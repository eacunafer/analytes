{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-Analytes Classification on the  preprocessed data using MLP\n",
    "### Edgar Acuna\n",
    "###  June 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tempfile\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataframe: (18000, 1701)\n"
     ]
    }
   ],
   "source": [
    "df1=pd.read_csv(\"c://onr2020/NRLset1_part1.csv\",header=None)\n",
    "df2=pd.read_csv(\"c://onr2020/NRLset1_part2.csv\",header=None)\n",
    "df3=pd.read_csv(\"c://onr2020/NRLset1_part3.csv\",header=None)\n",
    "df4=pd.read_csv(\"c://onr2020/NRLset1_part4.csv\",header=None)\n",
    "df5=pd.read_csv(\"c://onr2020/NRLset1_part5.csv\",header=None)\n",
    "df6=pd.read_csv(\"c://onr2020/NRLset1_part6.csv\",header=None)\n",
    "df7=pd.read_csv(\"c://onr2020/NRLset1_part7.csv\",header=None)\n",
    "df8=pd.read_csv(\"c://onr2020/NRLset1_part8.csv\",header=None)\n",
    "y=pd.read_csv(\"c://onr2020/labels.csv\",header=None)\n",
    "ys=pd.read_csv(\"c://onr2020/substrateIDs.csv\",header=None)\n",
    "subs=pd.read_csv(\"c://onr2020/substrates.csv\",header=None)\n",
    "dfset1=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8],ignore_index=True)\n",
    "print('Size of the dataframe: {}'.format(dfset1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataframe: (9, 1701)\n"
     ]
    }
   ],
   "source": [
    "print('Size of the dataframe: {}'.format(subs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfset2=dfset1.copy()\n",
    "dfset2['Analyte']=y\n",
    "dfset2['substrate']=ys\n",
    "dfsub1=dfset2[dfset2['substrate']==1]\n",
    "dfsub2=dfset2[dfset2['substrate']==2]\n",
    "dfsub3=dfset2[dfset2['substrate']==3]\n",
    "dfsub4=dfset2[dfset2['substrate']==4]\n",
    "dfsub5=dfset2[dfset2['substrate']==5]\n",
    "dfsub6=dfset2[dfset2['substrate']==6]\n",
    "dfsub7=dfset2[dfset2['substrate']==7]\n",
    "dfsub8=dfset2[dfset2['substrate']==8]\n",
    "dfsub9=dfset2[dfset2['substrate']==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfsub1=dfsub1.iloc[:,0:1701]\n",
    "mdfsub2=dfsub2.iloc[:,0:1701]\n",
    "mdfsub3=dfsub3.iloc[:,0:1701]\n",
    "mdfsub4=dfsub4.iloc[:,0:1701]\n",
    "mdfsub5=dfsub5.iloc[:,0:1701]\n",
    "mdfsub6=dfsub6.iloc[:,0:1701]\n",
    "mdfsub7=dfsub7.iloc[:,0:1701]\n",
    "mdfsub8=dfsub8.iloc[:,0:1701]\n",
    "mdfsub9=dfsub9.iloc[:,0:1701]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=subs.loc[0,:]\n",
    "y2=subs.loc[1,:]\n",
    "y3=subs.loc[2,:]\n",
    "y4=subs.loc[3,:]\n",
    "y5=subs.loc[4,:]\n",
    "y6=subs.loc[5,:]\n",
    "y7=subs.loc[6,:]\n",
    "y8=subs.loc[7,:]\n",
    "y9=subs.loc[8,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modsub1=mdfsub1.apply(lambda x : x -(np.sum(np.array(x)*np.array(y1))/np.sum(np.array(y1)*np.array(y1)))*y1,axis=1)\n",
    "modsub2=mdfsub2.apply(lambda x : x -(np.sum(np.array(x)*np.array(y2))/np.sum(np.array(y2)*np.array(y2)))*y2,axis=1)\n",
    "modsub3=mdfsub3.apply(lambda x : x -(np.sum(np.array(x)*np.array(y3))/np.sum(np.array(y3)*np.array(y3)))*y3,axis=1)\n",
    "modsub4=mdfsub4.apply(lambda x : x -(np.sum(np.array(x)*np.array(y4))/np.sum(np.array(y4)*np.array(y4)))*y4,axis=1)\n",
    "modsub5=mdfsub5.apply(lambda x : x -(np.sum(np.array(x)*np.array(y5))/np.sum(np.array(y5)*np.array(y5)))*y5,axis=1)\n",
    "modsub6=mdfsub6.apply(lambda x : x -(np.sum(np.array(x)*np.array(y6))/np.sum(np.array(y6)*np.array(y6)))*y6,axis=1)\n",
    "modsub7=mdfsub7.apply(lambda x : x -(np.sum(np.array(x)*np.array(y7))/np.sum(np.array(y7)*np.array(y7)))*y7,axis=1)\n",
    "modsub8=mdfsub8.apply(lambda x : x -(np.sum(np.array(x)*np.array(y8))/np.sum(np.array(y8)*np.array(y8)))*y8,axis=1)\n",
    "modsub9=mdfsub9.apply(lambda x : x -(np.sum(np.array(x)*np.array(y9))/np.sum(np.array(y9)*np.array(y9)))*y9,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001858</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>-0.002143</td>\n",
       "      <td>-0.004422</td>\n",
       "      <td>-0.003123</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>-0.001225</td>\n",
       "      <td>-0.001406</td>\n",
       "      <td>-0.002792</td>\n",
       "      <td>-0.002432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.005471</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>-0.005149</td>\n",
       "      <td>-0.001717</td>\n",
       "      <td>-0.003814</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.005481</td>\n",
       "      <td>-0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.002496</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>-0.015160</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>-0.018040</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.006529</td>\n",
       "      <td>0.009548</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.018158</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.007582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004576</td>\n",
       "      <td>-0.004550</td>\n",
       "      <td>-0.004524</td>\n",
       "      <td>-0.004502</td>\n",
       "      <td>-0.004476</td>\n",
       "      <td>-0.004446</td>\n",
       "      <td>-0.004411</td>\n",
       "      <td>-0.004373</td>\n",
       "      <td>-0.004332</td>\n",
       "      <td>-0.004301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.001097</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>-0.006438</td>\n",
       "      <td>-0.005102</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>-0.004804</td>\n",
       "      <td>-0.005517</td>\n",
       "      <td>-0.004411</td>\n",
       "      <td>-0.005738</td>\n",
       "      <td>-0.005031</td>\n",
       "      <td>-0.005584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "4   0.002296  0.002603  0.002368  0.003507  0.003637  0.003537  0.004850   \n",
       "5  -0.005471  0.003865  0.000351 -0.000060 -0.000258 -0.000582  0.002557   \n",
       "8  -0.002496  0.016867  0.014204  0.005327  0.003649  0.006143 -0.015160   \n",
       "28  0.001313  0.001443  0.001536  0.001612  0.001687  0.001768  0.001866   \n",
       "46 -0.001097  0.000040  0.001125  0.002056  0.001685  0.002006  0.000228   \n",
       "\n",
       "        7         8         9     ...      1691      1692      1693      1694  \\\n",
       "4   0.005059  0.004744  0.006244  ... -0.001858 -0.002531 -0.002143 -0.004422   \n",
       "5   0.003072  0.000961  0.003941  ... -0.004245 -0.001915 -0.005149 -0.001717   \n",
       "8   0.004201  0.003791  0.004599  ...  0.002574 -0.018040 -0.018488 -0.006529   \n",
       "28  0.001979  0.002079  0.002155  ... -0.004576 -0.004550 -0.004524 -0.004502   \n",
       "46  0.001179  0.001835  0.002005  ... -0.004655 -0.006438 -0.005102 -0.005563   \n",
       "\n",
       "        1695      1696      1697      1698      1699      1700  \n",
       "4  -0.003123 -0.000884 -0.001225 -0.001406 -0.002792 -0.002432  \n",
       "5  -0.003814 -0.003100 -0.000355 -0.000540 -0.005481 -0.000857  \n",
       "8   0.009548  0.004694  0.000399  0.018158  0.016369  0.007582  \n",
       "28 -0.004476 -0.004446 -0.004411 -0.004373 -0.004332 -0.004301  \n",
       "46 -0.004804 -0.005517 -0.004411 -0.005738 -0.005031 -0.005584  \n",
       "\n",
       "[5 rows x 1701 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf=[modsub1,modsub2,modsub3,modsub4,modsub5,modsub6,modsub7,modsub8,modsub9]\n",
    "cent_subs=pd.concat(subdf)\n",
    "cent_subs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001858</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>-0.002143</td>\n",
       "      <td>-0.004422</td>\n",
       "      <td>-0.003123</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>-0.001225</td>\n",
       "      <td>-0.001406</td>\n",
       "      <td>-0.002792</td>\n",
       "      <td>-0.002432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.005471</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>-0.005149</td>\n",
       "      <td>-0.001717</td>\n",
       "      <td>-0.003814</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.005481</td>\n",
       "      <td>-0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.002496</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>-0.015160</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>-0.018040</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.006529</td>\n",
       "      <td>0.009548</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.018158</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.007582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004576</td>\n",
       "      <td>-0.004550</td>\n",
       "      <td>-0.004524</td>\n",
       "      <td>-0.004502</td>\n",
       "      <td>-0.004476</td>\n",
       "      <td>-0.004446</td>\n",
       "      <td>-0.004411</td>\n",
       "      <td>-0.004373</td>\n",
       "      <td>-0.004332</td>\n",
       "      <td>-0.004301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.001097</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>-0.006438</td>\n",
       "      <td>-0.005102</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>-0.004804</td>\n",
       "      <td>-0.005517</td>\n",
       "      <td>-0.004411</td>\n",
       "      <td>-0.005738</td>\n",
       "      <td>-0.005031</td>\n",
       "      <td>-0.005584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "4   0.002296  0.002603  0.002368  0.003507  0.003637  0.003537  0.004850   \n",
       "5  -0.005471  0.003865  0.000351 -0.000060 -0.000258 -0.000582  0.002557   \n",
       "8  -0.002496  0.016867  0.014204  0.005327  0.003649  0.006143 -0.015160   \n",
       "28  0.001313  0.001443  0.001536  0.001612  0.001687  0.001768  0.001866   \n",
       "46 -0.001097  0.000040  0.001125  0.002056  0.001685  0.002006  0.000228   \n",
       "\n",
       "        7         8         9     ...      1691      1692      1693      1694  \\\n",
       "4   0.005059  0.004744  0.006244  ... -0.001858 -0.002531 -0.002143 -0.004422   \n",
       "5   0.003072  0.000961  0.003941  ... -0.004245 -0.001915 -0.005149 -0.001717   \n",
       "8   0.004201  0.003791  0.004599  ...  0.002574 -0.018040 -0.018488 -0.006529   \n",
       "28  0.001979  0.002079  0.002155  ... -0.004576 -0.004550 -0.004524 -0.004502   \n",
       "46  0.001179  0.001835  0.002005  ... -0.004655 -0.006438 -0.005102 -0.005563   \n",
       "\n",
       "        1695      1696      1697      1698      1699      1700  \n",
       "4  -0.003123 -0.000884 -0.001225 -0.001406 -0.002792 -0.002432  \n",
       "5  -0.003814 -0.003100 -0.000355 -0.000540 -0.005481 -0.000857  \n",
       "8   0.009548  0.004694  0.000399  0.018158  0.016369  0.007582  \n",
       "28 -0.004476 -0.004446 -0.004411 -0.004373 -0.004332 -0.004301  \n",
       "46 -0.004804 -0.005517 -0.004411 -0.005738 -0.005031 -0.005584  \n",
       "\n",
       "[5 rows x 1701 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=cent_subs.iloc[:,0:1701]\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 1701)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize(b)\n",
    "b1=b.apply(lambda x: x/(x**2).sum()**.5, axis=1)\n",
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=np.array(dfsub1['Analyte'].values.tolist())\n",
    "a2=np.array(dfsub2['Analyte'].values.tolist())\n",
    "a3=np.array(dfsub3['Analyte'].values.tolist())\n",
    "a4=np.array(dfsub4['Analyte'].values.tolist())\n",
    "a5=np.array(dfsub5['Analyte'].values.tolist())\n",
    "a6=np.array(dfsub6['Analyte'].values.tolist())\n",
    "a7=np.array(dfsub7['Analyte'].values.tolist())\n",
    "a8=np.array(dfsub8['Analyte'].values.tolist())\n",
    "a9=np.array(dfsub9['Analyte'].values.tolist())\n",
    "y=np.concatenate((a1,a2,a3,a4,a5,a6,a7,a8,a9),axis=None)\n",
    "#print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:\n",
      "(14400, 1701)\n",
      "Test dimension:\n",
      "(3600, 1701)\n"
     ]
    }
   ],
   "source": [
    "# Configuration options\n",
    "feature_vector_length = 1701\n",
    "num_classes = 18000\n",
    "X=b1.iloc[:,0:1701]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "# Convert target classes to categorical ones\n",
    "ytrain=Y_train\n",
    "ytest=Y_test\n",
    "Y_train = to_categorical(Y_train, num_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes)\n",
    "print('Train dimension:')\n",
    "print(X_train.shape)\n",
    "print('Test dimension:')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1701\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(14400, 1, 1701)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-306af2b446de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# reshaping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1701\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    297\u001b[0m            [5, 6]])\n\u001b[0;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[1;34m(self, result, context)\u001b[0m\n\u001b[0;32m   1927\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_axes_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_ORDERS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1929\u001b[1;33m         return self._constructor(result, **d).__finalize__(\n\u001b[0m\u001b[0;32m   1930\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"__array_wrap__\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1931\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    556\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;31m# by definition an array here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prep_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_dtype_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_prep_ndarray\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Must pass 2-d input. shape={values.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(14400, 1, 1701)"
     ]
    }
   ],
   "source": [
    "# reshaping\n",
    "print(X_train.shape[1])            \n",
    "X_train=np.reshape(X_train,(14400,1,1701))\n",
    "#X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input shape\n",
    "#input_shape = (feature_vector_length,)\n",
    "#print(f'Feature shape: {input_shape}')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, input_shape=(300,1701)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(40, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_8 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 1701]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-66709acbd67e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mbaseline_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_8 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 1701]\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "import time\n",
    "start_time = time.time()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "baseline_history=model.fit(X_train, Y_train, epochs=100, batch_size=150, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model after training\n",
    "test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(test_results)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-7b108664374f>:6: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "f1_scores in training set 0.9903507362154318 f1_scores in testing set 0.9475780810594095\n"
     ]
    }
   ],
   "source": [
    "#Computing F1-score\n",
    "train_features = np.array(X_train)\n",
    "test_features = np.array(X_test)\n",
    "train_labels=np.array(Y_train)\n",
    "test_labels=np.array(Y_test)\n",
    "train_predictions_baseline = model.predict_classes(train_features, batch_size=150)\n",
    "f1_train=sklearn.metrics.f1_score(ytrain, train_predictions_baseline, average=\"weighted\")\n",
    "test_predictions_baseline = model.predict_classes(test_features, batch_size=150)\n",
    "f1_test=sklearn.metrics.f1_score(ytest, test_predictions_baseline, average=\"weighted\")\n",
    "print('f1_scores in training set',f1_train,'f1_scores in testing set',f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77/77 [==============================] - 5s 61ms/step - loss: 3.1326 - accuracy: 1.0000 - precision: 0.9757 - recall: 0.5810 - val_loss: 0.1788 - val_accuracy: 1.0000 - val_precision: 0.9750 - val_recall: 0.9611\n",
      "Epoch 2/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 0.1562 - accuracy: 1.0000 - precision: 0.9741 - recall: 0.9693 - val_loss: 0.1289 - val_accuracy: 1.0000 - val_precision: 0.9749 - val_recall: 0.9726\n",
      "Epoch 3/200\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 0.1014 - accuracy: 1.0000 - precision: 0.9744 - recall: 0.9743 - val_loss: 0.0655 - val_accuracy: 1.0000 - val_precision: 0.9785 - val_recall: 0.9778\n",
      "Epoch 4/200\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 0.0370 - accuracy: 1.0000 - precision: 0.9889 - recall: 0.9889 - val_loss: 0.0206 - val_accuracy: 1.0000 - val_precision: 0.9955 - val_recall: 0.9951\n",
      "Epoch 5/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 0.0129 - accuracy: 1.0000 - precision: 0.9968 - recall: 0.9967 - val_loss: 0.0104 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 6/200\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 0.0054 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 0.0084 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 7/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 0.0035 - accuracy: 1.0000 - precision: 0.9996 - recall: 0.9995 - val_loss: 0.0074 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 8/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 0.0018 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 9/200\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 0.0015 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0078 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 10/200\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9999 - val_loss: 0.0074 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 11/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 9.6878e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0076 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 12/200\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 8.7097e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0077 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 13/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.7730e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0076 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 14/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.0139e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 15/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.4721e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 16/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 4.1779e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0080 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 17/200\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 2.5660e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 18/200\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 3.6819e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 19/200\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 2.5412e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 20/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 3.1951e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0091 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 21/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 2.7427e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 22/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.2853e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0102 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 23/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.7081e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 24/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.9891e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 25/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.6533e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 26/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.2659e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 27/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.4435e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 28/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.1654e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 29/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.0442e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 30/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.0392e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 31/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.5231e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 32/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 2.0109e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 33/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 9.7593e-04 - accuracy: 1.0000 - precision: 0.9995 - recall: 0.9995 - val_loss: 0.0125 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 34/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.0029e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 35/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 9.1352e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 36/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.9407e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0131 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 3.5530e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0123 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 38/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.5102e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 39/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 6.4129e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 40/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 8.0481e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 41/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.8320e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 42/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 6.9350e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 43/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.0374e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 44/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 3.2138e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0117 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 45/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 6.5228e-04 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.0116 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 46/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.4130e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000 - val_precision: 0.9976 - val_recall: 0.9976\n",
      "Epoch 47/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.8309e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0138 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 48/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.4926e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 49/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 9.5252e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 50/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 2.5060e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 51/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 3.7432e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 52/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 8.5812e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 53/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 4.2251e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 54/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 2.3882e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 55/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 1.3627e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0162 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 56/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 6.7426e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 57/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 2.2063e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 58/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.0190e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 59/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 3.1274e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 60/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 0.9996 - recall: 0.9996 - val_loss: 0.0191 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 61/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 7.7128e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 62/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.2697e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 63/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.4824e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 64/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 7.4665e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 65/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 0.0018 - accuracy: 1.0000 - precision: 0.9996 - recall: 0.9996 - val_loss: 0.0227 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 66/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 2.7848e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0168 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 67/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.3121e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 68/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 3.9406e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 69/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.0484e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 70/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.3007e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0194 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 71/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 0.0020 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 0.0170 - val_accuracy: 1.0000 - val_precision: 0.9976 - val_recall: 0.9976\n",
      "Epoch 72/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 4.7923e-04 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.0178 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 7.2454e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 74/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.4515e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 75/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 9.0459e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 76/200\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 1.9101e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0210 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 77/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 3.3106e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 78/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.4846e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 79/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 2.4882e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 80/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 2.7474e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 81/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 2.6610e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 82/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.6948e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0171 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 83/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 6.2235e-04 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.0240 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 84/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 3.2072e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 85/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.9770e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 86/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 5.3669e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0173 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 87/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.7546e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 88/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 3.9016e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0246 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 89/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 0.0014 - accuracy: 1.0000 - precision: 0.9996 - recall: 0.9996 - val_loss: 0.0179 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 90/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 2.1457e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 91/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 2.5846e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0196 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 92/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.1926e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 93/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 2.4110e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 94/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.5669e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 95/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 6.9717e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 96/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.8588e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 97/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 7.1575e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0192 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 98/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.4440e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 99/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 2.0645e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0311 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 100/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 8.1309e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0240 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9976\n",
      "Epoch 101/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.9785e-04 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.0263 - val_accuracy: 1.0000 - val_precision: 0.9976 - val_recall: 0.9972\n",
      "Epoch 102/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.6868e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 103/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.6011e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0199 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 104/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 2.3818e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0165 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 105/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 6.4167e-04 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.0182 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 106/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 4.1051e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0200 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 107/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 3.5387e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 108/200\n",
      "77/77 [==============================] - 5s 58ms/step - loss: 2.7034e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0216 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 1.9842e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 110/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.5150e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 111/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 3.8580e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 112/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 1.0132e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 113/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 2.6942e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0227 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 114/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.3615e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0199 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 115/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.8701e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 116/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.9185e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 117/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.9942e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 118/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 4.4879e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 119/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 2.9251e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 120/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 2.0866e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0227 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983.9458e-06 - accuracy: 1.0000 - precision: 1.00\n",
      "Epoch 121/200\n",
      "77/77 [==============================] - 5s 58ms/step - loss: 3.6726e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 122/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 9.7426e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 123/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 0.0014 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.0195 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 124/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 2.8682e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0211 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 125/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.5784e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0185 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 126/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 3.7141e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0239 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 127/200\n",
      "77/77 [==============================] - 5s 58ms/step - loss: 8.5865e-05 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0198 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 128/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.7066e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0240 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 129/200\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 1.5722e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0233 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9976\n",
      "Epoch 130/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 8.9481e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9976\n",
      "Epoch 131/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 2.7005e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0236 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 132/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.9075e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0247 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 133/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 2.0347e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9976\n",
      "Epoch 134/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 2.5423e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 135/200\n",
      "77/77 [==============================] - 5s 58ms/step - loss: 3.0919e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 136/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 4.7555e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 137/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 8.7540e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 138/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 4.2332e-04 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.0256 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 139/200\n",
      "77/77 [==============================] - 5s 63ms/step - loss: 3.5934e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0315 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 140/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.9482e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0274 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 141/200\n",
      "77/77 [==============================] - 5s 58ms/step - loss: 5.6439e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 142/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 1.3506e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 143/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 2.7216e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 144/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.3282e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 145/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 1.7275e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 146/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 2.5153e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 147/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 1.6256e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0435 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 148/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 0.0041 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 0.0207 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9979\n",
      "Epoch 149/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 9.3345e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 150/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 1.6919e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9979\n",
      "Epoch 151/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 5.6470e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 152/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 3.8225e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0182 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 153/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 1.0500e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0233 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 154/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 2.7889e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9979\n",
      "Epoch 155/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 5.5603e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 156/200\n",
      "77/77 [==============================] - 5s 63ms/step - loss: 1.8343e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 157/200\n",
      "77/77 [==============================] - 5s 58ms/step - loss: 4.9579e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 158/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 7.1815e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0220 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 159/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 1.1649e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 160/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 1.9261e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 161/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 1.7010e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 162/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 4.6514e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 163/200\n",
      "77/77 [==============================] - 5s 61ms/step - loss: 1.4939e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0345 - val_accuracy: 1.0000 - val_precision: 0.9972 - val_recall: 0.9969\n",
      "Epoch 164/200\n",
      "77/77 [==============================] - 5s 62ms/step - loss: 9.4049e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 165/200\n",
      "77/77 [==============================] - 5s 62ms/step - loss: 1.5953e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 166/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 6.4755e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 167/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 3.2239e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0211 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 168/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0208 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 169/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 3.6439e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0292 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 170/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 1.8670e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0250 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 171/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 9.6587e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 172/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 5.2722e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0280 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 173/200\n",
      "77/77 [==============================] - 5s 58ms/step - loss: 2.5844e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0313 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 174/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 1.4588e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0283 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 175/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 3.3170e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0167 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 176/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 8.3192e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 177/200\n",
      "77/77 [==============================] - 5s 61ms/step - loss: 2.9608e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 178/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 3.0888e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 179/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 2.1811e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0213 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 1.3262e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 181/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 1.2111e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0285 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 182/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 7.7029e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 183/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 2.0251e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 184/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 7.4812e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 185/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 2.4995e-04 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0212 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 186/200\n",
      "77/77 [==============================] - 5s 58ms/step - loss: 6.8485e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 187/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 2.5777e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 188/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 1.2217e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 189/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 3.1058e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0229 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9979\n",
      "Epoch 190/200\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 3.9076e-04 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.0177 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9986\n",
      "Epoch 191/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 9.2681e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9983\n",
      "Epoch 192/200\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 4.6521e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 193/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 4.8998e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 194/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 2.0892e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 195/200\n",
      "77/77 [==============================] - 5s 61ms/step - loss: 9.8945e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 196/200\n",
      "77/77 [==============================] - 5s 62ms/step - loss: 8.3659e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 197/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 1.9604e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 198/200\n",
      "77/77 [==============================] - 5s 61ms/step - loss: 6.7319e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 199/200\n",
      "77/77 [==============================] - 5s 61ms/step - loss: 3.7445e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 200/200\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 3.7037e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0181 - accuracy: 1.0000 - precision: 0.9989 - recall: 0.9989\n",
      "metrics for analyte 10 f1_scores, training set [0.99982185 0.99317872] f1_scores in testing set [0.99943198 0.97468354]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 18000\n",
    "#labels1=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40\n",
    "labels1=list(range(10,11))\n",
    "#labels1=[3,26]\n",
    "import time\n",
    "start_time=time.time()\n",
    "for j in labels1:\n",
    "    yclass=y.copy()\n",
    "    yclass[yclass!=j]=0 \n",
    "    yclass[yclass==j]=1\n",
    "    X_train, X_test, yclass_train, yclass_test = train_test_split(X,yclass,test_size=0.2,random_state=0)\n",
    "    #print('Train dimension:');print(X_train.shape)\n",
    "    #print('Test dimension:');print(X_test.shape)\n",
    "    Y_train = to_categorical(yclass_train, num_classes)\n",
    "    Y_test = to_categorical(yclass_test, num_classes)\n",
    "    # Set the input shape\n",
    "    input_shape = (feature_vector_length,) \n",
    "    #print(f'Feature shape: {input_shape}')\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.3, input_shape=input_shape))\n",
    "    model.add(Dense(300, input_shape=input_shape, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    #model.summary()\n",
    "    # Configure the model and start training\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\"), keras.metrics.Precision(name=\"precision\"),keras.metrics.Recall(name=\"recall\")])\n",
    "    baseline_history=model.fit(X_train, Y_train, epochs=200, batch_size=150, validation_split=0.2)\n",
    "    # Test the model after training\n",
    "    test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "    #print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}% -Precision: {test_results[2]}% -Recall: {test_results[3]}%')\n",
    "    #Computing F1-score\n",
    "    train_features = np.array(X_train)\n",
    "    test_features = np.array(X_test)\n",
    "    train_labels=np.array(yclass_train)\n",
    "    test_labels=np.array(yclass_test)\n",
    "    train_predictions_baseline = model.predict_classes(train_features, batch_size=100)\n",
    "    f1_train=sklearn.metrics.f1_score(train_labels, train_predictions_baseline, average=None)\n",
    "    test_predictions_baseline = model.predict_classes(test_features, batch_size=150)\n",
    "    f1_test=sklearn.metrics.f1_score(test_labels, test_predictions_baseline, average=None)\n",
    "    print(\"metrics for analyte\",j,'f1_scores, training set',f1_train,'f1_scores in testing set',f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytes 13, 34 and 37 are below .800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA before classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "dfset3=b1.copy()\n",
    "pca = PCA(n_components=30)\n",
    "pca_result = pca.fit_transform(dfset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:\n",
      "(14400, 50)\n",
      "Test dimension:\n",
      "(3600, 50)\n"
     ]
    }
   ],
   "source": [
    "# Configuration options\n",
    "feature_vector_length = 30\n",
    "num_classes = 18000\n",
    "X=pca_result\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.2,random_state=0)\n",
    "# Convert target classes to categorical ones\n",
    "ytrain=Y_train\n",
    "ytest=Y_test\n",
    "Y_train = to_categorical(Y_train, num_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes)\n",
    "print('Train dimension:')\n",
    "print(X_train.shape)\n",
    "print('Test dimension:')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (30,)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 18000)             378000    \n",
      "=================================================================\n",
      "Total params: 379,040\n",
      "Trainable params: 379,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the input shape\n",
    "input_shape = (feature_vector_length,)\n",
    "print(f'Feature shape: {input_shape}')\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "#model.add(Dropout(0.2, input_shape=input_shape))\n",
    "model.add(Dense(20, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected axis -1 of input shape to have value 30 but received input with shape [64, 50]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-33ac3fc1f250>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mbaseline_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\eacun\\anaconda38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected axis -1 of input shape to have value 30 but received input with shape [64, 50]\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "import time\n",
    "start_time = time.time()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "baseline_history=model.fit(X_train, Y_train, epochs=100, batch_size=64, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 6ms/step - loss: 0.2208 - accuracy: 0.9417\n",
      "[0.22077715396881104, 0.9416666626930237]\n",
      "Test results - Loss: 0.22077715396881104 - Accuracy: 0.9416666626930237%\n",
      "--- 223.01282048225403 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Test the model after training\n",
    "test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(test_results)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores in training set 0.9618240587439383 f1_scores in testing set 0.9419507751979359\n"
     ]
    }
   ],
   "source": [
    "#Computing F1-score\n",
    "train_features = np.array(X_train)\n",
    "test_features = np.array(X_test)\n",
    "train_labels=np.array(Y_train)\n",
    "test_labels=np.array(Y_test)\n",
    "train_predictions_baseline = model.predict_classes(train_features, batch_size=150)\n",
    "f1_train=sklearn.metrics.f1_score(ytrain, train_predictions_baseline, average=\"weighted\")\n",
    "test_predictions_baseline = model.predict_classes(test_features, batch_size=150)\n",
    "f1_test=sklearn.metrics.f1_score(ytest, test_predictions_baseline, average=\"weighted\")\n",
    "print('f1_scores in training set',f1_train,'f1_scores in testing set',f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "116/116 [==============================] - 5s 36ms/step - loss: 9.3857 - accuracy: 0.9999 - precision: 0.0342 - recall: 1.1892e-05 - val_loss: 3.0884 - val_accuracy: 0.9999 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.9189 - accuracy: 1.0000 - precision: 0.9784 - recall: 0.6275 - val_loss: 0.1238 - val_accuracy: 1.0000 - val_precision: 0.9729 - val_recall: 0.9729\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.1104 - accuracy: 1.0000 - precision: 0.9761 - recall: 0.9761 - val_loss: 0.1108 - val_accuracy: 1.0000 - val_precision: 0.9729 - val_recall: 0.9729\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0998 - accuracy: 1.0000 - precision: 0.9768 - recall: 0.9763 - val_loss: 0.1030 - val_accuracy: 1.0000 - val_precision: 0.9753 - val_recall: 0.9729\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0993 - accuracy: 1.0000 - precision: 0.9763 - recall: 0.9747 - val_loss: 0.0971 - val_accuracy: 1.0000 - val_precision: 0.9753 - val_recall: 0.9729\n",
      "Epoch 6/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0966 - accuracy: 1.0000 - precision: 0.9759 - recall: 0.9739 - val_loss: 0.0922 - val_accuracy: 1.0000 - val_precision: 0.9753 - val_recall: 0.9729\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0863 - accuracy: 1.0000 - precision: 0.9768 - recall: 0.9757 - val_loss: 0.0861 - val_accuracy: 1.0000 - val_precision: 0.9766 - val_recall: 0.9729\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0837 - accuracy: 1.0000 - precision: 0.9765 - recall: 0.9747 - val_loss: 0.0799 - val_accuracy: 1.0000 - val_precision: 0.9749 - val_recall: 0.9729\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0701 - accuracy: 1.0000 - precision: 0.9793 - recall: 0.9782 - val_loss: 0.0725 - val_accuracy: 1.0000 - val_precision: 0.9736 - val_recall: 0.9729\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 4s 31ms/step - loss: 0.0692 - accuracy: 1.0000 - precision: 0.9780 - recall: 0.9764 - val_loss: 0.0632 - val_accuracy: 1.0000 - val_precision: 0.9729 - val_recall: 0.9729\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0625 - accuracy: 1.0000 - precision: 0.9760 - recall: 0.9750 - val_loss: 0.0502 - val_accuracy: 1.0000 - val_precision: 0.9733 - val_recall: 0.9729\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0539 - accuracy: 1.0000 - precision: 0.9734 - recall: 0.9720 - val_loss: 0.0337 - val_accuracy: 1.0000 - val_precision: 0.9808 - val_recall: 0.9753\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0348 - accuracy: 1.0000 - precision: 0.9838 - recall: 0.9811 - val_loss: 0.0197 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9937\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0218 - accuracy: 1.0000 - precision: 0.9935 - recall: 0.9932 - val_loss: 0.0111 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0153 - accuracy: 1.0000 - precision: 0.9971 - recall: 0.9970 - val_loss: 0.0070 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 16/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0095 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 0.0048 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 17/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0092 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 18/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0081 - accuracy: 1.0000 - precision: 0.9983 - recall: 0.9983 - val_loss: 0.0028 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 19/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0064 - accuracy: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 0.0023 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 20/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0070 - accuracy: 1.0000 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.0019 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 21/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0066 - accuracy: 1.0000 - precision: 0.9985 - recall: 0.9985 - val_loss: 0.0018 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 22/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0045 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 0.0018 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 23/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0048 - accuracy: 1.0000 - precision: 0.9989 - recall: 0.9989 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 24/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0036 - accuracy: 1.0000 - precision: 0.9994 - recall: 0.9994 - val_loss: 0.0014 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 25/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0042 - accuracy: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 0.0014 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 26/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0040 - accuracy: 1.0000 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 27/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0042 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 28/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0047 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 29/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0037 - accuracy: 1.0000 - precision: 0.9995 - recall: 0.9995 - val_loss: 9.9972e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0063 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 31/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0051 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 9.9264e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0043 - accuracy: 1.0000 - precision: 0.9990 - recall: 0.9990 - val_loss: 9.2753e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0046 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 0.0013 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 34/100\n",
      "116/116 [==============================] - 4s 35ms/step - loss: 0.0036 - accuracy: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 8.8887e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0041 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 8.9451e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0031 - accuracy: 1.0000 - precision: 0.9989 - recall: 0.9989 - val_loss: 8.5558e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0022 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 8.4650e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0026 - accuracy: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 8.1121e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0020 - accuracy: 1.0000 - precision: 0.9993 - recall: 0.9993 - val_loss: 8.1869e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0044 - accuracy: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 8.0743e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0037 - accuracy: 1.0000 - precision: 0.9993 - recall: 0.9993 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 42/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0041 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 9.1432e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - precision: 0.9995 - recall: 0.9995 - val_loss: 0.0010 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 44/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0037 - accuracy: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 45/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0031 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 8.1565e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0039 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986 - val_loss: 9.4081e-04 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 47/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0038 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986 - val_loss: 7.2992e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 48/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0023 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 7.5951e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0020 - accuracy: 1.0000 - precision: 0.9996 - recall: 0.9996 - val_loss: 7.2098e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0020 - accuracy: 1.0000 - precision: 0.9995 - recall: 0.9995 - val_loss: 6.9504e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0050 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986 - val_loss: 6.6785e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 52/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0056 - accuracy: 1.0000 - precision: 0.9990 - recall: 0.9990 - val_loss: 7.4117e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0027 - accuracy: 1.0000 - precision: 0.9996 - recall: 0.9996 - val_loss: 7.1492e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0038 - accuracy: 1.0000 - precision: 0.9990 - recall: 0.9990 - val_loss: 8.3354e-04 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 55/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0030 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 56/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0022 - accuracy: 1.0000 - precision: 0.9994 - recall: 0.9994 - val_loss: 8.2947e-04 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 57/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0030 - accuracy: 1.0000 - precision: 0.9995 - recall: 0.9995 - val_loss: 7.1185e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0027 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 7.0035e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 59/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0030 - accuracy: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 6.9487e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0036 - accuracy: 1.0000 - precision: 0.9989 - recall: 0.9989 - val_loss: 0.0010 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 61/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0044 - accuracy: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 62/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0025 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 5.8018e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0028 - accuracy: 1.0000 - precision: 0.9993 - recall: 0.9993 - val_loss: 5.2694e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0029 - accuracy: 1.0000 - precision: 0.9993 - recall: 0.9993 - val_loss: 5.9344e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0025 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 7.2008e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 66/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0021 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 6.0644e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0028 - accuracy: 1.0000 - precision: 0.9996 - recall: 0.9996 - val_loss: 5.8850e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0038 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 6.3805e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0028 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 6.2281e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0025 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 5.4549e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 71/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 0.9995 - recall: 0.9995 - val_loss: 4.8785e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0035 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 5.6216e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0029 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 8.1216e-04 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 74/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0022 - accuracy: 1.0000 - precision: 0.9993 - recall: 0.9993 - val_loss: 7.6539e-04 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 75/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 5.3985e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0018 - accuracy: 1.0000 - precision: 0.9998 - recall: 0.9998 - val_loss: 5.6009e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0025 - accuracy: 1.0000 - precision: 0.9989 - recall: 0.9989 - val_loss: 4.4283e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 78/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0033 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 6.5222e-04 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 79/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0026 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986 - val_loss: 4.8319e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 5.9985e-04 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 81/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0018 - accuracy: 1.0000 - precision: 0.9993 - recall: 0.9993 - val_loss: 4.4162e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 82/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0027 - accuracy: 1.0000 - precision: 0.9993 - recall: 0.9993 - val_loss: 3.5354e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 83/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0035 - accuracy: 1.0000 - precision: 0.9989 - recall: 0.9989 - val_loss: 4.3307e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 84/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0033 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 5.4115e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 85/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0026 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 5.8294e-04 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 86/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0029 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 8.4769e-04 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 87/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0021 - accuracy: 1.0000 - precision: 0.9993 - recall: 0.9993 - val_loss: 3.9612e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 88/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0031 - accuracy: 1.0000 - precision: 0.9994 - recall: 0.9994 - val_loss: 4.2038e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 89/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0019 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 4.9270e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 90/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0067 - accuracy: 1.0000 - precision: 0.9987 - recall: 0.9987 - val_loss: 6.2167e-04 - val_accuracy: 1.0000 - val_precision: 0.9997 - val_recall: 0.9997\n",
      "Epoch 91/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0035 - accuracy: 1.0000 - precision: 0.9989 - recall: 0.9989 - val_loss: 4.7927e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 92/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0020 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 4.6233e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 93/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 0.9996 - recall: 0.9996 - val_loss: 4.5878e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 94/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0018 - accuracy: 1.0000 - precision: 0.9995 - recall: 0.9995 - val_loss: 4.7583e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 95/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0040 - accuracy: 1.0000 - precision: 0.9989 - recall: 0.9989 - val_loss: 4.6465e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 96/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - precision: 0.9993 - recall: 0.9993 - val_loss: 4.3270e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 97/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 0.9995 - recall: 0.9995 - val_loss: 4.0077e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 98/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 4.0791e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 99/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0024 - accuracy: 1.0000 - precision: 0.9994 - recall: 0.9994 - val_loss: 4.8560e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 100/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0016 - accuracy: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 5.1391e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986\n",
      "metrics for analyte 1 f1_scores, training set [0.99996437 0.99863201] f1_scores in testing set [0.99928947 0.96932515]\n",
      "Epoch 1/100\n",
      "116/116 [==============================] - 5s 35ms/step - loss: 9.2196 - accuracy: 0.9999 - precision: 0.0920 - recall: 3.5445e-04 - val_loss: 1.8291 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.1431\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.5206 - accuracy: 1.0000 - precision: 0.9808 - recall: 0.7774 - val_loss: 0.1137 - val_accuracy: 1.0000 - val_precision: 0.9760 - val_recall: 0.9760\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.1054 - accuracy: 1.0000 - precision: 0.9780 - recall: 0.9780 - val_loss: 0.1036 - val_accuracy: 1.0000 - val_precision: 0.9760 - val_recall: 0.9760\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.1028 - accuracy: 1.0000 - precision: 0.9772 - recall: 0.9763 - val_loss: 0.0971 - val_accuracy: 1.0000 - val_precision: 0.9760 - val_recall: 0.9760\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.1062 - accuracy: 1.0000 - precision: 0.9747 - recall: 0.9738 - val_loss: 0.0926 - val_accuracy: 1.0000 - val_precision: 0.9760 - val_recall: 0.9760\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 4s 35ms/step - loss: 0.0855 - accuracy: 1.0000 - precision: 0.9806 - recall: 0.9791 - val_loss: 0.0896 - val_accuracy: 1.0000 - val_precision: 0.9771 - val_recall: 0.9760\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0847 - accuracy: 1.0000 - precision: 0.9800 - recall: 0.9783 - val_loss: 0.0860 - val_accuracy: 1.0000 - val_precision: 0.9771 - val_recall: 0.9760\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 4s 36ms/step - loss: 0.0903 - accuracy: 1.0000 - precision: 0.9770 - recall: 0.9755 - val_loss: 0.0831 - val_accuracy: 1.0000 - val_precision: 0.9771 - val_recall: 0.9760\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0863 - accuracy: 1.0000 - precision: 0.9781 - recall: 0.9760 - val_loss: 0.0801 - val_accuracy: 1.0000 - val_precision: 0.9771 - val_recall: 0.9760\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0783 - accuracy: 1.0000 - precision: 0.9786 - recall: 0.9775 - val_loss: 0.0770 - val_accuracy: 1.0000 - val_precision: 0.9774 - val_recall: 0.9760\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0799 - accuracy: 1.0000 - precision: 0.9786 - recall: 0.9765 - val_loss: 0.0737 - val_accuracy: 1.0000 - val_precision: 0.9771 - val_recall: 0.9760\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0756 - accuracy: 1.0000 - precision: 0.9782 - recall: 0.9765 - val_loss: 0.0702 - val_accuracy: 1.0000 - val_precision: 0.9771 - val_recall: 0.9760\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0773 - accuracy: 1.0000 - precision: 0.9769 - recall: 0.9745 - val_loss: 0.0658 - val_accuracy: 1.0000 - val_precision: 0.9767 - val_recall: 0.9760\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 4s 35ms/step - loss: 0.0635 - accuracy: 1.0000 - precision: 0.9799 - recall: 0.9779 - val_loss: 0.0615 - val_accuracy: 1.0000 - val_precision: 0.9767 - val_recall: 0.9760\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0602 - accuracy: 1.0000 - precision: 0.9787 - recall: 0.9770 - val_loss: 0.0548 - val_accuracy: 1.0000 - val_precision: 0.9764 - val_recall: 0.9760\n",
      "Epoch 16/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0530 - accuracy: 1.0000 - precision: 0.9789 - recall: 0.9775 - val_loss: 0.0470 - val_accuracy: 1.0000 - val_precision: 0.9767 - val_recall: 0.9760\n",
      "Epoch 17/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0497 - accuracy: 1.0000 - precision: 0.9778 - recall: 0.9743 - val_loss: 0.0376 - val_accuracy: 1.0000 - val_precision: 0.9832 - val_recall: 0.9764\n",
      "Epoch 18/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0395 - accuracy: 1.0000 - precision: 0.9838 - recall: 0.9787 - val_loss: 0.0280 - val_accuracy: 1.0000 - val_precision: 0.9889 - val_recall: 0.9858\n",
      "Epoch 19/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0296 - accuracy: 1.0000 - precision: 0.9892 - recall: 0.9873 - val_loss: 0.0198 - val_accuracy: 1.0000 - val_precision: 0.9944 - val_recall: 0.9931\n",
      "Epoch 20/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0233 - accuracy: 1.0000 - precision: 0.9940 - recall: 0.9931 - val_loss: 0.0147 - val_accuracy: 1.0000 - val_precision: 0.9969 - val_recall: 0.9965\n",
      "Epoch 21/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0168 - accuracy: 1.0000 - precision: 0.9963 - recall: 0.9963 - val_loss: 0.0111 - val_accuracy: 1.0000 - val_precision: 0.9976 - val_recall: 0.9976\n",
      "Epoch 22/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0145 - accuracy: 1.0000 - precision: 0.9969 - recall: 0.9969 - val_loss: 0.0090 - val_accuracy: 1.0000 - val_precision: 0.9979 - val_recall: 0.9979\n",
      "Epoch 23/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0106 - accuracy: 1.0000 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.0073 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 24/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0107 - accuracy: 1.0000 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.0067 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 25/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0091 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9979 - val_loss: 0.0057 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 26/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0097 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 0.0055 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 27/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0131 - accuracy: 1.0000 - precision: 0.9974 - recall: 0.9973 - val_loss: 0.0054 - val_accuracy: 1.0000 - val_precision: 0.9983 - val_recall: 0.9983\n",
      "Epoch 28/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0068 - accuracy: 1.0000 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0048 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 29/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0074 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.0047 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 30/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0098 - accuracy: 1.0000 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.0045 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 31/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0095 - accuracy: 1.0000 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.0047 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 32/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0079 - accuracy: 1.0000 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.0043 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 33/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0056 - accuracy: 1.0000 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0046 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 34/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0062 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 0.0041 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 35/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0093 - accuracy: 1.0000 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.0039 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 36/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0090 - accuracy: 1.0000 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.0040 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 37/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0083 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 0.0039 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 38/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0054 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986 - val_loss: 0.0041 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 39/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0070 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986 - val_loss: 0.0039 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 40/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0087 - accuracy: 1.0000 - precision: 0.9985 - recall: 0.9985 - val_loss: 0.0041 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 41/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0064 - accuracy: 1.0000 - precision: 0.9980 - recall: 0.9980 - val_loss: 0.0038 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 42/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0062 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.0039 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 43/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0072 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 44/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0089 - accuracy: 1.0000 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.0037 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 45/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0080 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.0041 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 46/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0073 - accuracy: 1.0000 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.0038 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 47/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0058 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.0038 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 48/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0061 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.0041 - val_accuracy: 1.0000 - val_precision: 0.9986 - val_recall: 0.9986\n",
      "Epoch 49/100\n",
      "116/116 [==============================] - 4s 35ms/step - loss: 0.0074 - accuracy: 1.0000 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.0036 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 50/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0077 - accuracy: 1.0000 - precision: 0.9983 - recall: 0.9983 - val_loss: 0.0037 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 51/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0070 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.0036 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 52/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0058 - accuracy: 1.0000 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 53/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 0.0077 - accuracy: 1.0000 - precision: 0.9989 - recall: 0.9989 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 54/100\n",
      "116/116 [==============================] - 4s 37ms/step - loss: 0.0043 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 0.0041 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 55/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0055 - accuracy: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 0.0038 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 56/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0095 - accuracy: 1.0000 - precision: 0.9983 - recall: 0.9983 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 57/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0039 - accuracy: 1.0000 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 58/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0065 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 59/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0053 - accuracy: 1.0000 - precision: 0.9987 - recall: 0.9987 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 60/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0059 - accuracy: 1.0000 - precision: 0.9980 - recall: 0.9980 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 61/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0053 - accuracy: 1.0000 - precision: 0.9989 - recall: 0.9989 - val_loss: 0.0031 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 62/100\n",
      "116/116 [==============================] - 4s 35ms/step - loss: 0.0077 - accuracy: 1.0000 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.0037 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 63/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0071 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.0033 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 64/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0079 - accuracy: 1.0000 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.0032 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 65/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0043 - accuracy: 1.0000 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0033 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 66/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0073 - accuracy: 1.0000 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.0039 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 67/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0076 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986 - val_loss: 0.0033 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 68/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0057 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 0.0033 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 69/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0061 - accuracy: 1.0000 - precision: 0.9983 - recall: 0.9983 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 70/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0038 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 71/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0055 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 0.0039 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 72/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0084 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.0037 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 73/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0045 - accuracy: 1.0000 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 74/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0061 - accuracy: 1.0000 - precision: 0.9980 - recall: 0.9980 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 75/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0047 - accuracy: 1.0000 - precision: 0.9989 - recall: 0.9989 - val_loss: 0.0033 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 76/100\n",
      "116/116 [==============================] - 4s 32ms/step - loss: 0.0052 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986 - val_loss: 0.0036 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 77/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0055 - accuracy: 1.0000 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.0038 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0047 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 0.0031 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 79/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0059 - accuracy: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 0.0032 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 80/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0073 - accuracy: 1.0000 - precision: 0.9979 - recall: 0.9979 - val_loss: 0.0032 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 81/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0034 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992 - val_loss: 0.0031 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 82/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0063 - accuracy: 1.0000 - precision: 0.9980 - recall: 0.9980 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 83/100\n",
      "116/116 [==============================] - 4s 35ms/step - loss: 0.0096 - accuracy: 1.0000 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.0037 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 84/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0059 - accuracy: 1.0000 - precision: 0.9980 - recall: 0.9980 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 85/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0041 - accuracy: 1.0000 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0036 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 86/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0059 - accuracy: 1.0000 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 87/100\n",
      "116/116 [==============================] - 4s 35ms/step - loss: 0.0047 - accuracy: 1.0000 - precision: 0.9984 - recall: 0.9984 - val_loss: 0.0036 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 88/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0046 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 89/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0064 - accuracy: 1.0000 - precision: 0.9983 - recall: 0.9983 - val_loss: 0.0032 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 90/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0042 - accuracy: 1.0000 - precision: 0.9987 - recall: 0.9987 - val_loss: 0.0036 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 91/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0061 - accuracy: 1.0000 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 92/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0038 - accuracy: 1.0000 - precision: 0.9987 - recall: 0.9987 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 93/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0056 - accuracy: 1.0000 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0033 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 94/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0041 - accuracy: 1.0000 - precision: 0.9991 - recall: 0.9991 - val_loss: 0.0030 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 95/100\n",
      "116/116 [==============================] - 4s 35ms/step - loss: 0.0035 - accuracy: 1.0000 - precision: 0.9993 - recall: 0.9993 - val_loss: 0.0029 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990 - precision: 0.9993 - recall: 0\n",
      "Epoch 96/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0048 - accuracy: 1.0000 - precision: 0.9985 - recall: 0.9985 - val_loss: 0.0032 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "Epoch 97/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0034 - accuracy: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 0.0028 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 98/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0032 - accuracy: 1.0000 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0031 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 99/100\n",
      "116/116 [==============================] - 4s 34ms/step - loss: 0.0061 - accuracy: 1.0000 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.0029 - val_accuracy: 1.0000 - val_precision: 0.9993 - val_recall: 0.9993\n",
      "Epoch 100/100\n",
      "116/116 [==============================] - 4s 33ms/step - loss: 0.0052 - accuracy: 1.0000 - precision: 0.9986 - recall: 0.9986 - val_loss: 0.0032 - val_accuracy: 1.0000 - val_precision: 0.9990 - val_recall: 0.9990\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - precision: 0.9992 - recall: 0.9992\n",
      "metrics for analyte 2 f1_scores, training set [0.99957335 0.98219585] f1_scores in testing set [0.99957063 0.98591549]\n",
      "--- 777.4280734062195 seconds ---\n"
     ]
    }
   ],
   "source": [
    "num_classes = 18000\n",
    "labels1=[1,2]\n",
    "import time\n",
    "start_time=time.time()\n",
    "for j in labels1:\n",
    "    yclass=y.copy()\n",
    "    yclass[yclass!=j]=0 \n",
    "    yclass[yclass==j]=1\n",
    "    X_train, X_test, yclass_train, yclass_test = train_test_split(X,yclass,test_size=0.2,random_state=0)\n",
    "    #print('Train dimension:');print(X_train.shape)\n",
    "    #print('Test dimension:');print(X_test.shape)\n",
    "    Y_train = to_categorical(yclass_train, num_classes)\n",
    "    Y_test = to_categorical(yclass_test, num_classes)\n",
    "    # Set the input shape\n",
    "    input_shape = (feature_vector_length,) \n",
    "    #print(f'Feature shape: {input_shape}')\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.2, input_shape=input_shape))\n",
    "    model.add(Dense(30, input_shape=input_shape, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    #model.summary()\n",
    "    # Configure the model and start training\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\"), keras.metrics.Precision(name=\"precision\"),keras.metrics.Recall(name=\"recall\")])\n",
    "    baseline_history=model.fit(X_train, Y_train, epochs=100, batch_size=100, validation_split=0.2)\n",
    "    # Test the model after training\n",
    "    test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "    #print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}% -Precision: {test_results[2]}% -Recall: {test_results[3]}%')\n",
    "    #Computing F1-score\n",
    "    train_features = np.array(X_train)\n",
    "    test_features = np.array(X_test)\n",
    "    train_labels=np.array(yclass_train)\n",
    "    test_labels=np.array(yclass_test)\n",
    "    train_predictions_baseline = model.predict_classes(train_features, batch_size=150)\n",
    "    f1_train=sklearn.metrics.f1_score(train_labels, train_predictions_baseline, average=None)\n",
    "    test_predictions_baseline = model.predict_classes(test_features, batch_size=100)\n",
    "    f1_test=sklearn.metrics.f1_score(test_labels, test_predictions_baseline, average=None)\n",
    "    print(\"metrics for analyte\",j,'f1_scores, training set',f1_train,'f1_scores in testing set',f1_test)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
