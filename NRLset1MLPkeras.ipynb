{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP for analytes classification using Keras\n",
    "#### Edgar Acuna\n",
    "#### June 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tempfile\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "df1=pd.read_csv(\"c://onr2020/NRLset1_part1.csv\",header=None)\n",
    "df2=pd.read_csv(\"c://onr2020/NRLset1_part2.csv\",header=None)\n",
    "df3=pd.read_csv(\"c://onr2020/NRLset1_part3.csv\",header=None)\n",
    "df4=pd.read_csv(\"c://onr2020/NRLset1_part4.csv\",header=None)\n",
    "df5=pd.read_csv(\"c://onr2020/NRLset1_part5.csv\",header=None)\n",
    "df6=pd.read_csv(\"c://onr2020/NRLset1_part6.csv\",header=None)\n",
    "df7=pd.read_csv(\"c://onr2020/NRLset1_part7.csv\",header=None)\n",
    "df8=pd.read_csv(\"c://onr2020/NRLset1_part8.csv\",header=None)\n",
    "y=pd.read_csv(\"c://onr2020/labels.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:\n",
      "(12600, 1701)\n",
      "Test dimension:\n",
      "(5400, 1701)\n"
     ]
    }
   ],
   "source": [
    "dfset1=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8],ignore_index=True)\n",
    "# Configuration options\n",
    "feature_vector_length = 1701\n",
    "num_classes = 18000\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dfset1,y, test_size=0.3,random_state=0)\n",
    "print('Train dimension:');print(X_train.shape)\n",
    "print('Test dimension:');print(X_test.shape)\n",
    "\n",
    "# Convert target classes to categorical ones\n",
    "Y_train = to_categorical(Y_train, num_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (1701,)\n",
      "WARNING:tensorflow:From C:\\Users\\eacun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_1 (Dropout)          (None, 1701)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               510600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 18000)             1818000   \n",
      "=================================================================\n",
      "Total params: 2,358,700\n",
      "Trainable params: 2,358,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the input shape\n",
    "input_shape = (feature_vector_length,)\n",
    "print(f'Feature shape: {input_shape}')\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.3, input_shape=input_shape))\n",
    "model.add(Dense(300, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eacun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10080 samples, validate on 2520 samples\n",
      "Epoch 1/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 4.4428 - accuracy: 0.0236 - val_loss: 3.7832 - val_accuracy: 0.0230\n",
      "Epoch 2/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 3.7250 - accuracy: 0.0309 - val_loss: 3.6937 - val_accuracy: 0.0317\n",
      "Epoch 3/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 3.6880 - accuracy: 0.0333 - val_loss: 3.6694 - val_accuracy: 0.0361\n",
      "Epoch 4/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 3.6346 - accuracy: 0.0415 - val_loss: 3.5463 - val_accuracy: 0.0496\n",
      "Epoch 5/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 3.5640 - accuracy: 0.0548 - val_loss: 3.4663 - val_accuracy: 0.0651\n",
      "Epoch 6/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 3.4885 - accuracy: 0.0665 - val_loss: 3.3352 - val_accuracy: 0.0909\n",
      "Epoch 7/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 3.3868 - accuracy: 0.0925 - val_loss: 3.2078 - val_accuracy: 0.1369\n",
      "Epoch 8/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 3.2939 - accuracy: 0.1192 - val_loss: 3.0856 - val_accuracy: 0.1885\n",
      "Epoch 9/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 3.1903 - accuracy: 0.1414 - val_loss: 2.9242 - val_accuracy: 0.2405\n",
      "Epoch 10/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 3.0771 - accuracy: 0.1739 - val_loss: 2.8727 - val_accuracy: 0.2560\n",
      "Epoch 11/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 3.0021 - accuracy: 0.1995 - val_loss: 2.7612 - val_accuracy: 0.2770\n",
      "Epoch 12/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 2.9020 - accuracy: 0.2253 - val_loss: 2.7262 - val_accuracy: 0.3147\n",
      "Epoch 13/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 2.8213 - accuracy: 0.2517 - val_loss: 2.5934 - val_accuracy: 0.3440\n",
      "Epoch 14/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 2.7389 - accuracy: 0.2723 - val_loss: 2.5287 - val_accuracy: 0.3452\n",
      "Epoch 15/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 2.6755 - accuracy: 0.2906 - val_loss: 2.4100 - val_accuracy: 0.4083\n",
      "Epoch 16/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.6190 - accuracy: 0.3044 - val_loss: 2.3870 - val_accuracy: 0.3925\n",
      "Epoch 17/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 2.5450 - accuracy: 0.3184 - val_loss: 2.2224 - val_accuracy: 0.4663\n",
      "Epoch 18/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 2.4998 - accuracy: 0.3310 - val_loss: 2.1688 - val_accuracy: 0.4813\n",
      "Epoch 19/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 2.4484 - accuracy: 0.3466 - val_loss: 2.1336 - val_accuracy: 0.4940\n",
      "Epoch 20/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 2.4013 - accuracy: 0.3585 - val_loss: 2.1255 - val_accuracy: 0.4940\n",
      "Epoch 21/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 2.3753 - accuracy: 0.3586 - val_loss: 2.0046 - val_accuracy: 0.5175\n",
      "Epoch 22/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.3563 - accuracy: 0.3631 - val_loss: 2.0658 - val_accuracy: 0.4841\n",
      "Epoch 23/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.3209 - accuracy: 0.3692 - val_loss: 2.0045 - val_accuracy: 0.4992\n",
      "Epoch 24/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.2935 - accuracy: 0.3767 - val_loss: 1.9109 - val_accuracy: 0.5218\n",
      "Epoch 25/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.2647 - accuracy: 0.3807 - val_loss: 1.9161 - val_accuracy: 0.5345\n",
      "Epoch 26/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.2372 - accuracy: 0.3952 - val_loss: 1.9159 - val_accuracy: 0.5060\n",
      "Epoch 27/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.2283 - accuracy: 0.3952 - val_loss: 1.8789 - val_accuracy: 0.5190\n",
      "Epoch 28/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.2105 - accuracy: 0.3984 - val_loss: 1.8903 - val_accuracy: 0.5298\n",
      "Epoch 29/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.2012 - accuracy: 0.3992 - val_loss: 1.7869 - val_accuracy: 0.5679\n",
      "Epoch 30/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.1747 - accuracy: 0.4092 - val_loss: 1.8046 - val_accuracy: 0.5234\n",
      "Epoch 31/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.1638 - accuracy: 0.4103 - val_loss: 1.7824 - val_accuracy: 0.5500\n",
      "Epoch 32/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.1474 - accuracy: 0.4155 - val_loss: 1.8194 - val_accuracy: 0.5536\n",
      "Epoch 33/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.1315 - accuracy: 0.4216 - val_loss: 1.7982 - val_accuracy: 0.5476\n",
      "Epoch 34/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.1458 - accuracy: 0.4120 - val_loss: 1.7555 - val_accuracy: 0.5671\n",
      "Epoch 35/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.1180 - accuracy: 0.4184 - val_loss: 1.8004 - val_accuracy: 0.5460\n",
      "Epoch 36/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.1068 - accuracy: 0.4230 - val_loss: 1.7430 - val_accuracy: 0.5651\n",
      "Epoch 37/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0981 - accuracy: 0.4277 - val_loss: 1.7743 - val_accuracy: 0.5579\n",
      "Epoch 38/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.1191 - accuracy: 0.4209 - val_loss: 1.7215 - val_accuracy: 0.5655\n",
      "Epoch 39/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0777 - accuracy: 0.4317 - val_loss: 1.7374 - val_accuracy: 0.5738\n",
      "Epoch 40/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0579 - accuracy: 0.4391 - val_loss: 1.7106 - val_accuracy: 0.5528\n",
      "Epoch 41/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0620 - accuracy: 0.4346 - val_loss: 1.6504 - val_accuracy: 0.6091\n",
      "Epoch 42/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0547 - accuracy: 0.4362 - val_loss: 1.7258 - val_accuracy: 0.5611\n",
      "Epoch 43/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0328 - accuracy: 0.4426 - val_loss: 1.6401 - val_accuracy: 0.6079\n",
      "Epoch 44/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0507 - accuracy: 0.4393 - val_loss: 1.7178 - val_accuracy: 0.5730\n",
      "Epoch 45/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0433 - accuracy: 0.4441 - val_loss: 1.7064 - val_accuracy: 0.5754\n",
      "Epoch 46/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0168 - accuracy: 0.4482 - val_loss: 1.6152 - val_accuracy: 0.6194\n",
      "Epoch 47/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0116 - accuracy: 0.4476 - val_loss: 1.6422 - val_accuracy: 0.6071\n",
      "Epoch 48/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0138 - accuracy: 0.4507 - val_loss: 1.6565 - val_accuracy: 0.5905\n",
      "Epoch 49/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 1.9928 - accuracy: 0.4534 - val_loss: 1.7116 - val_accuracy: 0.5853\n",
      "Epoch 50/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 2.0059 - accuracy: 0.4521 - val_loss: 1.6285 - val_accuracy: 0.5877\n",
      "Epoch 51/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 1.9828 - accuracy: 0.4581 - val_loss: 1.6564 - val_accuracy: 0.5964\n",
      "Epoch 52/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 1.9852 - accuracy: 0.4566 - val_loss: 1.6099 - val_accuracy: 0.5952\n",
      "Epoch 53/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 1.9800 - accuracy: 0.4556 - val_loss: 1.5928 - val_accuracy: 0.6048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 1.9905 - accuracy: 0.4551 - val_loss: 1.5975 - val_accuracy: 0.6393\n",
      "Epoch 55/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 1.9622 - accuracy: 0.4594 - val_loss: 1.5907 - val_accuracy: 0.6163 1s - loss: 1.9604 - accuracy: 0.45\n",
      "Epoch 56/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 1.9724 - accuracy: 0.4606 - val_loss: 1.7002 - val_accuracy: 0.5444\n",
      "Epoch 57/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 1.9814 - accuracy: 0.4562 - val_loss: 1.6305 - val_accuracy: 0.5889\n",
      "Epoch 58/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 1.9749 - accuracy: 0.4564 - val_loss: 1.6216 - val_accuracy: 0.5833\n",
      "Epoch 59/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 1.9638 - accuracy: 0.4580 - val_loss: 1.6372 - val_accuracy: 0.5762\n",
      "Epoch 60/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 1.9482 - accuracy: 0.4631 - val_loss: 1.5832 - val_accuracy: 0.5948\n",
      "Epoch 61/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 1.9494 - accuracy: 0.4649 - val_loss: 1.5479 - val_accuracy: 0.6127\n",
      "Epoch 62/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 1.9440 - accuracy: 0.4685 - val_loss: 1.5602 - val_accuracy: 0.6179\n",
      "Epoch 63/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 1.9336 - accuracy: 0.4727 - val_loss: 1.5260 - val_accuracy: 0.6381\n",
      "Epoch 64/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 1.9428 - accuracy: 0.4659 - val_loss: 1.6134 - val_accuracy: 0.5710\n",
      "Epoch 65/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 1.9377 - accuracy: 0.4729 - val_loss: 1.5361 - val_accuracy: 0.6492\n",
      "Epoch 66/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 1.9342 - accuracy: 0.4676 - val_loss: 1.5584 - val_accuracy: 0.5964\n",
      "Epoch 67/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 1.9100 - accuracy: 0.4744 - val_loss: 1.5331 - val_accuracy: 0.6115\n",
      "Epoch 68/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 1.9109 - accuracy: 0.4754 - val_loss: 1.5240 - val_accuracy: 0.6270\n",
      "Epoch 69/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 1.9184 - accuracy: 0.4702 - val_loss: 1.5980 - val_accuracy: 0.5948\n",
      "Epoch 70/100\n",
      "10080/10080 [==============================] - 14s 1ms/step - loss: 1.9182 - accuracy: 0.4695 - val_loss: 1.5433 - val_accuracy: 0.6385\n",
      "Epoch 71/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 1.9167 - accuracy: 0.4683 - val_loss: 1.5421 - val_accuracy: 0.6171\n",
      "Epoch 72/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 1.9099 - accuracy: 0.4719 - val_loss: 1.6018 - val_accuracy: 0.6075\n",
      "Epoch 73/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 1.9217 - accuracy: 0.4714 - val_loss: 1.4973 - val_accuracy: 0.6556\n",
      "Epoch 74/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 1.9114 - accuracy: 0.4706 - val_loss: 1.5965 - val_accuracy: 0.6012\n",
      "Epoch 75/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 1.8967 - accuracy: 0.4753 - val_loss: 1.5470 - val_accuracy: 0.6183\n",
      "Epoch 76/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 1.9009 - accuracy: 0.4760 - val_loss: 1.5171 - val_accuracy: 0.6321\n",
      "Epoch 77/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 1.9053 - accuracy: 0.4775 - val_loss: 1.5082 - val_accuracy: 0.6385\n",
      "Epoch 78/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 1.9160 - accuracy: 0.4732 - val_loss: 1.5558 - val_accuracy: 0.6016\n",
      "Epoch 79/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 1.8834 - accuracy: 0.4812 - val_loss: 1.5070 - val_accuracy: 0.6353\n",
      "Epoch 80/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 1.8909 - accuracy: 0.4791 - val_loss: 1.4836 - val_accuracy: 0.6524\n",
      "Epoch 81/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 1.8754 - accuracy: 0.4839 - val_loss: 1.5176 - val_accuracy: 0.6175\n",
      "Epoch 82/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 1.8728 - accuracy: 0.4822 - val_loss: 1.4733 - val_accuracy: 0.6619\n",
      "Epoch 83/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8500 - accuracy: 0.4857 - val_loss: 1.4696 - val_accuracy: 0.6448\n",
      "Epoch 84/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8693 - accuracy: 0.4839 - val_loss: 1.4798 - val_accuracy: 0.6639\n",
      "Epoch 85/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8869 - accuracy: 0.4772 - val_loss: 1.5557 - val_accuracy: 0.6111\n",
      "Epoch 86/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8789 - accuracy: 0.4795 - val_loss: 1.4732 - val_accuracy: 0.6389\n",
      "Epoch 87/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8700 - accuracy: 0.4873 - val_loss: 1.4954 - val_accuracy: 0.6381\n",
      "Epoch 88/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8660 - accuracy: 0.4886 - val_loss: 1.4840 - val_accuracy: 0.6329\n",
      "Epoch 89/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8613 - accuracy: 0.4882 - val_loss: 1.5054 - val_accuracy: 0.6147\n",
      "Epoch 90/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8623 - accuracy: 0.4853 - val_loss: 1.5212 - val_accuracy: 0.6226\n",
      "Epoch 91/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8528 - accuracy: 0.4909 - val_loss: 1.4899 - val_accuracy: 0.6246\n",
      "Epoch 92/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8529 - accuracy: 0.4881 - val_loss: 1.4594 - val_accuracy: 0.6639\n",
      "Epoch 93/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8674 - accuracy: 0.4874 - val_loss: 1.5179 - val_accuracy: 0.6171\n",
      "Epoch 94/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8675 - accuracy: 0.4862 - val_loss: 1.4942 - val_accuracy: 0.6480\n",
      "Epoch 95/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8514 - accuracy: 0.4876 - val_loss: 1.5389 - val_accuracy: 0.6024\n",
      "Epoch 96/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8363 - accuracy: 0.4944 - val_loss: 1.5163 - val_accuracy: 0.6337\n",
      "Epoch 97/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8477 - accuracy: 0.4869 - val_loss: 1.4665 - val_accuracy: 0.6448\n",
      "Epoch 98/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8515 - accuracy: 0.4875 - val_loss: 1.4508 - val_accuracy: 0.6385\n",
      "Epoch 99/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 1.8359 - accuracy: 0.4863 - val_loss: 1.5036 - val_accuracy: 0.6389\n",
      "Epoch 100/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 1.8386 - accuracy: 0.4949 - val_loss: 1.5016 - val_accuracy: 0.6147\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "baseline_history=model.fit(X_train, Y_train, epochs=100, batch_size=50, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400/5400 [==============================] - 3s 533us/step\n",
      "[1.5748953676223756, 0.6050000190734863]\n",
      "Test results - Loss: 1.5748953676223756 - Accuracy: 0.6050000190734863%\n"
     ]
    }
   ],
   "source": [
    "# Test the model after training\n",
    "test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(test_results)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Classification of  some analytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyte #18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list(range(1,41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:\n",
      "(12600, 1701)\n",
      "Test dimension:\n",
      "(5400, 1701)\n"
     ]
    }
   ],
   "source": [
    "yclass=y.copy()\n",
    "yclass[yclass!=18]=0\n",
    "yclass[yclass==18]=1\n",
    "X_train, X_test, yclass_train, yclass_test = train_test_split(dfset1,yclass,test_size=0.3,random_state=0)\n",
    "print('Train dimension:');print(X_train.shape)\n",
    "print('Test dimension:');print(X_test.shape)\n",
    "Y_train = to_categorical(yclass_train, num_classes)\n",
    "Y_test = to_categorical(yclass_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (1701,)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_2 (Dropout)          (None, 1701)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 400)               680800    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                20050     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 18000)             918000    \n",
      "=================================================================\n",
      "Total params: 1,618,850\n",
      "Trainable params: 1,618,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the input shape\n",
    "input_shape = (feature_vector_length,)\n",
    "print(f'Feature shape: {input_shape}')\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.3, input_shape=input_shape))\n",
    "model.add(Dense(400, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10080 samples, validate on 2520 samples\n",
      "Epoch 1/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1352 - accuracy: 1.0000 - precision: 0.9755 - recall: 0.9755 - val_loss: 0.1090 - val_accuracy: 1.0000 - val_precision: 0.9806 - val_recall: 0.9806\n",
      "Epoch 2/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1317 - accuracy: 1.0000 - precision: 0.9764 - recall: 0.9759 - val_loss: 0.1098 - val_accuracy: 1.0000 - val_precision: 0.9810 - val_recall: 0.9810\n",
      "Epoch 3/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1310 - accuracy: 1.0000 - precision: 0.9753 - recall: 0.9751 - val_loss: 0.1276 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 4/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1233 - accuracy: 1.0000 - precision: 0.9750 - recall: 0.9744 - val_loss: 0.0812 - val_accuracy: 1.0000 - val_precision: 0.9790 - val_recall: 0.9790\n",
      "Epoch 5/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1088 - accuracy: 1.0000 - precision: 0.9747 - recall: 0.9745 - val_loss: 0.0836 - val_accuracy: 1.0000 - val_precision: 0.9794 - val_recall: 0.9794\n",
      "Epoch 6/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1043 - accuracy: 1.0000 - precision: 0.9746 - recall: 0.9743 - val_loss: 0.0803 - val_accuracy: 1.0000 - val_precision: 0.9790 - val_recall: 0.9790\n",
      "Epoch 7/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1028 - accuracy: 1.0000 - precision: 0.9751 - recall: 0.9749 - val_loss: 0.0738 - val_accuracy: 1.0000 - val_precision: 0.9794 - val_recall: 0.9794\n",
      "Epoch 8/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1009 - accuracy: 1.0000 - precision: 0.9745 - recall: 0.9744 - val_loss: 0.0776 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 9/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0971 - accuracy: 1.0000 - precision: 0.9741 - recall: 0.9741 - val_loss: 0.0799 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 10/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0995 - accuracy: 1.0000 - precision: 0.9745 - recall: 0.9744 - val_loss: 0.0762 - val_accuracy: 1.0000 - val_precision: 0.9802 - val_recall: 0.9802\n",
      "Epoch 11/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0968 - accuracy: 1.0000 - precision: 0.9742 - recall: 0.9742 - val_loss: 0.0734 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 12/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1006 - accuracy: 1.0000 - precision: 0.9747 - recall: 0.9746 - val_loss: 0.0715 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 13/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0944 - accuracy: 1.0000 - precision: 0.9745 - recall: 0.9744 - val_loss: 0.0741 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 14/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0929 - accuracy: 1.0000 - precision: 0.9755 - recall: 0.9754 - val_loss: 0.0700 - val_accuracy: 1.0000 - val_precision: 0.9802 - val_recall: 0.9802\n",
      "Epoch 15/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0939 - accuracy: 1.0000 - precision: 0.9748 - recall: 0.9747 - val_loss: 0.0644 - val_accuracy: 1.0000 - val_precision: 0.9806 - val_recall: 0.9806\n",
      "Epoch 16/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0900 - accuracy: 1.0000 - precision: 0.9763 - recall: 0.9763 - val_loss: 0.0663 - val_accuracy: 1.0000 - val_precision: 0.9802 - val_recall: 0.9802\n",
      "Epoch 17/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0888 - accuracy: 1.0000 - precision: 0.9761 - recall: 0.9759 - val_loss: 0.0729 - val_accuracy: 1.0000 - val_precision: 0.9829 - val_recall: 0.9829\n",
      "Epoch 18/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0889 - accuracy: 1.0000 - precision: 0.9778 - recall: 0.9776 - val_loss: 0.0675 - val_accuracy: 1.0000 - val_precision: 0.9841 - val_recall: 0.9837\n",
      "Epoch 19/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0898 - accuracy: 1.0000 - precision: 0.9778 - recall: 0.9776 - val_loss: 0.0595 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 20/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0855 - accuracy: 1.0000 - precision: 0.9790 - recall: 0.9789 - val_loss: 0.0607 - val_accuracy: 1.0000 - val_precision: 0.9849 - val_recall: 0.9849\n",
      "Epoch 21/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0917 - accuracy: 1.0000 - precision: 0.9771 - recall: 0.9769 - val_loss: 0.0641 - val_accuracy: 1.0000 - val_precision: 0.9845 - val_recall: 0.9845\n",
      "Epoch 22/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0823 - accuracy: 1.0000 - precision: 0.9793 - recall: 0.9791 - val_loss: 0.0598 - val_accuracy: 1.0000 - val_precision: 0.9853 - val_recall: 0.9853\n",
      "Epoch 23/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0840 - accuracy: 1.0000 - precision: 0.9782 - recall: 0.9782 - val_loss: 0.0570 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 24/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0845 - accuracy: 1.0000 - precision: 0.9787 - recall: 0.9787 - val_loss: 0.0585 - val_accuracy: 1.0000 - val_precision: 0.9845 - val_recall: 0.9845\n",
      "Epoch 25/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0846 - accuracy: 1.0000 - precision: 0.9784 - recall: 0.9783 - val_loss: 0.0673 - val_accuracy: 1.0000 - val_precision: 0.9829 - val_recall: 0.9829\n",
      "Epoch 26/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0847 - accuracy: 1.0000 - precision: 0.9780 - recall: 0.9780 - val_loss: 0.0599 - val_accuracy: 1.0000 - val_precision: 0.9837 - val_recall: 0.9837\n",
      "Epoch 27/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0812 - accuracy: 1.0000 - precision: 0.9798 - recall: 0.9796 - val_loss: 0.0599 - val_accuracy: 1.0000 - val_precision: 0.9853 - val_recall: 0.9853\n",
      "Epoch 28/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0827 - accuracy: 1.0000 - precision: 0.9782 - recall: 0.9781 - val_loss: 0.0565 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 29/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0840 - accuracy: 1.0000 - precision: 0.9785 - recall: 0.9784 - val_loss: 0.0555 - val_accuracy: 1.0000 - val_precision: 0.9873 - val_recall: 0.9873\n",
      "Epoch 30/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0795 - accuracy: 1.0000 - precision: 0.9800 - recall: 0.9800 - val_loss: 0.0557 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 31/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0843 - accuracy: 1.0000 - precision: 0.9791 - recall: 0.9788 - val_loss: 0.0578 - val_accuracy: 1.0000 - val_precision: 0.9869 - val_recall: 0.9869\n",
      "Epoch 32/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0810 - accuracy: 1.0000 - precision: 0.9797 - recall: 0.9797 - val_loss: 0.0561 - val_accuracy: 1.0000 - val_precision: 0.9841 - val_recall: 0.9841\n",
      "Epoch 33/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0827 - accuracy: 1.0000 - precision: 0.9794 - recall: 0.9794 - val_loss: 0.0564 - val_accuracy: 1.0000 - val_precision: 0.9853 - val_recall: 0.9853\n",
      "Epoch 34/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0829 - accuracy: 1.0000 - precision: 0.9788 - recall: 0.9786 - val_loss: 0.0616 - val_accuracy: 1.0000 - val_precision: 0.9841 - val_recall: 0.9841\n",
      "Epoch 35/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0818 - accuracy: 1.0000 - precision: 0.9789 - recall: 0.9788 - val_loss: 0.0609 - val_accuracy: 1.0000 - val_precision: 0.9853 - val_recall: 0.9853\n",
      "Epoch 36/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0813 - accuracy: 1.0000 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.0566 - val_accuracy: 1.0000 - val_precision: 0.9849 - val_recall: 0.9849\n",
      "Epoch 37/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0799 - accuracy: 1.0000 - precision: 0.9803 - recall: 0.9803 - val_loss: 0.0549 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 38/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0796 - accuracy: 1.0000 - precision: 0.9797 - recall: 0.9797 - val_loss: 0.0593 - val_accuracy: 1.0000 - val_precision: 0.9853 - val_recall: 0.9853\n",
      "Epoch 39/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0789 - accuracy: 1.0000 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.0642 - val_accuracy: 1.0000 - val_precision: 0.9841 - val_recall: 0.9841\n",
      "Epoch 40/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0806 - accuracy: 1.0000 - precision: 0.9802 - recall: 0.9801 - val_loss: 0.0609 - val_accuracy: 1.0000 - val_precision: 0.9849 - val_recall: 0.9849\n",
      "Epoch 41/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0803 - accuracy: 1.0000 - precision: 0.9796 - recall: 0.9796 - val_loss: 0.0656 - val_accuracy: 1.0000 - val_precision: 0.9817 - val_recall: 0.9817\n",
      "Epoch 42/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0799 - accuracy: 1.0000 - precision: 0.9801 - recall: 0.9800 - val_loss: 0.0614 - val_accuracy: 1.0000 - val_precision: 0.9833 - val_recall: 0.9833\n",
      "Epoch 43/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0806 - accuracy: 1.0000 - precision: 0.9804 - recall: 0.9804 - val_loss: 0.0531 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 44/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0751 - accuracy: 1.0000 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.0539 - val_accuracy: 1.0000 - val_precision: 0.9873 - val_recall: 0.9873\n",
      "Epoch 45/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0838 - accuracy: 1.0000 - precision: 0.9795 - recall: 0.9795 - val_loss: 0.0624 - val_accuracy: 1.0000 - val_precision: 0.9837 - val_recall: 0.9837\n",
      "Epoch 46/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0839 - accuracy: 1.0000 - precision: 0.9803 - recall: 0.9802 - val_loss: 0.0583 - val_accuracy: 1.0000 - val_precision: 0.9845 - val_recall: 0.9845\n",
      "Epoch 47/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0771 - accuracy: 1.0000 - precision: 0.9805 - recall: 0.9805 - val_loss: 0.0578 - val_accuracy: 1.0000 - val_precision: 0.9833 - val_recall: 0.9833\n",
      "Epoch 48/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0799 - accuracy: 1.0000 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.0613 - val_accuracy: 1.0000 - val_precision: 0.9821 - val_recall: 0.9817\n",
      "Epoch 49/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0791 - accuracy: 1.0000 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.0543 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 50/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0769 - accuracy: 1.0000 - precision: 0.9810 - recall: 0.9810 - val_loss: 0.0512 - val_accuracy: 1.0000 - val_precision: 0.9873 - val_recall: 0.9873\n",
      "Epoch 51/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0784 - accuracy: 1.0000 - precision: 0.9804 - recall: 0.9804 - val_loss: 0.0525 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 52/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0796 - accuracy: 1.0000 - precision: 0.9805 - recall: 0.9805 - val_loss: 0.0552 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 53/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0769 - accuracy: 1.0000 - precision: 0.9799 - recall: 0.9799 - val_loss: 0.0597 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 54/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0780 - accuracy: 1.0000 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.0560 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 55/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0768 - accuracy: 1.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.0553 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 56/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0787 - accuracy: 1.0000 - precision: 0.9803 - recall: 0.9803 - val_loss: 0.0536 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 57/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0807 - accuracy: 1.0000 - precision: 0.9803 - recall: 0.9803 - val_loss: 0.0559 - val_accuracy: 1.0000 - val_precision: 0.9849 - val_recall: 0.9849\n",
      "Epoch 58/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0804 - accuracy: 1.0000 - precision: 0.9796 - recall: 0.9795 - val_loss: 0.0521 - val_accuracy: 1.0000 - val_precision: 0.9881 - val_recall: 0.9881\n",
      "Epoch 59/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0761 - accuracy: 1.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.0535 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 60/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0746 - accuracy: 1.0000 - precision: 0.9819 - recall: 0.9819 - val_loss: 0.0526 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 61/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0787 - accuracy: 1.0000 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.0507 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 62/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0741 - accuracy: 1.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.0528 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 63/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0772 - accuracy: 1.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.0586 - val_accuracy: 1.0000 - val_precision: 0.9865 - val_recall: 0.9865\n",
      "Epoch 64/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0773 - accuracy: 1.0000 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.0552 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 65/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0798 - accuracy: 1.0000 - precision: 0.9807 - recall: 0.9806 - val_loss: 0.0589 - val_accuracy: 1.0000 - val_precision: 0.9889 - val_recall: 0.9889\n",
      "Epoch 66/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0761 - accuracy: 1.0000 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.0582 - val_accuracy: 1.0000 - val_precision: 0.9841 - val_recall: 0.9841\n",
      "Epoch 67/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0784 - accuracy: 1.0000 - precision: 0.9810 - recall: 0.9810 - val_loss: 0.0552 - val_accuracy: 1.0000 - val_precision: 0.9865 - val_recall: 0.9865\n",
      "Epoch 68/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0791 - accuracy: 1.0000 - precision: 0.9798 - recall: 0.9798 - val_loss: 0.0630 - val_accuracy: 1.0000 - val_precision: 0.9849 - val_recall: 0.9849\n",
      "Epoch 69/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0757 - accuracy: 1.0000 - precision: 0.9810 - recall: 0.9810 - val_loss: 0.0572 - val_accuracy: 1.0000 - val_precision: 0.9889 - val_recall: 0.9889\n",
      "Epoch 70/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0776 - accuracy: 1.0000 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.0553 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0774 - accuracy: 1.0000 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.0573 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 72/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0780 - accuracy: 1.0000 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.0774 - val_accuracy: 1.0000 - val_precision: 0.9802 - val_recall: 0.9802\n",
      "Epoch 73/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0768 - accuracy: 1.0000 - precision: 0.9802 - recall: 0.9802 - val_loss: 0.0553 - val_accuracy: 1.0000 - val_precision: 0.9889 - val_recall: 0.9889\n",
      "Epoch 74/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0774 - accuracy: 1.0000 - precision: 0.9811 - recall: 0.9811 - val_loss: 0.0521 - val_accuracy: 1.0000 - val_precision: 0.9881 - val_recall: 0.9881\n",
      "Epoch 75/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0768 - accuracy: 1.0000 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.0528 - val_accuracy: 1.0000 - val_precision: 0.9869 - val_recall: 0.9869\n",
      "Epoch 76/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0774 - accuracy: 1.0000 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.0528 - val_accuracy: 1.0000 - val_precision: 0.9869 - val_recall: 0.9869\n",
      "Epoch 77/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0771 - accuracy: 1.0000 - precision: 0.9798 - recall: 0.9798 - val_loss: 0.0508 - val_accuracy: 1.0000 - val_precision: 0.9881 - val_recall: 0.9881\n",
      "Epoch 78/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0780 - accuracy: 1.0000 - precision: 0.9813 - recall: 0.9813 - val_loss: 0.0563 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 79/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0750 - accuracy: 1.0000 - precision: 0.9814 - recall: 0.9813 - val_loss: 0.0553 - val_accuracy: 1.0000 - val_precision: 0.9849 - val_recall: 0.9849\n",
      "Epoch 80/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0775 - accuracy: 1.0000 - precision: 0.9805 - recall: 0.9805 - val_loss: 0.0503 - val_accuracy: 1.0000 - val_precision: 0.9889 - val_recall: 0.9889\n",
      "Epoch 81/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0746 - accuracy: 1.0000 - precision: 0.9815 - recall: 0.9815 - val_loss: 0.0527 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 82/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0785 - accuracy: 1.0000 - precision: 0.9811 - recall: 0.9811 - val_loss: 0.0534 - val_accuracy: 1.0000 - val_precision: 0.9865 - val_recall: 0.9865\n",
      "Epoch 83/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0754 - accuracy: 1.0000 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.0558 - val_accuracy: 1.0000 - val_precision: 0.9853 - val_recall: 0.9853\n",
      "Epoch 84/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0775 - accuracy: 1.0000 - precision: 0.9813 - recall: 0.9813 - val_loss: 0.0583 - val_accuracy: 1.0000 - val_precision: 0.9845 - val_recall: 0.9845\n",
      "Epoch 85/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0745 - accuracy: 1.0000 - precision: 0.9811 - recall: 0.9811 - val_loss: 0.0532 - val_accuracy: 1.0000 - val_precision: 0.9873 - val_recall: 0.9873\n",
      "Epoch 86/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0751 - accuracy: 1.0000 - precision: 0.9815 - recall: 0.9815 - val_loss: 0.0592 - val_accuracy: 1.0000 - val_precision: 0.9833 - val_recall: 0.9833\n",
      "Epoch 87/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0757 - accuracy: 1.0000 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.0553 - val_accuracy: 1.0000 - val_precision: 0.9865 - val_recall: 0.9865\n",
      "Epoch 88/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0751 - accuracy: 1.0000 - precision: 0.9805 - recall: 0.9805 - val_loss: 0.0502 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 89/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0736 - accuracy: 1.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.0522 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 90/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0769 - accuracy: 1.0000 - precision: 0.9815 - recall: 0.9815 - val_loss: 0.0520 - val_accuracy: 1.0000 - val_precision: 0.9865 - val_recall: 0.9865\n",
      "Epoch 91/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0749 - accuracy: 1.0000 - precision: 0.9815 - recall: 0.9815 - val_loss: 0.0541 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 92/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0735 - accuracy: 1.0000 - precision: 0.9817 - recall: 0.9817 - val_loss: 0.0493 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 93/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0719 - accuracy: 1.0000 - precision: 0.9823 - recall: 0.9822 - val_loss: 0.0504 - val_accuracy: 1.0000 - val_precision: 0.9865 - val_recall: 0.9865\n",
      "Epoch 94/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0722 - accuracy: 1.0000 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.0521 - val_accuracy: 1.0000 - val_precision: 0.9889 - val_recall: 0.9889\n",
      "Epoch 95/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0776 - accuracy: 1.0000 - precision: 0.9802 - recall: 0.9802 - val_loss: 0.0523 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 96/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0740 - accuracy: 1.0000 - precision: 0.9817 - recall: 0.9817 - val_loss: 0.0503 - val_accuracy: 1.0000 - val_precision: 0.9869 - val_recall: 0.9869\n",
      "Epoch 97/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0737 - accuracy: 1.0000 - precision: 0.9820 - recall: 0.9820 - val_loss: 0.0477 - val_accuracy: 1.0000 - val_precision: 0.9889 - val_recall: 0.9889\n",
      "Epoch 98/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0756 - accuracy: 1.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.0505 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 99/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0762 - accuracy: 1.0000 - precision: 0.9815 - recall: 0.9815 - val_loss: 0.0501 - val_accuracy: 1.0000 - val_precision: 0.9881 - val_recall: 0.9881\n",
      "Epoch 100/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0758 - accuracy: 1.0000 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.0517 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\"), keras.metrics.Precision(name=\"precision\"),keras.metrics.Recall(name=\"recall\")])\n",
    "baseline_history=model.fit(X_train, Y_train, epochs=100, batch_size=50, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model after training\n",
    "test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}% -Precision: {test_results[2]}% -Recall: {test_results[3]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for plotting\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_metrics(history):\n",
    "  metrics =  ['loss', 'accuracy','precision','recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(baseline_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model.predict_classes(X_train,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores, training set [0.99200581 0.54166667] f1_scores in testing set [0.99208294 0.55789474]\n"
     ]
    }
   ],
   "source": [
    "#Computing F1-score\n",
    "train_features = np.array(X_train)\n",
    "test_features = np.array(X_test)\n",
    "train_labels=np.array(yclass_train)\n",
    "test_labels=np.array(yclass_test)\n",
    "train_predictions_baseline = model.predict_classes(train_features, batch_size=150)\n",
    "f1_train=sklearn.metrics.f1_score(train_labels, train_predictions_baseline, average=None)\n",
    "test_predictions_baseline = model.predict_classes(test_features, batch_size=150)\n",
    "f1_test=sklearn.metrics.f1_score(test_labels, test_predictions_baseline, average=None)\n",
    "print('f1_scores, training set',f1_train,'f1_scores in testing set',f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ROC curve\n",
    "fp, tp, _ = sklearn.metrics.roc_curve(train_labels, train_predictions_baseline)\n",
    "fp1, tp1, _ = sklearn.metrics.roc_curve(test_labels, test_predictions_baseline)\n",
    "roc_auc = sklearn.metrics.auc(fp,tp)\n",
    "roc_auc1 = sklearn.metrics.auc(fp1,tp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(fp, tp, 'b', label='AUC-train = %0.2f'% roc_auc)\n",
    "ax.plot(fp1, tp1, 'b--', label='AUC-test = %0.2f'% roc_auc1)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([0,1.0])\n",
    "plt.ylim([0,1.0])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyte #24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yclass=y.copy()\n",
    "yclass[yclass!=24]=0\n",
    "yclass[yclass==24]=1\n",
    "X_train, X_test, yclass_train, yclass_test = train_test_split(dfset1,yclass,test_size=0.3,random_state=0)\n",
    "print('Train dimension:');print(X_train.shape)\n",
    "print('Test dimension:');print(X_test.shape)\n",
    "Y_train = to_categorical(yclass_train, num_classes)\n",
    "Y_test = to_categorical(yclass_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (1701,)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_3 (Dropout)          (None, 1701)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 400)               680800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                20050     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 18000)             918000    \n",
      "=================================================================\n",
      "Total params: 1,618,850\n",
      "Trainable params: 1,618,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the input shape\n",
    "input_shape = (feature_vector_length,)\n",
    "print(f'Feature shape: {input_shape}')\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.3, input_shape=input_shape))\n",
    "model.add(Dense(400, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10080 samples, validate on 2520 samples\n",
      "Epoch 1/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.8985 - accuracy: 1.0000 - precision: 0.9738 - recall: 0.8754 - val_loss: 0.2606 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9782\n",
      "Epoch 2/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.2810 - accuracy: 1.0000 - precision: 0.9743 - recall: 0.9716 - val_loss: 0.2099 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9778\n",
      "Epoch 3/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.2211 - accuracy: 1.0000 - precision: 0.9742 - recall: 0.9734 - val_loss: 0.1668 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 4/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1870 - accuracy: 1.0000 - precision: 0.9735 - recall: 0.9735 - val_loss: 0.1750 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 5/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1697 - accuracy: 1.0000 - precision: 0.9742 - recall: 0.9740 - val_loss: 0.1457 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 6/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1614 - accuracy: 1.0000 - precision: 0.9742 - recall: 0.9742 - val_loss: 0.1401 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 7/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1507 - accuracy: 1.0000 - precision: 0.9742 - recall: 0.9742 - val_loss: 0.1338 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 8/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1468 - accuracy: 1.0000 - precision: 0.9742 - recall: 0.9742 - val_loss: 0.1262 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 9/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1422 - accuracy: 1.0000 - precision: 0.9745 - recall: 0.9745 - val_loss: 0.1251 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 10/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1406 - accuracy: 1.0000 - precision: 0.9743 - recall: 0.9743 - val_loss: 0.1225 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 11/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1385 - accuracy: 1.0000 - precision: 0.9750 - recall: 0.9750 - val_loss: 0.1194 - val_accuracy: 1.0000 - val_precision: 0.9790 - val_recall: 0.9790\n",
      "Epoch 12/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1392 - accuracy: 1.0000 - precision: 0.9748 - recall: 0.9748 - val_loss: 0.1174 - val_accuracy: 1.0000 - val_precision: 0.9790 - val_recall: 0.9790\n",
      "Epoch 13/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1349 - accuracy: 1.0000 - precision: 0.9747 - recall: 0.9747 - val_loss: 0.1163 - val_accuracy: 1.0000 - val_precision: 0.9794 - val_recall: 0.9794\n",
      "Epoch 14/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1337 - accuracy: 1.0000 - precision: 0.9753 - recall: 0.9751 - val_loss: 0.1127 - val_accuracy: 1.0000 - val_precision: 0.9802 - val_recall: 0.9802\n",
      "Epoch 15/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1332 - accuracy: 1.0000 - precision: 0.9756 - recall: 0.9754 - val_loss: 0.1151 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 16/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1379 - accuracy: 1.0000 - precision: 0.9741 - recall: 0.9736 - val_loss: 0.0882 - val_accuracy: 1.0000 - val_precision: 0.9793 - val_recall: 0.9786\n",
      "Epoch 17/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1185 - accuracy: 1.0000 - precision: 0.9741 - recall: 0.9739 - val_loss: 0.0852 - val_accuracy: 1.0000 - val_precision: 0.9798 - val_recall: 0.9794\n",
      "Epoch 18/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.1159 - accuracy: 1.0000 - precision: 0.9745 - recall: 0.9740 - val_loss: 0.0873 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 19/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.1046 - accuracy: 1.0000 - precision: 0.9742 - recall: 0.9739 - val_loss: 0.0914 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 20/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.1048 - accuracy: 1.0000 - precision: 0.9744 - recall: 0.9741 - val_loss: 0.0796 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 21/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0991 - accuracy: 1.0000 - precision: 0.9746 - recall: 0.9745 - val_loss: 0.0798 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 22/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1055 - accuracy: 1.0000 - precision: 0.9740 - recall: 0.9738 - val_loss: 0.1040 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 23/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.1003 - accuracy: 1.0000 - precision: 0.9741 - recall: 0.9740 - val_loss: 0.0742 - val_accuracy: 1.0000 - val_precision: 0.9794 - val_recall: 0.9794\n",
      "Epoch 24/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1022 - accuracy: 1.0000 - precision: 0.9747 - recall: 0.9746 - val_loss: 0.0784 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 25/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.1001 - accuracy: 1.0000 - precision: 0.9742 - recall: 0.9742 - val_loss: 0.0744 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 26/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0996 - accuracy: 1.0000 - precision: 0.9744 - recall: 0.9743 - val_loss: 0.0764 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 27/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0978 - accuracy: 1.0000 - precision: 0.9741 - recall: 0.9740 - val_loss: 0.0793 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 28/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0971 - accuracy: 1.0000 - precision: 0.9740 - recall: 0.9737 - val_loss: 0.0971 - val_accuracy: 1.0000 - val_precision: 0.9790 - val_recall: 0.9786\n",
      "Epoch 29/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0960 - accuracy: 1.0000 - precision: 0.9744 - recall: 0.9743 - val_loss: 0.0709 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 30/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0946 - accuracy: 1.0000 - precision: 0.9748 - recall: 0.9745 - val_loss: 0.0732 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 31/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0919 - accuracy: 1.0000 - precision: 0.9751 - recall: 0.9751 - val_loss: 0.0660 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 32/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0917 - accuracy: 1.0000 - precision: 0.9752 - recall: 0.9750 - val_loss: 0.0692 - val_accuracy: 1.0000 - val_precision: 0.9786 - val_recall: 0.9786\n",
      "Epoch 33/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0896 - accuracy: 1.0000 - precision: 0.9754 - recall: 0.9753 - val_loss: 0.0623 - val_accuracy: 1.0000 - val_precision: 0.9810 - val_recall: 0.9810\n",
      "Epoch 34/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0898 - accuracy: 1.0000 - precision: 0.9752 - recall: 0.9750 - val_loss: 0.0683 - val_accuracy: 1.0000 - val_precision: 0.9825 - val_recall: 0.9825\n",
      "Epoch 35/100\n",
      "10080/10080 [==============================] - 19s 2ms/step - loss: 0.0908 - accuracy: 1.0000 - precision: 0.9764 - recall: 0.9763 - val_loss: 0.0635 - val_accuracy: 1.0000 - val_precision: 0.9813 - val_recall: 0.9813s: 0.0924 - accuracy: 1.\n",
      "Epoch 36/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0914 - accuracy: 1.0000 - precision: 0.9757 - recall: 0.9756 - val_loss: 0.0625 - val_accuracy: 1.0000 - val_precision: 0.9817 - val_recall: 0.9817\n",
      "Epoch 37/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0883 - accuracy: 1.0000 - precision: 0.9778 - recall: 0.9774 - val_loss: 0.0620 - val_accuracy: 1.0000 - val_precision: 0.9833 - val_recall: 0.9833\n",
      "Epoch 38/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0868 - accuracy: 1.0000 - precision: 0.9773 - recall: 0.9772 - val_loss: 0.0650 - val_accuracy: 1.0000 - val_precision: 0.9810 - val_recall: 0.9810\n",
      "Epoch 39/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0845 - accuracy: 1.0000 - precision: 0.9781 - recall: 0.9779 - val_loss: 0.0668 - val_accuracy: 1.0000 - val_precision: 0.9825 - val_recall: 0.9825\n",
      "Epoch 40/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0868 - accuracy: 1.0000 - precision: 0.9770 - recall: 0.9769 - val_loss: 0.0647 - val_accuracy: 1.0000 - val_precision: 0.9865 - val_recall: 0.9865\n",
      "Epoch 41/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0828 - accuracy: 1.0000 - precision: 0.9787 - recall: 0.9787 - val_loss: 0.0613 - val_accuracy: 1.0000 - val_precision: 0.9849 - val_recall: 0.9849\n",
      "Epoch 42/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0859 - accuracy: 1.0000 - precision: 0.9777 - recall: 0.9775 - val_loss: 0.0602 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 43/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0843 - accuracy: 1.0000 - precision: 0.9791 - recall: 0.9790 - val_loss: 0.0571 - val_accuracy: 1.0000 - val_precision: 0.9845 - val_recall: 0.9845\n",
      "Epoch 44/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0819 - accuracy: 1.0000 - precision: 0.9781 - recall: 0.9781 - val_loss: 0.0580 - val_accuracy: 1.0000 - val_precision: 0.9853 - val_recall: 0.9853\n",
      "Epoch 45/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0866 - accuracy: 1.0000 - precision: 0.9781 - recall: 0.9781 - val_loss: 0.0614 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 46/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0838 - accuracy: 1.0000 - precision: 0.9784 - recall: 0.9784 - val_loss: 0.0551 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 47/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0838 - accuracy: 1.0000 - precision: 0.9791 - recall: 0.9791 - val_loss: 0.0656 - val_accuracy: 1.0000 - val_precision: 0.9813 - val_recall: 0.9813\n",
      "Epoch 48/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0807 - accuracy: 1.0000 - precision: 0.9795 - recall: 0.9793 - val_loss: 0.0567 - val_accuracy: 1.0000 - val_precision: 0.9849 - val_recall: 0.9849\n",
      "Epoch 49/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 0.0789 - accuracy: 1.0000 - precision: 0.9805 - recall: 0.9805 - val_loss: 0.0617 - val_accuracy: 1.0000 - val_precision: 0.9845 - val_recall: 0.9845\n",
      "Epoch 50/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 0.0801 - accuracy: 1.0000 - precision: 0.9794 - recall: 0.9794 - val_loss: 0.0551 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 51/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 0.0834 - accuracy: 1.0000 - precision: 0.9799 - recall: 0.9798 - val_loss: 0.0551 - val_accuracy: 1.0000 - val_precision: 0.9865 - val_recall: 0.9865\n",
      "Epoch 52/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 0.0836 - accuracy: 1.0000 - precision: 0.9794 - recall: 0.9794 - val_loss: 0.0648 - val_accuracy: 1.0000 - val_precision: 0.9821 - val_recall: 0.9821\n",
      "Epoch 53/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0794 - accuracy: 1.0000 - precision: 0.9799 - recall: 0.9799 - val_loss: 0.0551 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 54/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0773 - accuracy: 1.0000 - precision: 0.9810 - recall: 0.9810 - val_loss: 0.0576 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 55/100\n",
      "10080/10080 [==============================] - 15s 1ms/step - loss: 0.0786 - accuracy: 1.0000 - precision: 0.9801 - recall: 0.9800 - val_loss: 0.0632 - val_accuracy: 1.0000 - val_precision: 0.9841 - val_recall: 0.9841\n",
      "Epoch 56/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0788 - accuracy: 1.0000 - precision: 0.9804 - recall: 0.9804 - val_loss: 0.0567 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 57/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0753 - accuracy: 1.0000 - precision: 0.9805 - recall: 0.9805 - val_loss: 0.0625 - val_accuracy: 1.0000 - val_precision: 0.9849 - val_recall: 0.9849\n",
      "Epoch 58/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0775 - accuracy: 1.0000 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.0561 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 59/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0819 - accuracy: 1.0000 - precision: 0.9805 - recall: 0.9805 - val_loss: 0.0535 - val_accuracy: 1.0000 - val_precision: 0.9873 - val_recall: 0.9873\n",
      "Epoch 60/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0789 - accuracy: 1.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.0538 - val_accuracy: 1.0000 - val_precision: 0.9865 - val_recall: 0.9865\n",
      "Epoch 61/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0795 - accuracy: 1.0000 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.0531 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 62/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0764 - accuracy: 1.0000 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.0527 - val_accuracy: 1.0000 - val_precision: 0.9873 - val_recall: 0.9873\n",
      "Epoch 63/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0776 - accuracy: 1.0000 - precision: 0.9804 - recall: 0.9804 - val_loss: 0.0570 - val_accuracy: 1.0000 - val_precision: 0.9849 - val_recall: 0.9849\n",
      "Epoch 64/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0777 - accuracy: 1.0000 - precision: 0.9810 - recall: 0.9810 - val_loss: 0.0504 - val_accuracy: 1.0000 - val_precision: 0.9873 - val_recall: 0.9873\n",
      "Epoch 65/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0759 - accuracy: 1.0000 - precision: 0.9813 - recall: 0.9813 - val_loss: 0.0631 - val_accuracy: 1.0000 - val_precision: 0.9794 - val_recall: 0.9794\n",
      "Epoch 66/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0768 - accuracy: 1.0000 - precision: 0.9810 - recall: 0.9810 - val_loss: 0.0497 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 67/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0809 - accuracy: 1.0000 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.0628 - val_accuracy: 1.0000 - val_precision: 0.9873 - val_recall: 0.9873\n",
      "Epoch 68/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0774 - accuracy: 1.0000 - precision: 0.9810 - recall: 0.9810 - val_loss: 0.0555 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 69/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0771 - accuracy: 1.0000 - precision: 0.9810 - recall: 0.9810 - val_loss: 0.0512 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 70/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0812 - accuracy: 1.0000 - precision: 0.9801 - recall: 0.9801 - val_loss: 0.0657 - val_accuracy: 1.0000 - val_precision: 0.9841 - val_recall: 0.9841\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0769 - accuracy: 1.0000 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.0570 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 72/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0768 - accuracy: 1.0000 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.0521 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 73/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0756 - accuracy: 1.0000 - precision: 0.9805 - recall: 0.9805 - val_loss: 0.0536 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 74/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0771 - accuracy: 1.0000 - precision: 0.9804 - recall: 0.9804 - val_loss: 0.0500 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 75/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0762 - accuracy: 1.0000 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.0553 - val_accuracy: 1.0000 - val_precision: 0.9881 - val_recall: 0.9881\n",
      "Epoch 76/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0744 - accuracy: 1.0000 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.0591 - val_accuracy: 1.0000 - val_precision: 0.9853 - val_recall: 0.9853\n",
      "Epoch 77/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0744 - accuracy: 1.0000 - precision: 0.9821 - recall: 0.9821 - val_loss: 0.0562 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 78/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0784 - accuracy: 1.0000 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.0588 - val_accuracy: 1.0000 - val_precision: 0.9853 - val_recall: 0.9853\n",
      "Epoch 79/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0778 - accuracy: 1.0000 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.0556 - val_accuracy: 1.0000 - val_precision: 0.9873 - val_recall: 0.9873\n",
      "Epoch 80/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0742 - accuracy: 1.0000 - precision: 0.9817 - recall: 0.9816 - val_loss: 0.0564 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 81/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0757 - accuracy: 1.0000 - precision: 0.9805 - recall: 0.9805 - val_loss: 0.0508 - val_accuracy: 1.0000 - val_precision: 0.9889 - val_recall: 0.9889\n",
      "Epoch 82/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0747 - accuracy: 1.0000 - precision: 0.9819 - recall: 0.9819 - val_loss: 0.0554 - val_accuracy: 1.0000 - val_precision: 0.9853 - val_recall: 0.9853\n",
      "Epoch 83/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0739 - accuracy: 1.0000 - precision: 0.9820 - recall: 0.9820 - val_loss: 0.0496 - val_accuracy: 1.0000 - val_precision: 0.9885 - val_recall: 0.9885\n",
      "Epoch 84/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0742 - accuracy: 1.0000 - precision: 0.9810 - recall: 0.9810 - val_loss: 0.0522 - val_accuracy: 1.0000 - val_precision: 0.9873 - val_recall: 0.9873\n",
      "Epoch 85/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0751 - accuracy: 1.0000 - precision: 0.9813 - recall: 0.9813 - val_loss: 0.0663 - val_accuracy: 1.0000 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "Epoch 86/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0761 - accuracy: 1.0000 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.0589 - val_accuracy: 1.0000 - val_precision: 0.9865 - val_recall: 0.9865\n",
      "Epoch 87/100\n",
      "10080/10080 [==============================] - 15s 2ms/step - loss: 0.0774 - accuracy: 1.0000 - precision: 0.9815 - recall: 0.9815 - val_loss: 0.0529 - val_accuracy: 1.0000 - val_precision: 0.9869 - val_recall: 0.9869\n",
      "Epoch 88/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0746 - accuracy: 1.0000 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.0565 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 89/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0767 - accuracy: 1.0000 - precision: 0.9816 - recall: 0.9816 - val_loss: 0.0524 - val_accuracy: 1.0000 - val_precision: 0.9889 - val_recall: 0.9889\n",
      "Epoch 90/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0750 - accuracy: 1.0000 - precision: 0.9811 - recall: 0.9811 - val_loss: 0.0527 - val_accuracy: 1.0000 - val_precision: 0.9869 - val_recall: 0.9869\n",
      "Epoch 91/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0784 - accuracy: 1.0000 - precision: 0.9803 - recall: 0.9803 - val_loss: 0.0558 - val_accuracy: 1.0000 - val_precision: 0.9849 - val_recall: 0.9849\n",
      "Epoch 92/100\n",
      "10080/10080 [==============================] - 18s 2ms/step - loss: 0.0750 - accuracy: 1.0000 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.0515 - val_accuracy: 1.0000 - val_precision: 0.9869 - val_recall: 0.9869\n",
      "Epoch 93/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0734 - accuracy: 1.0000 - precision: 0.9818 - recall: 0.9818 - val_loss: 0.0532 - val_accuracy: 1.0000 - val_precision: 0.9881 - val_recall: 0.9881\n",
      "Epoch 94/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0770 - accuracy: 1.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.0579 - val_accuracy: 1.0000 - val_precision: 0.9857 - val_recall: 0.9857\n",
      "Epoch 95/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0744 - accuracy: 1.0000 - precision: 0.9811 - recall: 0.9811 - val_loss: 0.0574 - val_accuracy: 1.0000 - val_precision: 0.9845 - val_recall: 0.9845\n",
      "Epoch 96/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0747 - accuracy: 1.0000 - precision: 0.9816 - recall: 0.9816 - val_loss: 0.0509 - val_accuracy: 1.0000 - val_precision: 0.9873 - val_recall: 0.9873\n",
      "Epoch 97/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0762 - accuracy: 1.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.0520 - val_accuracy: 1.0000 - val_precision: 0.9869 - val_recall: 0.9869\n",
      "Epoch 98/100\n",
      "10080/10080 [==============================] - 16s 2ms/step - loss: 0.0775 - accuracy: 1.0000 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.0520 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 99/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0770 - accuracy: 1.0000 - precision: 0.9808 - recall: 0.9807 - val_loss: 0.0495 - val_accuracy: 1.0000 - val_precision: 0.9877 - val_recall: 0.9877\n",
      "Epoch 100/100\n",
      "10080/10080 [==============================] - 17s 2ms/step - loss: 0.0737 - accuracy: 1.0000 - precision: 0.9813 - recall: 0.9813 - val_loss: 0.0526 - val_accuracy: 1.0000 - val_precision: 0.9881 - val_recall: 0.9881\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and start training\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\"), keras.metrics.Precision(name=\"precision\"),keras.metrics.Recall(name=\"recall\")])\n",
    "baseline_history=model.fit(X_train, Y_train, epochs=100, batch_size=50, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400/5400 [==============================] - 3s 547us/step\n",
      "Test results - Loss: 0.06692275035988401 - Accuracy: 0.9999989867210388% -Precision: 0.9848148226737976% -Recall: 0.9848148226737976%\n"
     ]
    }
   ],
   "source": [
    "# Test the model after training\n",
    "test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}% -Precision: {test_results[2]}% -Recall: {test_results[3]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_scores, training set [0.99232695 0.56621005] f1_scores in testing set [0.99227144 0.56842105]\n"
     ]
    }
   ],
   "source": [
    "#Computing F1-score\n",
    "train_features = np.array(X_train)\n",
    "test_features = np.array(X_test)\n",
    "train_labels=np.array(yclass_train)\n",
    "test_labels=np.array(yclass_test)\n",
    "train_predictions_baseline = model.predict_classes(train_features, batch_size=150)\n",
    "f1_train=sklearn.metrics.f1_score(train_labels, train_predictions_baseline, average=None)\n",
    "test_predictions_baseline = model.predict_classes(test_features, batch_size=150)\n",
    "f1_test=sklearn.metrics.f1_score(test_labels, test_predictions_baseline, average=None)\n",
    "print('f1_scores, training set',f1_train,'f1_scores in testing set',f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
